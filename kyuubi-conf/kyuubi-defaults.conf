# # Spark Configuration
spark.master=spark://host.docker.internal:7077
spark.sql.adaptive.enabled=true
spark.sql.catalogImplementation=hive
spark.serializer=org.apache.spark.serializer.KryoSerializer
spark.jars=/workspace/delta-jars/kyuubi-spark-sql-engine_2.12-1.10.1.jar,/workspace/delta-jars/kyuubi-common_2.12-1.10.1.jar,/workspace/delta-jars/delta-spark_2.12-3.3.0.jar,/workspace/delta-jars/delta-storage-3.3.0.jar,/workspace/delta-jars/kyuubi-server-plugin-1.10.1.jar,/workspace/delta-jars/aws-java-sdk-bundle-1.12.782.jar,/workspace/delta-jars/hadoop-aws-3.3.4.jar
spark.jars.packages=io.delta:delta-spark_2.12:3.3.0,org.apache.hadoop:hadoop-aws:3.3.4
spark.driver.extraClassPath=/workspace/delta-jars/*
spark.executor.extraClassPath=/workspace/delta-jars/*
spark.hive.metastore.uris=thrift://host.docker.internal:9083
spark.hadoop.hadoop.security.authentication=simple

# Engine Settings
kyuubi.engine.jdbc.connection.url=jdbc:hive2://localhost:10009
kyuubi.engine.jdbc.connection.driver=org.apache.hive.jdbc.HiveDriver
kyuubi.engine.spark.version=3.5.4
kyuubi.engine.spark.scala.version=2.12
kyuubi.engine.share.level=CONNECTION
kyuubi.engine.type=SPARK_SQL

# Authentication and HA
kyuubi.authentication=NONE
kyuubi.ha.enabled=false

# Session and Operation Timeouts (all in milliseconds)
kyuubi.session.engine.submit.timeout=300000
kyuubi.session.engine.initialize.timeout=600000
kyuubi.session.engine.idle.timeout=300000
kyuubi.operation.timeout=300000

# Frontend Settings
kyuubi.frontend.bind.host=0.0.0.0
kyuubi.frontend.protocols=THRIFT_BINARY,REST
kyuubi.frontend.thrift.binary.bind.port=10009
kyuubi.frontend.rest.bind.port=10099

# S3A Configuration for MinIO
spark.hadoop.fs.defaultFS=s3a://wba
spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3a.connection.ssl.enabled=true
spark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider
spark.hadoop.fs.s3a.access.key=minioadmin
spark.hadoop.fs.s3a.secret.key=minioadmin
spark.hadoop.fs.s3a.endpoint=http://minio:9000
spark.hadoop.fs.s3a.path.style.access=true

# Delta Lake Configuration
spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension
spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog
spark.delta.logStore.class=io.delta.storage.S3SingleDriverLogStore
spark.sql.warehouse.dir=s3a://wba/warehouse

