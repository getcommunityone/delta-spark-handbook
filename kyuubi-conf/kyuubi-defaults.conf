# # Spark Configuration
spark.master=spark://host.docker.internal:7077
spark.sql.adaptive.enabled=true
spark.sql.catalogImplementation=hive
#spark.jars.packages=io.delta:delta-core_2.12:2.4.0,org.apache.hadoop:hadoop-aws:3.3.6,org.apache.hadoop:hadoop-common:3.3.6,org.apache.kyuubi:kyuubi-spark-sql-engine_2.12:1.10.0
spark.serializer=org.apache.spark.serializer.KryoSerializer
spark.jars=/workspace/delta-spark-handbook/delta-jars/kyuubi-spark-sql-engine_2.12-1.10.1.jar,/workspace/delta-spark-handbook/delta-jars/kyuubi-common_2.12-1.10.1.jar,/workspace/delta-spark-handbook/delta-jars/delta-spark_2.12-3.3.0.jar,/workspace/delta-jars/delta-storage-3.3.0.jar,/workspace/delta-spark-handbook/delta-jars/kyuubi-server-plugin-1.10.1.jar
spark.jars.packages=io.delta:delta-spark_2.12:3.3.0,org.apache.hadoop:hadoop-aws:3.3.2,software.amazon.awssdk:aws-sdk-java:2.20.159
spark.driver.extraClassPath=/workspace/delta-spark-handbook/delta-jars/*
spark.executor.extraClassPath=/workspace/delta-spark-handbook/delta-jars/*
spark.hive.metastore.uris=thrift://host.docker.internal:9083
spark.hadoop.hadoop.security.authentication=simple

kyuubi.engine.jdbc.connection.url=jdbc:hive2://localhost:10009
kyuubi.engine.jdbc.connection.driver=org.apache.hive.jdbc.HiveDriver

# # Kyuubi Configuration
# kyuubi.frontend.thrift.binary.protocol.version=BINARY
# kyuubi.frontend.thrift.binary.min.version=0.14.0
# kyuubi.frontend.thrift.binary.allow.older.versions=true
# kyuubi.frontend.thrift.binary.bind.host=0.0.0.0
# kyuubi.frontend.thrift.binary.bind.port=10009
# kyuubi.frontend.protocols=THRIFT_BINARY
# kyuubi.metrics.enabled=false
# kyuubi.engine.type=SPARK_SQL
# kyuubi.engine.share.level=USER
# kyuubi.engine.pool.size=1
# kyuubi.frontend.thrift.binary.authentication=NONE
# kyuubi.frontend.thrift.binary.sasl.qop=none

# Frontend Settings
# kyuubi.frontend.rest.bind.host=0.0.0.0
# kyuubi.frontend.rest.bind.port=10099
# kyuubi.web.ui.host=0.0.0.0

kyuubi.engine.spark.version=3.5.4
kyuubi.engine.spark.scala.version=2.12
# kyuubi.engine.share.level=CONNECTION
# kyuubi.engine.spark.master=local[*]  # Change to yarn if needed
# kyuubi.engine.spark.submit.deployMode=client
# kyuubi.engine.spark.home=/opt/spark
# kyuubi.session.engine.submit.timeout=300000
# kyuubi.session.engine.idle.timeout=3600000
# kyuubi.session.engine.initialize.timeout=600000
# kyuubi.engine.default.database=default
# kyuubi.engine.jdbc.connection.url=jdbc:hive2://localhost:10009/default;auth=none
# kyuubi.jdbc.driver.class=org.apache.hive.jdbc.HiveDriver

kyuubi.authentication=NONE
kyuubi.ha.enabled=false

# kyuubi.frontend.bind.host=0.0.0.0
# kyuubi.frontend.protocols=THRIFT_BINARY,REST
# kyuubi.frontend.thrift.binary.bind.port=10009
# kyuubi.frontend.rest.bind.port=10099
# # kyuubi.ha.addresses=zookeeper:2181
# kyuubi.session.engine.idle.timeout=PT5M
# kyuubi.operation.incremental.collect=true
# kyuubi.operation.progress.enabled=true
# kyuubi.ha.enabled=false

# kyuubi.metrics.reporters=PROMETHEUS
# kyuubi.metrics.prometheus.port=10019

# kyuubi.engine.session.initialize.sql \
#       show namespaces in tpcds; \
#       show namespaces in tpch; \
#       show namespaces in postgres

# S3A Configuration for MinIO
spark.hadoop.fs.defaultFS=s3a://wba
spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3a.connection.ssl.enabled=true
spark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider
spark.hadoop.fs.s3a.access.key=minioadmin
spark.hadoop.fs.s3a.secret.key=minioadmin
spark.hadoop.fs.s3a.endpoint=http://minio:9000
spark.hadoop.fs.s3a.path.style.access=true
spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension
spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog
spark.delta.logStore.class io.delta.storage.S3SingleDriverLogStore
spark.sql.warehouse.dir s3a://wba/warehouse

