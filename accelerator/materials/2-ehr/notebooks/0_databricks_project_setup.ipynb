{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "769ae8c0",
   "metadata": {},
   "source": [
    "# Databricks Project Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb1fe81",
   "metadata": {},
   "source": [
    "This notebook is part of the OMOP CDM series available at [GitHub](https://github.com/databricks-industry-solutions/omop-cdm)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd84e4c",
   "metadata": {},
   "source": [
    "For more details, visit [Databricks Blog](https://www.databricks.com/blog/2021/07/19/unlocking-the-power-of-health-data-with-a-modern-data-lakehouse.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809b9382",
   "metadata": {},
   "source": [
    "## Add Widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cb3b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "project_name = 'omop-cdm-100K' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0b0dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify path to raw data for each project\n",
    "project_data_paths = {\n",
    "    'omop-cdm-100K': \"s3://hls-eng-data-public/data/rwe/all-states-90K/\",\n",
    "    'omop-cdm-10K': \"s3://hls-eng-data-public/data/synthea/\",\n",
    "    'psm': \"s3://hls-eng-data-public/data/rwe/dbx-covid-sim/\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e970d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "class SolAccUtil:\n",
    "    def __init__(self, project_name, data_path=None, base_path=None):\n",
    "        from pyspark.sql import SparkSession\n",
    "\n",
    "        spark = SparkSession.builder.appName(\"OMOP531\").getOrCreate()\n",
    "        \n",
    "        user = spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
    "        project_name = project_name.strip().replace(' ', '-')\n",
    "        self.settings = {}\n",
    "\n",
    "        if base_path is not None:\n",
    "            base_path = base_path\n",
    "        else:\n",
    "            base_path = f'/home/{user}/health-lakehouse'\n",
    "\n",
    "        if data_path is not None:\n",
    "            data_path = data_path\n",
    "        else:\n",
    "            data_path = project_data_paths[project_name]\n",
    "\n",
    "        delta_path = f'{base_path}/{project_name}/delta'\n",
    "\n",
    "        experiment_name = f'/Users/{user}/{project_name}'\n",
    "        experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "        if not experiment:\n",
    "            experiment_id = mlflow.create_experiment(experiment_name)\n",
    "            experiment = mlflow.get_experiment(experiment_id)\n",
    "\n",
    "        self.settings['base_path'] = base_path\n",
    "        self.settings['delta_path'] = delta_path\n",
    "        self.settings['data_path'] = data_path\n",
    "        self.settings['experiment_name'] = experiment.name\n",
    "        self.settings['experiment_id'] = experiment.experiment_id\n",
    "        self.settings['artifact_location'] = experiment.artifact_location\n",
    "        self.settings['tags'] = experiment.tags\n",
    "\n",
    "    def print_info(self):\n",
    "        for key, val in self.settings.items():\n",
    "            print(f\"{key}: {val}\")\n",
    "\n",
    "    def display_data(self):\n",
    "        from pyspark.sql.functions import lit\n",
    "        from pyspark.sql import SparkSession\n",
    "\n",
    "        spark = SparkSession.builder.getOrCreate()\n",
    "        files = spark.sql(f\"SHOW FILES IN '{self.settings['data_path']}'\")\n",
    "        if files.count() == 0:\n",
    "            print(\"No data available. Please run load_remote_data(<url for the data>)\")\n",
    "        else:\n",
    "            print(\"Data available in\", self.settings['data_path'])\n",
    "            files.withColumn(\"project\", lit(self.settings[\"experiment_name\"])).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748a021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define project settings\n",
    "project_settings = SolAccUtil(project_name=project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9ee140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write configurations for later access\n",
    "import json\n",
    "\n",
    "with open(f'/tmp/{project_name}_configs.json', 'w') as f:\n",
    "    json.dump(project_settings.settings, f, indent=4)\n",
    "\n",
    "print(\"Configurations saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4116530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display project settings\n",
    "project_settings.print_info()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
