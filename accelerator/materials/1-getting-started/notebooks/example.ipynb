{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/02/18 20:36:16 INFO SparkContext: SparkContext is stopping with exitCode 0.\n",
            "25/02/18 20:36:16 INFO SparkUI: Stopped Spark web UI at http://8d144dbc4ecc:4040\n",
            "25/02/18 20:36:16 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\n",
            "25/02/18 20:36:16 INFO MemoryStore: MemoryStore cleared\n",
            "25/02/18 20:36:16 INFO BlockManager: BlockManager stopped\n",
            "25/02/18 20:36:16 INFO BlockManagerMaster: BlockManagerMaster stopped\n",
            "25/02/18 20:36:16 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\n",
            "25/02/18 20:36:16 INFO SparkContext: Successfully stopped SparkContext\n",
            "25/02/18 20:36:16 INFO SparkContext: Running Spark version 3.4.4\n",
            "25/02/18 20:36:16 INFO ResourceUtils: ==============================================================\n",
            "25/02/18 20:36:16 INFO ResourceUtils: No custom resources configured for spark.driver.\n",
            "25/02/18 20:36:16 INFO ResourceUtils: ==============================================================\n",
            "25/02/18 20:36:16 INFO SparkContext: Submitted application: DeltaExample\n",
            "25/02/18 20:36:16 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
            "25/02/18 20:36:16 INFO ResourceProfile: Limiting resource is cpu\n",
            "25/02/18 20:36:16 INFO ResourceProfileManager: Added ResourceProfile id: 0\n",
            "25/02/18 20:36:16 INFO SecurityManager: Changing view acls to: vscode\n",
            "25/02/18 20:36:16 INFO SecurityManager: Changing modify acls to: vscode\n",
            "25/02/18 20:36:16 INFO SecurityManager: Changing view acls groups to: \n",
            "25/02/18 20:36:16 INFO SecurityManager: Changing modify acls groups to: \n",
            "25/02/18 20:36:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: vscode; groups with view permissions: EMPTY; users with modify permissions: vscode; groups with modify permissions: EMPTY\n",
            "25/02/18 20:36:16 DEBUG TransportServer: Shuffle server started on 172.19.0.2 with port 39665\n",
            "25/02/18 20:36:16 INFO Utils: Successfully started service 'sparkDriver' on port 39665.\n",
            "25/02/18 20:36:16 DEBUG SparkEnv: Using serializer: class org.apache.spark.serializer.JavaSerializer\n",
            "25/02/18 20:36:16 INFO SparkEnv: Registering MapOutputTracker\n",
            "25/02/18 20:36:16 DEBUG MapOutputTrackerMasterEndpoint: init\n",
            "25/02/18 20:36:16 INFO SparkEnv: Registering BlockManagerMaster\n",
            "25/02/18 20:36:16 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
            "25/02/18 20:36:16 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
            "25/02/18 20:36:16 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
            "25/02/18 20:36:16 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-6cb7c80f-5653-47fa-871c-11ca58c804e6\n",
            "25/02/18 20:36:16 DEBUG DiskBlockManager: Adding shutdown hook\n",
            "25/02/18 20:36:16 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB\n",
            "25/02/18 20:36:16 INFO SparkEnv: Registering OutputCommitCoordinator\n",
            "25/02/18 20:36:16 DEBUG OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: init\n",
            "25/02/18 20:36:16 DEBUG SecurityManager: Created SSL options for ui: SSLOptions{enabled=false, port=None, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}\n",
            "25/02/18 20:36:16 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI\n",
            "25/02/18 20:36:16 DEBUG JettyUtils: Using requestHeaderSize: 8192\n",
            "25/02/18 20:36:16 DEBUG JettyUtils: Using setSendServerVersion: false\n",
            "25/02/18 20:36:16 DEBUG JettyUtils: Using setSendXPoweredBy: false\n",
            "25/02/18 20:36:16 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n",
            "25/02/18 20:36:16 INFO SparkContext: Added JAR /opt/spark/jars/delta-core_2.12-2.4.0.jar at spark://8d144dbc4ecc:39665/jars/delta-core_2.12-2.4.0.jar with timestamp 1739910976906\n",
            "25/02/18 20:36:16 INFO SparkContext: Added JAR /opt/spark/jars/delta-storage-2.4.0.jar at spark://8d144dbc4ecc:39665/jars/delta-storage-2.4.0.jar with timestamp 1739910976906\n",
            "25/02/18 20:36:16 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.2.jar at spark://8d144dbc4ecc:39665/jars/hadoop-aws-3.3.2.jar with timestamp 1739910976906\n",
            "25/02/18 20:36:16 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.261.jar at spark://8d144dbc4ecc:39665/jars/aws-java-sdk-bundle-1.12.261.jar with timestamp 1739910976906\n",
            "25/02/18 20:36:16 INFO Executor: Starting executor ID driver on host 8d144dbc4ecc\n",
            "25/02/18 20:36:16 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/delta-core_2.12-2.4.0.jar,/opt/spark/jars/delta-storage-2.4.0.jar,/opt/spark/jars/hadoop-aws-3.3.2.jar,/opt/spark/jars/aws-java-sdk-bundle-1.12.261.jar,file:/workspace/delta-spark-handbook/accelerator/materials/1-getting-started/notebooks/aws-java-sdk-bundle-1.12.261.jar'\n",
            "25/02/18 20:36:16 INFO Executor: Fetching spark://8d144dbc4ecc:39665/jars/delta-core_2.12-2.4.0.jar with timestamp 1739910976906\n",
            "25/02/18 20:36:16 DEBUG TransportClientFactory: Creating new connection to 8d144dbc4ecc/172.19.0.2:39665\n",
            "25/02/18 20:36:16 DEBUG TransportClientFactory: Connection to 8d144dbc4ecc/172.19.0.2:39665 successful, running bootstraps...\n",
            "25/02/18 20:36:16 INFO TransportClientFactory: Successfully created connection to 8d144dbc4ecc/172.19.0.2:39665 after 2 ms (0 ms spent in bootstraps)\n",
            "25/02/18 20:36:16 DEBUG TransportClient: Sending stream request for /jars/delta-core_2.12-2.4.0.jar to 8d144dbc4ecc/172.19.0.2:39665\n",
            "25/02/18 20:36:16 INFO Utils: Fetching spark://8d144dbc4ecc:39665/jars/delta-core_2.12-2.4.0.jar to /tmp/spark-bb3a6d1c-8a60-4320-9101-dfda92c02de9/userFiles-1b523487-6795-4fcd-9d29-3d37a28ed924/fetchFileTemp10507075412139197750.tmp\n",
            "25/02/18 20:36:16 DEBUG TransportServer: New connection accepted for remote address /172.19.0.2:34954.\n",
            "25/02/18 20:36:16 INFO Executor: Adding file:/tmp/spark-bb3a6d1c-8a60-4320-9101-dfda92c02de9/userFiles-1b523487-6795-4fcd-9d29-3d37a28ed924/delta-core_2.12-2.4.0.jar to class loader\n",
            "25/02/18 20:36:16 INFO Executor: Fetching spark://8d144dbc4ecc:39665/jars/hadoop-aws-3.3.2.jar with timestamp 1739910976906\n",
            "25/02/18 20:36:16 DEBUG TransportClient: Sending stream request for /jars/hadoop-aws-3.3.2.jar to 8d144dbc4ecc/172.19.0.2:39665\n",
            "25/02/18 20:36:16 INFO Utils: Fetching spark://8d144dbc4ecc:39665/jars/hadoop-aws-3.3.2.jar to /tmp/spark-bb3a6d1c-8a60-4320-9101-dfda92c02de9/userFiles-1b523487-6795-4fcd-9d29-3d37a28ed924/fetchFileTemp6881363123871003813.tmp\n",
            "25/02/18 20:36:17 INFO Executor: Adding file:/tmp/spark-bb3a6d1c-8a60-4320-9101-dfda92c02de9/userFiles-1b523487-6795-4fcd-9d29-3d37a28ed924/hadoop-aws-3.3.2.jar to class loader\n",
            "25/02/18 20:36:17 INFO Executor: Fetching spark://8d144dbc4ecc:39665/jars/delta-storage-2.4.0.jar with timestamp 1739910976906\n",
            "25/02/18 20:36:17 DEBUG TransportClient: Sending stream request for /jars/delta-storage-2.4.0.jar to 8d144dbc4ecc/172.19.0.2:39665\n",
            "25/02/18 20:36:17 INFO Utils: Fetching spark://8d144dbc4ecc:39665/jars/delta-storage-2.4.0.jar to /tmp/spark-bb3a6d1c-8a60-4320-9101-dfda92c02de9/userFiles-1b523487-6795-4fcd-9d29-3d37a28ed924/fetchFileTemp12580586516642812044.tmp\n",
            "25/02/18 20:36:17 INFO Executor: Adding file:/tmp/spark-bb3a6d1c-8a60-4320-9101-dfda92c02de9/userFiles-1b523487-6795-4fcd-9d29-3d37a28ed924/delta-storage-2.4.0.jar to class loader\n",
            "25/02/18 20:36:17 DEBUG TransportServer: Shuffle server started on 172.19.0.2 with port 46261\n",
            "25/02/18 20:36:17 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46261.\n",
            "25/02/18 20:36:17 INFO NettyBlockTransferService: Server created on 8d144dbc4ecc:46261\n",
            "25/02/18 20:36:17 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
            "25/02/18 20:36:17 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 8d144dbc4ecc, 46261, None)\n",
            "25/02/18 20:36:17 DEBUG DefaultTopologyMapper: Got a request for 8d144dbc4ecc\n",
            "25/02/18 20:36:17 INFO BlockManagerMasterEndpoint: Registering block manager 8d144dbc4ecc:46261 with 434.4 MiB RAM, BlockManagerId(driver, 8d144dbc4ecc, 46261, None)\n",
            "25/02/18 20:36:17 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 8d144dbc4ecc, 46261, None)\n",
            "25/02/18 20:36:17 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 8d144dbc4ecc, 46261, None)\n",
            "25/02/18 20:36:17 DEBUG SparkContext: Adding shutdown hook\n",
            "25/02/18 20:36:17 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\n",
            "25/02/18 20:36:17 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.delta.logStore.class -> io.delta.storage.S3SingleDriverLogStore\n",
            "25/02/18 20:36:17 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.hadoop.fs.s3a.connection.ssl.enabled -> false\n",
            "25/02/18 20:36:17 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.jars -> /opt/spark/jars/delta-core_2.12-2.4.0.jar,/opt/spark/jars/delta-storage-2.4.0.jar,/opt/spark/jars/hadoop-aws-3.3.2.jar,/opt/spark/jars/aws-java-sdk-bundle-1.12.261.jar\n",
            "25/02/18 20:36:17 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.hadoop.fs.s3a.impl.disable.cache -> true\n",
            "25/02/18 20:36:17 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.sql.catalog.spark_catalog -> org.apache.spark.sql.delta.catalog.DeltaCatalog\n",
            "25/02/18 20:36:17 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.hadoop.fs.s3a.path.style.access -> true\n",
            "25/02/18 20:36:17 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.app.name -> DeltaExample\n",
            "25/02/18 20:36:17 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.hadoop.fs.s3a.multipart.size -> 104857600\n",
            "25/02/18 20:36:17 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.hadoop.fs.s3a.aws.credentials.provider -> org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\n",
            "25/02/18 20:36:17 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.hadoop.fs.s3a.connection.maximum -> 1\n",
            "25/02/18 20:36:17 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.hadoop.fs.s3a.connection.timeout -> 5000\n",
            "25/02/18 20:36:17 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.hadoop.fs.s3a.secret.key -> minioadmin\n",
            "25/02/18 20:36:17 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.hadoop.fs.s3a.attempts.maximum -> 1\n",
            "25/02/18 20:36:17 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.hadoop.fs.s3a.access.key -> minioadmin\n",
            "25/02/18 20:36:17 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.hadoop.fs.s3a.debug.detailed.exceptions -> true\n",
            "25/02/18 20:36:17 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.master -> local[*]\n",
            "25/02/18 20:36:17 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.driver.extraClassPath -> /opt/spark/jars/delta-core_2.12-2.4.0.jar,/opt/spark/jars/delta-storage-2.4.0.jar,/opt/spark/jars/hadoop-aws-3.3.2.jar,/opt/spark/jars/aws-java-sdk-bundle-1.12.261.jar\n",
            "25/02/18 20:36:17 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.executor.extraClassPath -> /opt/spark/jars/delta-core_2.12-2.4.0.jar,/opt/spark/jars/delta-storage-2.4.0.jar,/opt/spark/jars/hadoop-aws-3.3.2.jar,/opt/spark/jars/aws-java-sdk-bundle-1.12.261.jar\n",
            "25/02/18 20:36:17 DEBUG SharedState: Applying static initial session options to SparkConf: spark.sql.catalogImplementation -> hive\n",
            "25/02/18 20:36:17 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.hadoop.fs.s3a.endpoint -> http://localhost:9000\n",
            "25/02/18 20:36:17 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.hadoop.fs.s3a.impl -> org.apache.hadoop.fs.s3a.S3AFileSystem\n",
            "25/02/18 20:36:17 DEBUG SharedState: Applying static initial session options to SparkConf: spark.sql.extensions -> io.delta.sql.DeltaSparkSessionExtension\n",
            "25/02/18 20:36:17 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.hadoop.fs.s3a.fast.upload -> true\n",
            "25/02/18 20:36:17 INFO SharedState: Warehouse path is 'file:/tmp/spark-warehouse'.\n",
            "25/02/18 20:36:17 DEBUG SparkSqlParser: Parsing command: SET spark.databricks.delta.formatCheck.enabled=false\n",
            "25/02/18 20:36:17 DEBUG ClosureCleaner: Cleaning indylambda closure: $anonfun$pythonToJava$1\n",
            "25/02/18 20:36:17 DEBUG ClosureCleaner:  +++ indylambda closure ($anonfun$pythonToJava$1) is now cleaned +++\n",
            "25/02/18 20:36:17 DEBUG ClosureCleaner: Cleaning indylambda closure: $anonfun$toJavaArray$1\n",
            "25/02/18 20:36:17 DEBUG ClosureCleaner:  +++ indylambda closure ($anonfun$toJavaArray$1) is now cleaned +++\n",
            "25/02/18 20:36:17 DEBUG ClosureCleaner: Cleaning indylambda closure: $anonfun$applySchemaToPythonRDD$1\n",
            "25/02/18 20:36:17 DEBUG ClosureCleaner:  +++ indylambda closure ($anonfun$applySchemaToPythonRDD$1) is now cleaned +++\n",
            "25/02/18 20:36:17 DEBUG WholeStageCodegenExec: \n",
            "/* 001 */ public Object generate(Object[] references) {\n",
            "/* 002 */   return new GeneratedIteratorForCodegenStage1(references);\n",
            "/* 003 */ }\n",
            "/* 004 */\n",
            "/* 005 */ // codegenStageId=1\n",
            "/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {\n",
            "/* 007 */   private Object[] references;\n",
            "/* 008 */   private scala.collection.Iterator[] inputs;\n",
            "/* 009 */   private scala.collection.Iterator rdd_input_0;\n",
            "/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] rdd_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];\n",
            "/* 011 */\n",
            "/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {\n",
            "/* 013 */     this.references = references;\n",
            "/* 014 */   }\n",
            "/* 015 */\n",
            "/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {\n",
            "/* 017 */     partitionIndex = index;\n",
            "/* 018 */     this.inputs = inputs;\n",
            "/* 019 */     rdd_input_0 = inputs[0];\n",
            "/* 020 */     rdd_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);\n",
            "/* 021 */     rdd_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 64);\n",
            "/* 022 */\n",
            "/* 023 */   }\n",
            "/* 024 */\n",
            "/* 025 */   protected void processNext() throws java.io.IOException {\n",
            "/* 026 */     while ( rdd_input_0.hasNext()) {\n",
            "/* 027 */       InternalRow rdd_row_0 = (InternalRow) rdd_input_0.next();\n",
            "/* 028 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);\n",
            "/* 029 */       // common sub-expressions\n",
            "/* 030 */\n",
            "/* 031 */       boolean rdd_isNull_0 = rdd_row_0.isNullAt(0);\n",
            "/* 032 */       long rdd_value_0 = rdd_isNull_0 ?\n",
            "/* 033 */       -1L : (rdd_row_0.getLong(0));\n",
            "/* 034 */       boolean project_isNull_0 = rdd_isNull_0;\n",
            "/* 035 */       UTF8String project_value_0 = null;\n",
            "/* 036 */       if (!rdd_isNull_0) {\n",
            "/* 037 */         project_value_0 = UTF8String.fromString(String.valueOf(rdd_value_0));\n",
            "/* 038 */       }\n",
            "/* 039 */       boolean rdd_isNull_1 = rdd_row_0.isNullAt(1);\n",
            "/* 040 */       UTF8String rdd_value_1 = rdd_isNull_1 ?\n",
            "/* 041 */       null : (rdd_row_0.getUTF8String(1));\n",
            "/* 042 */       rdd_mutableStateArray_0[1].reset();\n",
            "/* 043 */\n",
            "/* 044 */       rdd_mutableStateArray_0[1].zeroOutNullBytes();\n",
            "/* 045 */\n",
            "/* 046 */       if (project_isNull_0) {\n",
            "/* 047 */         rdd_mutableStateArray_0[1].setNullAt(0);\n",
            "/* 048 */       } else {\n",
            "/* 049 */         rdd_mutableStateArray_0[1].write(0, project_value_0);\n",
            "/* 050 */       }\n",
            "/* 051 */\n",
            "/* 052 */       if (rdd_isNull_1) {\n",
            "/* 053 */         rdd_mutableStateArray_0[1].setNullAt(1);\n",
            "/* 054 */       } else {\n",
            "/* 055 */         rdd_mutableStateArray_0[1].write(1, rdd_value_1);\n",
            "/* 056 */       }\n",
            "/* 057 */       append((rdd_mutableStateArray_0[1].getRow()));\n",
            "/* 058 */       if (shouldStop()) return;\n",
            "/* 059 */     }\n",
            "/* 060 */   }\n",
            "/* 061 */\n",
            "/* 062 */ }\n",
            "\n",
            "25/02/18 20:36:17 DEBUG ClosureCleaner: Cleaning indylambda closure: $anonfun$doExecute$4$adapted\n",
            "25/02/18 20:36:17 DEBUG ClosureCleaner:  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++\n",
            "25/02/18 20:36:17 DEBUG ClosureCleaner: Cleaning indylambda closure: $anonfun$executeTake$2\n",
            "25/02/18 20:36:17 DEBUG ClosureCleaner:  +++ indylambda closure ($anonfun$executeTake$2) is now cleaned +++\n",
            "25/02/18 20:36:17 DEBUG ClosureCleaner: Cleaning indylambda closure: $anonfun$runJob$5\n",
            "25/02/18 20:36:17 DEBUG ClosureCleaner:  +++ indylambda closure ($anonfun$runJob$5) is now cleaned +++\n",
            "25/02/18 20:36:17 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
            "25/02/18 20:36:17 DEBUG DAGScheduler: eagerlyComputePartitionsForRddAndAncestors for RDD 6 took 0.000223 seconds\n",
            "25/02/18 20:36:17 DEBUG DAGScheduler: Merging stage rdd profiles: Set()\n",
            "25/02/18 20:36:17 INFO DAGScheduler: Got job 0 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
            "25/02/18 20:36:17 INFO DAGScheduler: Final stage: ResultStage 0 (showString at NativeMethodAccessorImpl.java:0)\n",
            "25/02/18 20:36:17 INFO DAGScheduler: Parents of final stage: List()\n",
            "25/02/18 20:36:17 INFO DAGScheduler: Missing parents: List()\n",
            "25/02/18 20:36:17 DEBUG DAGScheduler: submitStage(ResultStage 0 (name=showString at NativeMethodAccessorImpl.java:0;jobs=0))\n",
            "25/02/18 20:36:17 DEBUG DAGScheduler: missing: List()\n",
            "25/02/18 20:36:17 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
            "25/02/18 20:36:17 DEBUG DAGScheduler: submitMissingTasks(ResultStage 0)\n",
            "25/02/18 20:36:17 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 12.4 KiB, free 434.4 MiB)\n",
            "25/02/18 20:36:17 DEBUG BlockManager: Put block broadcast_0 locally took 1 ms\n",
            "25/02/18 20:36:17 DEBUG BlockManager: Putting block broadcast_0 without replication took 1 ms\n",
            "25/02/18 20:36:17 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 434.4 MiB)\n",
            "25/02/18 20:36:17 DEBUG BlockManagerMasterEndpoint: Updating block info on master broadcast_0_piece0 for BlockManagerId(driver, 8d144dbc4ecc, 46261, None)\n",
            "25/02/18 20:36:17 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 8d144dbc4ecc:46261 (size: 6.6 KiB, free: 434.4 MiB)\n",
            "25/02/18 20:36:17 DEBUG BlockManagerMaster: Updated info of block broadcast_0_piece0\n",
            "25/02/18 20:36:17 DEBUG BlockManager: Told master about block broadcast_0_piece0\n",
            "25/02/18 20:36:17 DEBUG BlockManager: Put block broadcast_0_piece0 locally took 3 ms\n",
            "25/02/18 20:36:17 DEBUG BlockManager: Putting block broadcast_0_piece0 without replication took 3 ms\n",
            "25/02/18 20:36:17 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1540\n",
            "25/02/18 20:36:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
            "25/02/18 20:36:17 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0\n",
            "25/02/18 20:36:17 DEBUG TaskSetManager: Epoch for TaskSet 0.0: 0\n",
            "25/02/18 20:36:17 DEBUG TaskSetManager: Adding pending tasks took 0 ms\n",
            "25/02/18 20:36:17 DEBUG TaskSetManager: Valid locality levels for TaskSet 0.0: NO_PREF, ANY\n",
            "25/02/18 20:36:17 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0.0, runningTasks: 0\n",
            "25/02/18 20:36:17 DEBUG TaskSetManager: Valid locality levels for TaskSet 0.0: NO_PREF, ANY\n",
            "25/02/18 20:36:17 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (8d144dbc4ecc, executor driver, partition 0, PROCESS_LOCAL, 8727 bytes) \n",
            "25/02/18 20:36:17 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY\n",
            "25/02/18 20:36:17 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)\n",
            "25/02/18 20:36:17 DEBUG ExecutorMetricsPoller: stageTCMP: (0, 0) -> 1\n",
            "25/02/18 20:36:17 DEBUG BlockManager: Getting local block broadcast_0\n",
            "25/02/18 20:36:17 DEBUG BlockManager: Level for block broadcast_0 is StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "25/02/18 20:36:17 INFO PythonRunner: Times: total = 731, boot = 636, init = 95, finish = 0\n",
            "25/02/18 20:36:17 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1843 bytes result sent to driver\n",
            "25/02/18 20:36:17 DEBUG ExecutorMetricsPoller: stageTCMP: (0, 0) -> 0\n",
            "25/02/18 20:36:17 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 742 ms on 8d144dbc4ecc (executor driver) (1/1)\n",
            "25/02/18 20:36:17 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
            "25/02/18 20:36:17 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 48161\n",
            "25/02/18 20:36:17 INFO DAGScheduler: ResultStage 0 (showString at NativeMethodAccessorImpl.java:0) finished in 0.753 s\n",
            "25/02/18 20:36:17 DEBUG DAGScheduler: After removal of stage 0, remaining stages = 0\n",
            "25/02/18 20:36:17 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\n",
            "25/02/18 20:36:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished\n",
            "25/02/18 20:36:17 INFO DAGScheduler: Job 0 finished: showString at NativeMethodAccessorImpl.java:0, took 0.757662 s\n",
            "25/02/18 20:36:17 DEBUG ClosureCleaner: Cleaning indylambda closure: $anonfun$executeTake$2\n",
            "25/02/18 20:36:17 DEBUG ClosureCleaner:  +++ indylambda closure ($anonfun$executeTake$2) is now cleaned +++\n",
            "25/02/18 20:36:17 DEBUG ClosureCleaner: Cleaning indylambda closure: $anonfun$runJob$5\n",
            "25/02/18 20:36:17 DEBUG ClosureCleaner:  +++ indylambda closure ($anonfun$runJob$5) is now cleaned +++\n",
            "25/02/18 20:36:17 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
            "25/02/18 20:36:17 DEBUG DAGScheduler: eagerlyComputePartitionsForRddAndAncestors for RDD 6 took 0.000083 seconds\n",
            "25/02/18 20:36:17 DEBUG DAGScheduler: Merging stage rdd profiles: Set()\n",
            "25/02/18 20:36:17 INFO DAGScheduler: Got job 1 (showString at NativeMethodAccessorImpl.java:0) with 4 output partitions\n",
            "25/02/18 20:36:17 INFO DAGScheduler: Final stage: ResultStage 1 (showString at NativeMethodAccessorImpl.java:0)\n",
            "25/02/18 20:36:17 INFO DAGScheduler: Parents of final stage: List()\n",
            "25/02/18 20:36:17 INFO DAGScheduler: Missing parents: List()\n",
            "25/02/18 20:36:17 DEBUG DAGScheduler: submitStage(ResultStage 1 (name=showString at NativeMethodAccessorImpl.java:0;jobs=1))\n",
            "25/02/18 20:36:17 DEBUG DAGScheduler: missing: List()\n",
            "25/02/18 20:36:17 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
            "25/02/18 20:36:17 DEBUG DAGScheduler: submitMissingTasks(ResultStage 1)\n",
            "25/02/18 20:36:17 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.4 KiB, free 434.4 MiB)\n",
            "25/02/18 20:36:17 DEBUG BlockManager: Put block broadcast_1 locally took 1 ms\n",
            "25/02/18 20:36:17 DEBUG BlockManager: Putting block broadcast_1 without replication took 1 ms\n",
            "25/02/18 20:36:17 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 434.4 MiB)\n",
            "25/02/18 20:36:17 DEBUG BlockManagerMasterEndpoint: Updating block info on master broadcast_1_piece0 for BlockManagerId(driver, 8d144dbc4ecc, 46261, None)\n",
            "25/02/18 20:36:17 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 8d144dbc4ecc:46261 (size: 6.6 KiB, free: 434.4 MiB)\n",
            "25/02/18 20:36:17 DEBUG BlockManagerMaster: Updated info of block broadcast_1_piece0\n",
            "25/02/18 20:36:17 DEBUG BlockManager: Told master about block broadcast_1_piece0\n",
            "25/02/18 20:36:17 DEBUG BlockManager: Put block broadcast_1_piece0 locally took 1 ms\n",
            "25/02/18 20:36:17 DEBUG BlockManager: Putting block broadcast_1_piece0 without replication took 1 ms\n",
            "25/02/18 20:36:17 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1540\n",
            "25/02/18 20:36:17 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(1, 2, 3, 4))\n",
            "25/02/18 20:36:17 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks resource profile 0\n",
            "25/02/18 20:36:17 DEBUG TaskSetManager: Epoch for TaskSet 1.0: 0\n",
            "25/02/18 20:36:17 DEBUG TaskSetManager: Adding pending tasks took 0 ms\n",
            "25/02/18 20:36:17 DEBUG TaskSetManager: Valid locality levels for TaskSet 1.0: NO_PREF, ANY\n",
            "25/02/18 20:36:17 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_1.0, runningTasks: 0\n",
            "25/02/18 20:36:17 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (8d144dbc4ecc, executor driver, partition 1, PROCESS_LOCAL, 8727 bytes) \n",
            "25/02/18 20:36:17 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (8d144dbc4ecc, executor driver, partition 2, PROCESS_LOCAL, 8727 bytes) \n",
            "25/02/18 20:36:17 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (8d144dbc4ecc, executor driver, partition 3, PROCESS_LOCAL, 8763 bytes) \n",
            "25/02/18 20:36:17 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (8d144dbc4ecc, executor driver, partition 4, PROCESS_LOCAL, 8727 bytes) \n",
            "25/02/18 20:36:17 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY\n",
            "25/02/18 20:36:17 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)\n",
            "25/02/18 20:36:17 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)\n",
            "25/02/18 20:36:17 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)\n",
            "25/02/18 20:36:17 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)\n",
            "25/02/18 20:36:17 DEBUG ExecutorMetricsPoller: stageTCMP: (1, 0) -> 1\n",
            "25/02/18 20:36:17 DEBUG ExecutorMetricsPoller: stageTCMP: (1, 0) -> 2\n",
            "25/02/18 20:36:17 DEBUG ExecutorMetricsPoller: stageTCMP: (1, 0) -> 3\n",
            "25/02/18 20:36:17 DEBUG ExecutorMetricsPoller: stageTCMP: (1, 0) -> 4\n",
            "25/02/18 20:36:17 DEBUG BlockManager: Getting local block broadcast_1\n",
            "25/02/18 20:36:17 DEBUG BlockManager: Level for block broadcast_1 is StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "25/02/18 20:36:18 INFO PythonRunner: Times: total = 197, boot = -12, init = 209, finish = 0\n",
            "25/02/18 20:36:18 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1843 bytes result sent to driver\n",
            "25/02/18 20:36:18 DEBUG ExecutorMetricsPoller: stageTCMP: (1, 0) -> 3\n",
            "25/02/18 20:36:18 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 219 ms on 8d144dbc4ecc (executor driver) (1/4)\n",
            "25/02/18 20:36:18 INFO PythonRunner: Times: total = 238, boot = 5, init = 233, finish = 0\n",
            "25/02/18 20:36:18 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1843 bytes result sent to driver\n",
            "25/02/18 20:36:18 DEBUG ExecutorMetricsPoller: stageTCMP: (1, 0) -> 2\n",
            "25/02/18 20:36:18 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 249 ms on 8d144dbc4ecc (executor driver) (2/4)\n",
            "25/02/18 20:36:18 INFO PythonRunner: Times: total = 247, boot = 9, init = 238, finish = 0\n",
            "25/02/18 20:36:18 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 1881 bytes result sent to driver\n",
            "25/02/18 20:36:18 DEBUG ExecutorMetricsPoller: stageTCMP: (1, 0) -> 1\n",
            "25/02/18 20:36:18 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 256 ms on 8d144dbc4ecc (executor driver) (3/4)\n",
            "25/02/18 20:36:18 INFO PythonRunner: Times: total = 266, boot = 16, init = 250, finish = 0\n",
            "25/02/18 20:36:18 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 1843 bytes result sent to driver\n",
            "25/02/18 20:36:18 DEBUG ExecutorMetricsPoller: stageTCMP: (1, 0) -> 0\n",
            "25/02/18 20:36:18 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 275 ms on 8d144dbc4ecc (executor driver) (4/4)\n",
            "25/02/18 20:36:18 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool \n",
            "25/02/18 20:36:18 INFO DAGScheduler: ResultStage 1 (showString at NativeMethodAccessorImpl.java:0) finished in 0.284 s\n",
            "25/02/18 20:36:18 DEBUG PoolThreadCache: Freed 4 thread-local buffer(s) from thread: rpc-server-4-1\n",
            "25/02/18 20:36:18 DEBUG DAGScheduler: After removal of stage 1, remaining stages = 0\n",
            "25/02/18 20:36:18 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\n",
            "25/02/18 20:36:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished\n",
            "25/02/18 20:36:18 INFO DAGScheduler: Job 1 finished: showString at NativeMethodAccessorImpl.java:0, took 0.287229 s\n",
            "25/02/18 20:36:18 DEBUG ClosureCleaner: Cleaning indylambda closure: $anonfun$executeTake$2\n",
            "25/02/18 20:36:18 DEBUG ClosureCleaner:  +++ indylambda closure ($anonfun$executeTake$2) is now cleaned +++\n",
            "25/02/18 20:36:18 DEBUG ClosureCleaner: Cleaning indylambda closure: $anonfun$runJob$5\n",
            "25/02/18 20:36:18 DEBUG ClosureCleaner:  +++ indylambda closure ($anonfun$runJob$5) is now cleaned +++\n",
            "25/02/18 20:36:18 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
            "25/02/18 20:36:18 DEBUG DAGScheduler: eagerlyComputePartitionsForRddAndAncestors for RDD 6 took 0.000179 seconds\n",
            "25/02/18 20:36:18 DEBUG DAGScheduler: Merging stage rdd profiles: Set()\n",
            "25/02/18 20:36:18 INFO DAGScheduler: Got job 2 (showString at NativeMethodAccessorImpl.java:0) with 3 output partitions\n",
            "25/02/18 20:36:18 INFO DAGScheduler: Final stage: ResultStage 2 (showString at NativeMethodAccessorImpl.java:0)\n",
            "25/02/18 20:36:18 INFO DAGScheduler: Parents of final stage: List()\n",
            "25/02/18 20:36:18 INFO DAGScheduler: Missing parents: List()\n",
            "25/02/18 20:36:18 DEBUG DAGScheduler: submitStage(ResultStage 2 (name=showString at NativeMethodAccessorImpl.java:0;jobs=2))\n",
            "25/02/18 20:36:18 DEBUG DAGScheduler: missing: List()\n",
            "25/02/18 20:36:18 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[6] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
            "25/02/18 20:36:18 DEBUG DAGScheduler: submitMissingTasks(ResultStage 2)\n",
            "25/02/18 20:36:18 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 12.4 KiB, free 434.4 MiB)\n",
            "25/02/18 20:36:18 DEBUG BlockManager: Put block broadcast_2 locally took 1 ms\n",
            "25/02/18 20:36:18 DEBUG BlockManager: Putting block broadcast_2 without replication took 1 ms\n",
            "25/02/18 20:36:18 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 434.3 MiB)\n",
            "25/02/18 20:36:18 DEBUG BlockManagerMasterEndpoint: Updating block info on master broadcast_2_piece0 for BlockManagerId(driver, 8d144dbc4ecc, 46261, None)\n",
            "25/02/18 20:36:18 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 8d144dbc4ecc:46261 (size: 6.6 KiB, free: 434.4 MiB)\n",
            "25/02/18 20:36:18 DEBUG BlockManagerMaster: Updated info of block broadcast_2_piece0\n",
            "25/02/18 20:36:18 DEBUG BlockManager: Told master about block broadcast_2_piece0\n",
            "25/02/18 20:36:18 DEBUG BlockManager: Put block broadcast_2_piece0 locally took 1 ms\n",
            "25/02/18 20:36:18 DEBUG BlockManager: Putting block broadcast_2_piece0 without replication took 1 ms\n",
            "25/02/18 20:36:18 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1540\n",
            "25/02/18 20:36:18 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 2 (MapPartitionsRDD[6] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(5, 6, 7))\n",
            "25/02/18 20:36:18 INFO TaskSchedulerImpl: Adding task set 2.0 with 3 tasks resource profile 0\n",
            "25/02/18 20:36:18 DEBUG TaskSetManager: Epoch for TaskSet 2.0: 0\n",
            "25/02/18 20:36:18 DEBUG TaskSetManager: Adding pending tasks took 0 ms\n",
            "25/02/18 20:36:18 DEBUG TaskSetManager: Valid locality levels for TaskSet 2.0: NO_PREF, ANY\n",
            "25/02/18 20:36:18 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_2.0, runningTasks: 0\n",
            "25/02/18 20:36:18 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5) (8d144dbc4ecc, executor driver, partition 5, PROCESS_LOCAL, 8727 bytes) \n",
            "25/02/18 20:36:18 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 6) (8d144dbc4ecc, executor driver, partition 6, PROCESS_LOCAL, 8727 bytes) \n",
            "25/02/18 20:36:18 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 7) (8d144dbc4ecc, executor driver, partition 7, PROCESS_LOCAL, 8763 bytes) \n",
            "25/02/18 20:36:18 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY\n",
            "25/02/18 20:36:18 INFO Executor: Running task 2.0 in stage 2.0 (TID 7)\n",
            "25/02/18 20:36:18 INFO Executor: Running task 1.0 in stage 2.0 (TID 6)\n",
            "25/02/18 20:36:18 DEBUG ExecutorMetricsPoller: stageTCMP: (2, 0) -> 1\n",
            "25/02/18 20:36:18 DEBUG ExecutorMetricsPoller: stageTCMP: (2, 0) -> 2\n",
            "25/02/18 20:36:18 DEBUG BlockManager: Getting local block broadcast_2\n",
            "25/02/18 20:36:18 DEBUG BlockManager: Level for block broadcast_2 is StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "25/02/18 20:36:18 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)\n",
            "25/02/18 20:36:18 DEBUG ExecutorMetricsPoller: stageTCMP: (2, 0) -> 3\n",
            "25/02/18 20:36:18 INFO PythonRunner: Times: total = 114, boot = -31, init = 145, finish = 0\n",
            "25/02/18 20:36:18 INFO Executor: Finished task 2.0 in stage 2.0 (TID 7). 1881 bytes result sent to driver\n",
            "25/02/18 20:36:18 DEBUG ExecutorMetricsPoller: stageTCMP: (2, 0) -> 2\n",
            "25/02/18 20:36:18 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 7) in 123 ms on 8d144dbc4ecc (executor driver) (1/3)\n",
            "25/02/18 20:36:18 INFO PythonRunner: Times: total = 130, boot = -73, init = 203, finish = 0\n",
            "25/02/18 20:36:18 INFO Executor: Finished task 1.0 in stage 2.0 (TID 6). 1843 bytes result sent to driver\n",
            "25/02/18 20:36:18 DEBUG ExecutorMetricsPoller: stageTCMP: (2, 0) -> 1\n",
            "25/02/18 20:36:18 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 6) in 138 ms on 8d144dbc4ecc (executor driver) (2/3)\n",
            "25/02/18 20:36:18 INFO PythonRunner: Times: total = 133, boot = -28, init = 161, finish = 0\n",
            "25/02/18 20:36:18 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 1843 bytes result sent to driver\n",
            "25/02/18 20:36:18 DEBUG ExecutorMetricsPoller: stageTCMP: (2, 0) -> 0\n",
            "25/02/18 20:36:18 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 145 ms on 8d144dbc4ecc (executor driver) (3/3)\n",
            "25/02/18 20:36:18 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool \n",
            "25/02/18 20:36:18 INFO DAGScheduler: ResultStage 2 (showString at NativeMethodAccessorImpl.java:0) finished in 0.153 s\n",
            "25/02/18 20:36:18 DEBUG DAGScheduler: After removal of stage 2, remaining stages = 0\n",
            "25/02/18 20:36:18 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job\n",
            "25/02/18 20:36:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished\n",
            "25/02/18 20:36:18 INFO DAGScheduler: Job 2 finished: showString at NativeMethodAccessorImpl.java:0, took 0.156504 s\n",
            "25/02/18 20:36:18 DEBUG GenerateSafeProjection: code for createexternalrow(input[0, string, true].toString, input[1, string, true].toString, StructField(id,StringType,true), StructField(name,StringType,true)):\n",
            "/* 001 */ public java.lang.Object generate(Object[] references) {\n",
            "/* 002 */   return new SpecificSafeProjection(references);\n",
            "/* 003 */ }\n",
            "/* 004 */\n",
            "/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {\n",
            "/* 006 */\n",
            "/* 007 */   private Object[] references;\n",
            "/* 008 */   private InternalRow mutableRow;\n",
            "/* 009 */\n",
            "/* 010 */\n",
            "/* 011 */   public SpecificSafeProjection(Object[] references) {\n",
            "/* 012 */     this.references = references;\n",
            "/* 013 */     mutableRow = (InternalRow) references[references.length - 1];\n",
            "/* 014 */\n",
            "/* 015 */   }\n",
            "/* 016 */\n",
            "/* 017 */   public void initialize(int partitionIndex) {\n",
            "/* 018 */\n",
            "/* 019 */   }\n",
            "/* 020 */\n",
            "/* 021 */   public java.lang.Object apply(java.lang.Object _i) {\n",
            "/* 022 */     InternalRow i = (InternalRow) _i;\n",
            "/* 023 */     org.apache.spark.sql.Row value_5 = CreateExternalRow_0(i);\n",
            "/* 024 */     if (false) {\n",
            "/* 025 */       mutableRow.setNullAt(0);\n",
            "/* 026 */     } else {\n",
            "/* 027 */\n",
            "/* 028 */       mutableRow.update(0, value_5);\n",
            "/* 029 */     }\n",
            "/* 030 */\n",
            "/* 031 */     return mutableRow;\n",
            "/* 032 */   }\n",
            "/* 033 */\n",
            "/* 034 */\n",
            "/* 035 */   private org.apache.spark.sql.Row CreateExternalRow_0(InternalRow i) {\n",
            "/* 036 */     Object[] values_0 = new Object[2];\n",
            "/* 037 */\n",
            "/* 038 */     boolean isNull_2 = i.isNullAt(0);\n",
            "/* 039 */     UTF8String value_2 = isNull_2 ?\n",
            "/* 040 */     null : (i.getUTF8String(0));\n",
            "/* 041 */     boolean isNull_1 = true;\n",
            "/* 042 */     java.lang.String value_1 = null;\n",
            "/* 043 */     if (!isNull_2) {\n",
            "/* 044 */       isNull_1 = false;\n",
            "/* 045 */       if (!isNull_1) {\n",
            "/* 046 */\n",
            "/* 047 */         Object funcResult_0 = null;\n",
            "/* 048 */         funcResult_0 = value_2.toString();\n",
            "/* 049 */         value_1 = (java.lang.String) funcResult_0;\n",
            "/* 050 */\n",
            "/* 051 */       }\n",
            "/* 052 */     }\n",
            "/* 053 */     if (isNull_1) {\n",
            "/* 054 */       values_0[0] = null;\n",
            "/* 055 */     } else {\n",
            "/* 056 */       values_0[0] = value_1;\n",
            "/* 057 */     }\n",
            "/* 058 */\n",
            "/* 059 */     boolean isNull_4 = i.isNullAt(1);\n",
            "/* 060 */     UTF8String value_4 = isNull_4 ?\n",
            "/* 061 */     null : (i.getUTF8String(1));\n",
            "/* 062 */     boolean isNull_3 = true;\n",
            "/* 063 */     java.lang.String value_3 = null;\n",
            "/* 064 */     if (!isNull_4) {\n",
            "/* 065 */       isNull_3 = false;\n",
            "/* 066 */       if (!isNull_3) {\n",
            "/* 067 */\n",
            "/* 068 */         Object funcResult_1 = null;\n",
            "/* 069 */         funcResult_1 = value_4.toString();\n",
            "/* 070 */         value_3 = (java.lang.String) funcResult_1;\n",
            "/* 071 */\n",
            "/* 072 */       }\n",
            "/* 073 */     }\n",
            "/* 074 */     if (isNull_3) {\n",
            "/* 075 */       values_0[1] = null;\n",
            "/* 076 */     } else {\n",
            "/* 077 */       values_0[1] = value_3;\n",
            "/* 078 */     }\n",
            "/* 079 */\n",
            "/* 080 */     final org.apache.spark.sql.Row value_0 = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values_0, ((org.apache.spark.sql.types.StructType) references[0] /* schema */));\n",
            "/* 081 */\n",
            "/* 082 */     return value_0;\n",
            "/* 083 */   }\n",
            "/* 084 */\n",
            "/* 085 */ }\n",
            "\n",
            "25/02/18 20:36:18 DEBUG FileSystem: Bypassing cache to create filesystem s3a://wba/test.parquet\n",
            "25/02/18 20:36:18 DEBUG FileSystem: Starting: Creating FS s3a://wba/test.parquet\n",
            "25/02/18 20:36:18 DEBUG FileSystem: Looking for FS supporting s3a\n",
            "25/02/18 20:36:18 DEBUG FileSystem: looking for configuration option fs.s3a.impl\n",
            "25/02/18 20:36:18 DEBUG FileSystem: Filesystem s3a defined in configuration option\n",
            "25/02/18 20:36:18 DEBUG FileSystem: FS for s3a is class org.apache.hadoop.fs.s3a.S3AFileSystem\n",
            "25/02/18 20:36:18 DEBUG S3AFileSystem: Initializing S3AFileSystem for wba\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Propagating entries under fs.s3a.bucket.wba.\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Data is unencrypted\n",
            "25/02/18 20:36:18 DEBUG S3ARetryPolicy: Retrying on recoverable AWS failures 7 times with an initial interval of 500ms\n",
            "25/02/18 20:36:18 DEBUG MetricsSystemImpl: S3AMetrics3-wba, \n",
            "25/02/18 20:36:18 DEBUG MetricsConfig: poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans\n",
            "25/02/18 20:36:18 DEBUG MetricsConfig: poking parent 'MetricsConfig' for key: source.start_mbeans\n",
            "25/02/18 20:36:18 DEBUG MetricsConfig: poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans\n",
            "25/02/18 20:36:18 DEBUG MetricsSourceAdapter: Updating attr cache...\n",
            "25/02/18 20:36:18 DEBUG MetricsSourceAdapter: Done. # tags & metrics=187\n",
            "25/02/18 20:36:18 DEBUG MetricsSourceAdapter: Updating info cache...\n",
            "25/02/18 20:36:18 DEBUG MetricsSystemImpl: [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=A unique identifier for the instance, name=tag.s3aFileSystemId, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Hostname from the FS URL, name=tag.bucket, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Total number of directories created through the object store., name=directories_created, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Total number of directories deleted through the object store., name=directories_deleted, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Total number of files copied within the object store., name=files_copied, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Total number of bytes copied within the object store., name=files_copied_bytes, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Total number of files created through the object store., name=files_created, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Total number of files deleted from the object store., name=files_deleted, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Total number of files whose delete request was rejected, name=files_delete_rejected, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Total number of fake directory entries created in the object store., name=fake_directories_created, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Total number of fake directory deletes submitted to object store., name=fake_directories_deleted, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Errors caught and ignored, name=ignored_errors, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of createNonRecursive(), name=op_create_non_recursive, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of hflush(), name=op_hflush, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of hsync(), name=op_hsync, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of listLocatedStatus(), name=op_list_located_status, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of open(), name=op_open, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Object copy requests, name=object_copy_requests, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Objects deleted in delete requests, name=object_delete_objects, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of requests for object metadata, name=object_metadata_request, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Object put/multipart upload completed count, name=object_put_request_completed, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=number of bytes uploaded, name=object_put_bytes, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of S3 Select requests issued, name=object_select_requests, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of times the TCP stream was aborted, name=stream_aborted, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Bytes read from an input stream in read() calls, name=stream_read_bytes, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of bytes discarded by aborting an input stream, name=stream_read_bytes_discarded_in_abort, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of bytes read and discarded when closing an input stream, name=stream_read_bytes_discarded_in_close, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of times the TCP stream was closed, name=stream_read_closed, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Total count of times an attempt to close an input stream was made, name=stream_read_close_operations, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of exceptions raised during input stream reads, name=stream_read_exceptions, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of readFully() operations in an input stream, name=stream_read_fully_operations, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Total count of times an input stream to object store data was opened, name=stream_read_opened, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of read() operations in an input stream, name=stream_read_operations, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of incomplete read() operations in an input stream, name=stream_read_operations_incomplete, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of version mismatches encountered while reading an input stream, name=stream_read_version_mismatches, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of executed seek operations which went backwards in a stream, name=stream_read_seek_backward_operations, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of bytes moved backwards during seek operations in an input stream, name=stream_read_bytes_backwards_on_seek, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of bytes read and discarded during seek() in an input stream, name=stream_read_seek_bytes_discarded, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of bytes skipped during forward seek operations an input stream, name=stream_read_seek_bytes_skipped, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of executed seek operations which went forward in an input stream, name=stream_read_seek_forward_operations, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of seek operations in an input stream, name=stream_read_seek_operations, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of times the seek policy was dynamically changed in an input stream, name=stream_read_seek_policy_changed, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Total count of bytes read from an input stream, name=stream_read_total_bytes, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of stream write failures reported, name=stream_write_exceptions, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of failures when finalizing a multipart upload, name=stream_write_exceptions_completing_upload, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of block/partition uploads completed, name=stream_write_block_uploads, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of number of block uploads committed, name=stream_write_block_uploads_committed, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of number of block uploads aborted, name=stream_write_block_uploads_aborted, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of total time taken for uploads to complete, name=stream_write_total_time, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of total data uploaded, name=stream_write_total_data, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of bytes written to output stream (including all not yet uploaded), name=stream_write_bytes, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of files to commit created, name=committer_commits_created, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of files committed, name=committer_commits_completed, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of successful jobs, name=committer_jobs_completed, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of failed jobs, name=committer_jobs_failed, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of successful tasks, name=committer_tasks_completed, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of failed tasks, name=committer_tasks_failed, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Amount of data committed, name=committer_bytes_committed, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of bytes uploaded duing commit operations, name=committer_bytes_uploaded, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of commits failed, name=committer_commits.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of commits aborted, name=committer_commits_aborted, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of commits reverted, name=committer_commits_reverted, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of files created under 'magic' paths, name=committer_magic_files_created, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=S3Guard metadata store put one metadata path request, name=s3guard_metadatastore_put_path_request, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=S3Guard metadata store initialization times, name=s3guard_metadatastore_initialization, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=S3Guard metadata store records deleted, name=s3guard_metadatastore_record_deletes, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=S3Guard metadata store records read, name=s3guard_metadatastore_record_reads, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=S3Guard metadata store records written, name=s3guard_metadatastore_record_writes, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=S3Guard metadata store retry events, name=s3guard_metadatastore_retry, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=S3Guard metadata store throttled events, name=s3guard_metadatastore_throttled, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=S3Guard metadata store authoritative directories updated from S3, name=s3guard_metadatastore_authoritative_directories_updated, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=requests made of the remote store, name=store_io_request, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=retried requests made of the remote store, name=store_io_retry, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Requests throttled and retried, name=store_io_throttled, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Multipart Uploader Instantiated, name=multipart_instantiated, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Multipart Part Put Operation, name=multipart_upload_part_put, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Multipart Part Put Bytes, name=multipart_upload_part_put_bytes, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Multipart Upload Aborted, name=multipart_upload_aborted, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Multipart Upload Abort Unner Path Invoked, name=multipart_upload_abort_under_path_invoked, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Multipart Upload Completed, name=multipart_upload_completed, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Multipart Upload Started, name=multipart_upload_started, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Audit access check was rejected, name=audit_access_check_failure, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Audit Span Created, name=audit_span_creation, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Audit failure/rejection, name=audit_failure, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=AWS request made, name=audit_request_execution, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Current number of active put requests, name=object_put_request_active, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=number of bytes queued for upload/being actively uploaded, name=object_put_bytes_pending, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of block/partition uploads active, name=stream_write_block_uploads_active, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Gauge of block/partitions uploads queued to be written, name=stream_write_block_uploads_pending, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Gauge of data queued to be written, name=stream_write_block_uploads_data_pending, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=gauge to indicate if client side encryption is enabled, name=client_side_encryption_enabled, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Executor acquired., name=action_executor_acquired, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Executor acquired., name=action_executor_acquired.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=HEAD request., name=action_http_head_request, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=HEAD request., name=action_http_head_request.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=GET request., name=action_http_get_request, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=GET request., name=action_http_get_request.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of abort(), name=op_abort, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of abort(), name=op_abort.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of access(), name=op_access, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of access(), name=op_access.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of copyFromLocalFile(), name=op_copy_from_local_file, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of copyFromLocalFile(), name=op_copy_from_local_file.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of create(), name=op_create, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of create(), name=op_create.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of delete(), name=op_delete, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of delete(), name=op_delete.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of exists(), name=op_exists, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of exists(), name=op_exists.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of getContentSummary(), name=op_get_content_summary, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of getContentSummary(), name=op_get_content_summary.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of getDelegationToken(), name=op_get_delegation_token, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of getDelegationToken(), name=op_get_delegation_token.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of getFileChecksum(), name=op_get_file_checksum, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of getFileChecksum(), name=op_get_file_checksum.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of getFileStatus(), name=op_get_file_status, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of getFileStatus(), name=op_get_file_status.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of globStatus(), name=op_glob_status, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of globStatus(), name=op_glob_status.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of isDirectory(), name=op_is_directory, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of isDirectory(), name=op_is_directory.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of isFile(), name=op_is_file, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of isFile(), name=op_is_file.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of listFiles(), name=op_list_files, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of listFiles(), name=op_list_files.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of listStatus(), name=op_list_status, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of listStatus(), name=op_list_status.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of mkdirs(), name=op_mkdirs, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of mkdirs(), name=op_mkdirs.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of rename(), name=op_rename, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of rename(), name=op_rename.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of getXAttrs(Path path), name=op_xattr_get_map, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of getXAttrs(Path path), name=op_xattr_get_map.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of getXAttr(Path, String), name=op_xattr_get_named, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of getXAttr(Path, String), name=op_xattr_get_named.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of xattr(), name=op_xattr_get_named_map, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of xattr(), name=op_xattr_get_named_map.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of getXAttrs(Path path, List<String> names), name=op_xattr_list, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of getXAttrs(Path path, List<String> names), name=op_xattr_list.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Object delete requests, name=object_delete_request, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Object delete requests, name=object_delete_request.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Object bulk delete requests, name=object_bulk_delete_request, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Object bulk delete requests, name=object_bulk_delete_request.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of object listings made, name=object_list_request, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of object listings made, name=object_list_request.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of continued object listings made, name=object_continue_list_request, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of continued object listings made, name=object_continue_list_request.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Object multipart upload initiated, name=object_multipart_initiated, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Object multipart upload initiated, name=object_multipart_initiated.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Object multipart upload aborted, name=object_multipart_aborted, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Object multipart upload aborted, name=object_multipart_aborted.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Object put/multipart upload count, name=object_put_request, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Object put/multipart upload count, name=object_put_request.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Total queue duration of all block uploads, name=stream_write_queue_duration, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Total queue duration of all block uploads, name=stream_write_queue_duration.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Duration Tracking of time to commit an entire job, name=committer_commit_job, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Duration Tracking of time to commit an entire job, name=committer_commit_job.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Duration Tracking of time to materialize a file in job commit, name=committer_materialize_file, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Duration Tracking of time to materialize a file in job commit, name=committer_materialize_file.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Duration Tracking of files uploaded from a local staging path, name=committer_stage_file_upload, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Duration Tracking of files uploaded from a local staging path, name=committer_stage_file_upload.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Store Existence Probe, name=store_exists_probe, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Store Existence Probe, name=store_exists_probe.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of delegation tokens issued, name=delegation_tokens_issued, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of delegation tokens issued, name=delegation_tokens_issued.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Multipart Upload List, name=multipart_upload_list, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Multipart Upload List, name=multipart_upload_list.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for s3Guard metadata store put one metadata path latency with 1s interval, name=S3guard_metadatastore_put_path_latencyNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=50 percentile latency with 1 second interval for s3Guard metadata store put one metadata path latency, name=S3guard_metadatastore_put_path_latency50thPercentileLatency, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=75 percentile latency with 1 second interval for s3Guard metadata store put one metadata path latency, name=S3guard_metadatastore_put_path_latency75thPercentileLatency, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=90 percentile latency with 1 second interval for s3Guard metadata store put one metadata path latency, name=S3guard_metadatastore_put_path_latency90thPercentileLatency, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=95 percentile latency with 1 second interval for s3Guard metadata store put one metadata path latency, name=S3guard_metadatastore_put_path_latency95thPercentileLatency, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=99 percentile latency with 1 second interval for s3Guard metadata store put one metadata path latency, name=S3guard_metadatastore_put_path_latency99thPercentileLatency, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of events for s3Guard metadata store throttle rate with 1s interval, name=S3guard_metadatastore_throttle_rateNumEvents, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=50 percentile frequency (Hz) with 1 second interval for s3Guard metadata store throttle rate, name=S3guard_metadatastore_throttle_rate50thPercentileFrequency (Hz), type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=75 percentile frequency (Hz) with 1 second interval for s3Guard metadata store throttle rate, name=S3guard_metadatastore_throttle_rate75thPercentileFrequency (Hz), type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=90 percentile frequency (Hz) with 1 second interval for s3Guard metadata store throttle rate, name=S3guard_metadatastore_throttle_rate90thPercentileFrequency (Hz), type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=95 percentile frequency (Hz) with 1 second interval for s3Guard metadata store throttle rate, name=S3guard_metadatastore_throttle_rate95thPercentileFrequency (Hz), type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=99 percentile frequency (Hz) with 1 second interval for s3Guard metadata store throttle rate, name=S3guard_metadatastore_throttle_rate99thPercentileFrequency (Hz), type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of events for rate of S3 request throttling with 1s interval, name=Store_io_throttle_rateNumEvents, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=50 percentile frequency (Hz) with 1 second interval for rate of S3 request throttling, name=Store_io_throttle_rate50thPercentileFrequency (Hz), type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=75 percentile frequency (Hz) with 1 second interval for rate of S3 request throttling, name=Store_io_throttle_rate75thPercentileFrequency (Hz), type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=90 percentile frequency (Hz) with 1 second interval for rate of S3 request throttling, name=Store_io_throttle_rate90thPercentileFrequency (Hz), type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=95 percentile frequency (Hz) with 1 second interval for rate of S3 request throttling, name=Store_io_throttle_rate95thPercentileFrequency (Hz), type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=99 percentile frequency (Hz) with 1 second interval for rate of S3 request throttling, name=Store_io_throttle_rate99thPercentileFrequency (Hz), type=java.lang.Long, read-only, descriptor={}]]\n",
            "25/02/18 20:36:18 DEBUG MetricsSourceAdapter: Done\n",
            "25/02/18 20:36:18 DEBUG MBeans: Registered Hadoop:service=s3a-file-system,name=S3AMetrics3-wba\n",
            "25/02/18 20:36:18 DEBUG MetricsSourceAdapter: MBean for source S3AMetrics3-wba registered.\n",
            "25/02/18 20:36:18 DEBUG MetricsSystemImpl: Registered source S3AMetrics3-wba\n",
            "25/02/18 20:36:18 DEBUG S3AFileSystem: Client Side Encryption enabled: false\n",
            "25/02/18 20:36:18 DEBUG S3ARetryPolicy: Retrying on recoverable AWS failures 7 times with an initial interval of 500ms\n",
            "25/02/18 20:36:18 DEBUG S3GuardExistsRetryPolicy: Retrying on recoverable S3Guard table/S3 inconsistencies 7 times with an initial interval of 2000ms\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Value of fs.s3a.paging.maximum is 5000\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Value of fs.s3a.block.size is 33554432\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Value of fs.s3a.readahead.range is 65536\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Value of fs.s3a.max.total.tasks is 32\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Value of fs.s3a.threads.keepalivetime is 60\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Value of fs.s3a.executor.capacity is 16\n",
            "25/02/18 20:36:18 DEBUG SignerManager: No custom signers specified\n",
            "25/02/18 20:36:18 DEBUG AuditIntegration: auditing is disabled\n",
            "25/02/18 20:36:18 DEBUG AbstractService: Service: NoopAuditManagerS3A entered state INITED\n",
            "25/02/18 20:36:18 DEBUG CompositeService: NoopAuditManagerS3A: initing services, size=0\n",
            "25/02/18 20:36:18 DEBUG CompositeService: Adding service NoopAuditor\n",
            "25/02/18 20:36:18 DEBUG AbstractService: Service: NoopAuditor entered state INITED\n",
            "25/02/18 20:36:18 DEBUG CompositeService: NoopAuditManagerS3A: starting services, size=1\n",
            "25/02/18 20:36:18 DEBUG AbstractService: Service NoopAuditor is started\n",
            "25/02/18 20:36:18 DEBUG AbstractService: Service NoopAuditManagerS3A is started\n",
            "25/02/18 20:36:18 DEBUG AuditIntegration: Started Audit Manager Service NoopAuditManagerS3A in state NoopAuditManagerS3A: STARTED\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Value of fs.s3a.internal.upload.part.count.limit is 10000\n",
            "25/02/18 20:36:18 DEBUG S3ARetryPolicy: Retrying on recoverable AWS failures 7 times with an initial interval of 500ms\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Credential provider class is org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: For URI s3a://wba/test.parquet, using credentials AWSCredentialProviderList[refcount= 1: [SimpleAWSCredentialsProvider]\n",
            "25/02/18 20:36:18 DEBUG S3AFileSystem: Using credential provider AWSCredentialProviderList[refcount= 1: [SimpleAWSCredentialsProvider]\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Value of fs.s3a.connection.maximum is 1\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Value of fs.s3a.attempts.maximum is 1\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Value of fs.s3a.connection.establish.timeout is 5000\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Value of fs.s3a.connection.timeout is 5000\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Value of fs.s3a.socket.send.buffer is 8192\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Value of fs.s3a.socket.recv.buffer is 8192\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Using User-Agent: Hadoop 3.3.4\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Data is unencrypted\n",
            "25/02/18 20:36:18 DEBUG DefaultS3ClientFactory: Creating endpoint configuration for \"http://localhost:9000\"\n",
            "25/02/18 20:36:18 DEBUG DefaultS3ClientFactory: Endpoint URI = http://localhost:9000\n",
            "25/02/18 20:36:18 DEBUG DefaultS3ClientFactory: Endpoint http://localhost:9000 is not the default; parsing\n",
            "25/02/18 20:36:18 DEBUG DefaultS3ClientFactory: Region for endpoint http://localhost:9000, URI http://localhost:9000 is determined as null\n",
            "25/02/18 20:36:18 DEBUG CsmConfigurationProviderChain: Unable to load configuration from com.amazonaws.monitoring.EnvironmentVariableCsmConfigurationProvider@5c98d4e4: Unable to load Client Side Monitoring configurations from environment variables!\n",
            "25/02/18 20:36:18 DEBUG CsmConfigurationProviderChain: Unable to load configuration from com.amazonaws.monitoring.SystemPropertyCsmConfigurationProvider@6480ba75: Unable to load Client Side Monitoring configurations from system properties variables!\n",
            "25/02/18 20:36:18 DEBUG CsmConfigurationProviderChain: Unable to load configuration from com.amazonaws.monitoring.ProfileCsmConfigurationProvider@722b6601: Could not find the 'default' profile!\n",
            "25/02/18 20:36:18 DEBUG S3AFileSystem: skipping check for bucket existence\n",
            "25/02/18 20:36:18 DEBUG S3AFileSystem: Input fadvise policy = normal\n",
            "25/02/18 20:36:18 DEBUG S3AFileSystem: Change detection policy = ETagChangeDetectionPolicy mode=Server\n",
            "25/02/18 20:36:18 DEBUG S3AFileSystem: Filesystem support for magic committers is enabled\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Value of fs.s3a.fast.upload.active.blocks is 4\n",
            "25/02/18 20:36:18 DEBUG S3AFileSystem: Using S3ABlockOutputStream with buffer = disk; block=104857600; queue limit=4\n",
            "25/02/18 20:36:18 DEBUG S3Guard: Metastore option source [core-default.xml]\n",
            "25/02/18 20:36:18 DEBUG S3Guard: Using NullMetadataStore metadata store for s3a filesystem\n",
            "25/02/18 20:36:18 DEBUG S3AFileSystem: S3Guard is disabled on this bucket: wba\n",
            "25/02/18 20:36:18 DEBUG DirectoryPolicyImpl: Directory markers will be deleted\n",
            "25/02/18 20:36:18 DEBUG S3AFileSystem: Directory marker retention policy is DirectoryMarkerRetention{policy='delete'}\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Value of fs.s3a.multipart.purge.age is 86400\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Value of fs.s3a.bulk.delete.page.size is 250\n",
            "25/02/18 20:36:18 DEBUG FileSystem: Creating FS s3a://wba/test.parquet: duration 0:00.014s\n",
            "25/02/18 20:36:18 DEBUG FileSystem: Bypassing cache to create filesystem s3a://wba/test.parquet\n",
            "25/02/18 20:36:18 DEBUG FileSystem: Starting: Creating FS s3a://wba/test.parquet\n",
            "25/02/18 20:36:18 DEBUG FileSystem: Looking for FS supporting s3a\n",
            "25/02/18 20:36:18 DEBUG FileSystem: looking for configuration option fs.s3a.impl\n",
            "25/02/18 20:36:18 DEBUG FileSystem: Filesystem s3a defined in configuration option\n",
            "25/02/18 20:36:18 DEBUG FileSystem: FS for s3a is class org.apache.hadoop.fs.s3a.S3AFileSystem\n",
            "25/02/18 20:36:18 DEBUG S3AFileSystem: Initializing S3AFileSystem for wba\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Propagating entries under fs.s3a.bucket.wba.\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Data is unencrypted\n",
            "25/02/18 20:36:18 DEBUG S3ARetryPolicy: Retrying on recoverable AWS failures 7 times with an initial interval of 500ms\n",
            "25/02/18 20:36:18 DEBUG MetricsSystemImpl: S3AMetrics4-wba, \n",
            "25/02/18 20:36:18 DEBUG MetricsConfig: poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans\n",
            "25/02/18 20:36:18 DEBUG MetricsConfig: poking parent 'MetricsConfig' for key: source.start_mbeans\n",
            "25/02/18 20:36:18 DEBUG MetricsConfig: poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans\n",
            "25/02/18 20:36:18 DEBUG MetricsSourceAdapter: Updating attr cache...\n",
            "25/02/18 20:36:18 DEBUG MetricsSourceAdapter: Done. # tags & metrics=187\n",
            "25/02/18 20:36:18 DEBUG MetricsSourceAdapter: Updating info cache...\n",
            "25/02/18 20:36:18 DEBUG MetricsSystemImpl: [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=A unique identifier for the instance, name=tag.s3aFileSystemId, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Hostname from the FS URL, name=tag.bucket, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Total number of directories created through the object store., name=directories_created, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Total number of directories deleted through the object store., name=directories_deleted, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Total number of files copied within the object store., name=files_copied, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Total number of bytes copied within the object store., name=files_copied_bytes, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Total number of files created through the object store., name=files_created, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Total number of files deleted from the object store., name=files_deleted, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Total number of files whose delete request was rejected, name=files_delete_rejected, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Total number of fake directory entries created in the object store., name=fake_directories_created, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Total number of fake directory deletes submitted to object store., name=fake_directories_deleted, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Errors caught and ignored, name=ignored_errors, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of createNonRecursive(), name=op_create_non_recursive, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of hflush(), name=op_hflush, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of hsync(), name=op_hsync, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of listLocatedStatus(), name=op_list_located_status, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of open(), name=op_open, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Object copy requests, name=object_copy_requests, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Objects deleted in delete requests, name=object_delete_objects, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of requests for object metadata, name=object_metadata_request, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Object put/multipart upload completed count, name=object_put_request_completed, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=number of bytes uploaded, name=object_put_bytes, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of S3 Select requests issued, name=object_select_requests, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of times the TCP stream was aborted, name=stream_aborted, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Bytes read from an input stream in read() calls, name=stream_read_bytes, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of bytes discarded by aborting an input stream, name=stream_read_bytes_discarded_in_abort, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of bytes read and discarded when closing an input stream, name=stream_read_bytes_discarded_in_close, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of times the TCP stream was closed, name=stream_read_closed, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Total count of times an attempt to close an input stream was made, name=stream_read_close_operations, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of exceptions raised during input stream reads, name=stream_read_exceptions, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of readFully() operations in an input stream, name=stream_read_fully_operations, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Total count of times an input stream to object store data was opened, name=stream_read_opened, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of read() operations in an input stream, name=stream_read_operations, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of incomplete read() operations in an input stream, name=stream_read_operations_incomplete, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of version mismatches encountered while reading an input stream, name=stream_read_version_mismatches, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of executed seek operations which went backwards in a stream, name=stream_read_seek_backward_operations, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of bytes moved backwards during seek operations in an input stream, name=stream_read_bytes_backwards_on_seek, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of bytes read and discarded during seek() in an input stream, name=stream_read_seek_bytes_discarded, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of bytes skipped during forward seek operations an input stream, name=stream_read_seek_bytes_skipped, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of executed seek operations which went forward in an input stream, name=stream_read_seek_forward_operations, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of seek operations in an input stream, name=stream_read_seek_operations, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of times the seek policy was dynamically changed in an input stream, name=stream_read_seek_policy_changed, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Total count of bytes read from an input stream, name=stream_read_total_bytes, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of stream write failures reported, name=stream_write_exceptions, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of failures when finalizing a multipart upload, name=stream_write_exceptions_completing_upload, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of block/partition uploads completed, name=stream_write_block_uploads, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of number of block uploads committed, name=stream_write_block_uploads_committed, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of number of block uploads aborted, name=stream_write_block_uploads_aborted, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of total time taken for uploads to complete, name=stream_write_total_time, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of total data uploaded, name=stream_write_total_data, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of bytes written to output stream (including all not yet uploaded), name=stream_write_bytes, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of files to commit created, name=committer_commits_created, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of files committed, name=committer_commits_completed, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of successful jobs, name=committer_jobs_completed, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of failed jobs, name=committer_jobs_failed, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of successful tasks, name=committer_tasks_completed, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of failed tasks, name=committer_tasks_failed, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Amount of data committed, name=committer_bytes_committed, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of bytes uploaded duing commit operations, name=committer_bytes_uploaded, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of commits failed, name=committer_commits.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of commits aborted, name=committer_commits_aborted, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of commits reverted, name=committer_commits_reverted, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of files created under 'magic' paths, name=committer_magic_files_created, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=S3Guard metadata store put one metadata path request, name=s3guard_metadatastore_put_path_request, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=S3Guard metadata store initialization times, name=s3guard_metadatastore_initialization, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=S3Guard metadata store records deleted, name=s3guard_metadatastore_record_deletes, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=S3Guard metadata store records read, name=s3guard_metadatastore_record_reads, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=S3Guard metadata store records written, name=s3guard_metadatastore_record_writes, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=S3Guard metadata store retry events, name=s3guard_metadatastore_retry, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=S3Guard metadata store throttled events, name=s3guard_metadatastore_throttled, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=S3Guard metadata store authoritative directories updated from S3, name=s3guard_metadatastore_authoritative_directories_updated, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=requests made of the remote store, name=store_io_request, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=retried requests made of the remote store, name=store_io_retry, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Requests throttled and retried, name=store_io_throttled, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Multipart Uploader Instantiated, name=multipart_instantiated, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Multipart Part Put Operation, name=multipart_upload_part_put, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Multipart Part Put Bytes, name=multipart_upload_part_put_bytes, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Multipart Upload Aborted, name=multipart_upload_aborted, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Multipart Upload Abort Unner Path Invoked, name=multipart_upload_abort_under_path_invoked, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Multipart Upload Completed, name=multipart_upload_completed, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Multipart Upload Started, name=multipart_upload_started, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Audit access check was rejected, name=audit_access_check_failure, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Audit Span Created, name=audit_span_creation, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Audit failure/rejection, name=audit_failure, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=AWS request made, name=audit_request_execution, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Current number of active put requests, name=object_put_request_active, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=number of bytes queued for upload/being actively uploaded, name=object_put_bytes_pending, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of block/partition uploads active, name=stream_write_block_uploads_active, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Gauge of block/partitions uploads queued to be written, name=stream_write_block_uploads_pending, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Gauge of data queued to be written, name=stream_write_block_uploads_data_pending, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=gauge to indicate if client side encryption is enabled, name=client_side_encryption_enabled, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Executor acquired., name=action_executor_acquired, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Executor acquired., name=action_executor_acquired.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=HEAD request., name=action_http_head_request, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=HEAD request., name=action_http_head_request.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=GET request., name=action_http_get_request, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=GET request., name=action_http_get_request.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of abort(), name=op_abort, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of abort(), name=op_abort.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of access(), name=op_access, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of access(), name=op_access.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of copyFromLocalFile(), name=op_copy_from_local_file, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of copyFromLocalFile(), name=op_copy_from_local_file.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of create(), name=op_create, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of create(), name=op_create.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of delete(), name=op_delete, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of delete(), name=op_delete.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of exists(), name=op_exists, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of exists(), name=op_exists.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of getContentSummary(), name=op_get_content_summary, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of getContentSummary(), name=op_get_content_summary.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of getDelegationToken(), name=op_get_delegation_token, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of getDelegationToken(), name=op_get_delegation_token.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of getFileChecksum(), name=op_get_file_checksum, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of getFileChecksum(), name=op_get_file_checksum.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of getFileStatus(), name=op_get_file_status, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of getFileStatus(), name=op_get_file_status.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of globStatus(), name=op_glob_status, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of globStatus(), name=op_glob_status.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of isDirectory(), name=op_is_directory, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of isDirectory(), name=op_is_directory.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of isFile(), name=op_is_file, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of isFile(), name=op_is_file.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of listFiles(), name=op_list_files, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of listFiles(), name=op_list_files.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of listStatus(), name=op_list_status, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of listStatus(), name=op_list_status.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of mkdirs(), name=op_mkdirs, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of mkdirs(), name=op_mkdirs.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of rename(), name=op_rename, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of rename(), name=op_rename.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of getXAttrs(Path path), name=op_xattr_get_map, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of getXAttrs(Path path), name=op_xattr_get_map.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of getXAttr(Path, String), name=op_xattr_get_named, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of getXAttr(Path, String), name=op_xattr_get_named.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of xattr(), name=op_xattr_get_named_map, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of xattr(), name=op_xattr_get_named_map.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of getXAttrs(Path path, List<String> names), name=op_xattr_list, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Calls of getXAttrs(Path path, List<String> names), name=op_xattr_list.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Object delete requests, name=object_delete_request, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Object delete requests, name=object_delete_request.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Object bulk delete requests, name=object_bulk_delete_request, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Object bulk delete requests, name=object_bulk_delete_request.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of object listings made, name=object_list_request, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of object listings made, name=object_list_request.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of continued object listings made, name=object_continue_list_request, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of continued object listings made, name=object_continue_list_request.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Object multipart upload initiated, name=object_multipart_initiated, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Object multipart upload initiated, name=object_multipart_initiated.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Object multipart upload aborted, name=object_multipart_aborted, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Object multipart upload aborted, name=object_multipart_aborted.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Object put/multipart upload count, name=object_put_request, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Object put/multipart upload count, name=object_put_request.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Total queue duration of all block uploads, name=stream_write_queue_duration, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Total queue duration of all block uploads, name=stream_write_queue_duration.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Duration Tracking of time to commit an entire job, name=committer_commit_job, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Duration Tracking of time to commit an entire job, name=committer_commit_job.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Duration Tracking of time to materialize a file in job commit, name=committer_materialize_file, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Duration Tracking of time to materialize a file in job commit, name=committer_materialize_file.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Duration Tracking of files uploaded from a local staging path, name=committer_stage_file_upload, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Duration Tracking of files uploaded from a local staging path, name=committer_stage_file_upload.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Store Existence Probe, name=store_exists_probe, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Store Existence Probe, name=store_exists_probe.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of delegation tokens issued, name=delegation_tokens_issued, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Count of delegation tokens issued, name=delegation_tokens_issued.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Multipart Upload List, name=multipart_upload_list, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Multipart Upload List, name=multipart_upload_list.failures, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for s3Guard metadata store put one metadata path latency with 1s interval, name=S3guard_metadatastore_put_path_latencyNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=50 percentile latency with 1 second interval for s3Guard metadata store put one metadata path latency, name=S3guard_metadatastore_put_path_latency50thPercentileLatency, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=75 percentile latency with 1 second interval for s3Guard metadata store put one metadata path latency, name=S3guard_metadatastore_put_path_latency75thPercentileLatency, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=90 percentile latency with 1 second interval for s3Guard metadata store put one metadata path latency, name=S3guard_metadatastore_put_path_latency90thPercentileLatency, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=95 percentile latency with 1 second interval for s3Guard metadata store put one metadata path latency, name=S3guard_metadatastore_put_path_latency95thPercentileLatency, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=99 percentile latency with 1 second interval for s3Guard metadata store put one metadata path latency, name=S3guard_metadatastore_put_path_latency99thPercentileLatency, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of events for s3Guard metadata store throttle rate with 1s interval, name=S3guard_metadatastore_throttle_rateNumEvents, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=50 percentile frequency (Hz) with 1 second interval for s3Guard metadata store throttle rate, name=S3guard_metadatastore_throttle_rate50thPercentileFrequency (Hz), type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=75 percentile frequency (Hz) with 1 second interval for s3Guard metadata store throttle rate, name=S3guard_metadatastore_throttle_rate75thPercentileFrequency (Hz), type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=90 percentile frequency (Hz) with 1 second interval for s3Guard metadata store throttle rate, name=S3guard_metadatastore_throttle_rate90thPercentileFrequency (Hz), type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=95 percentile frequency (Hz) with 1 second interval for s3Guard metadata store throttle rate, name=S3guard_metadatastore_throttle_rate95thPercentileFrequency (Hz), type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=99 percentile frequency (Hz) with 1 second interval for s3Guard metadata store throttle rate, name=S3guard_metadatastore_throttle_rate99thPercentileFrequency (Hz), type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of events for rate of S3 request throttling with 1s interval, name=Store_io_throttle_rateNumEvents, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=50 percentile frequency (Hz) with 1 second interval for rate of S3 request throttling, name=Store_io_throttle_rate50thPercentileFrequency (Hz), type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=75 percentile frequency (Hz) with 1 second interval for rate of S3 request throttling, name=Store_io_throttle_rate75thPercentileFrequency (Hz), type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=90 percentile frequency (Hz) with 1 second interval for rate of S3 request throttling, name=Store_io_throttle_rate90thPercentileFrequency (Hz), type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=95 percentile frequency (Hz) with 1 second interval for rate of S3 request throttling, name=Store_io_throttle_rate95thPercentileFrequency (Hz), type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=99 percentile frequency (Hz) with 1 second interval for rate of S3 request throttling, name=Store_io_throttle_rate99thPercentileFrequency (Hz), type=java.lang.Long, read-only, descriptor={}]]\n",
            "25/02/18 20:36:18 DEBUG MetricsSourceAdapter: Done\n",
            "25/02/18 20:36:18 DEBUG MBeans: Registered Hadoop:service=s3a-file-system,name=S3AMetrics4-wba\n",
            "25/02/18 20:36:18 DEBUG MetricsSourceAdapter: MBean for source S3AMetrics4-wba registered.\n",
            "25/02/18 20:36:18 DEBUG MetricsSystemImpl: Registered source S3AMetrics4-wba\n",
            "25/02/18 20:36:18 DEBUG S3AFileSystem: Client Side Encryption enabled: false\n",
            "25/02/18 20:36:18 DEBUG S3ARetryPolicy: Retrying on recoverable AWS failures 7 times with an initial interval of 500ms\n",
            "25/02/18 20:36:18 DEBUG S3GuardExistsRetryPolicy: Retrying on recoverable S3Guard table/S3 inconsistencies 7 times with an initial interval of 2000ms\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Value of fs.s3a.paging.maximum is 5000\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Value of fs.s3a.block.size is 33554432\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Value of fs.s3a.readahead.range is 65536\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Value of fs.s3a.max.total.tasks is 32\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Value of fs.s3a.threads.keepalivetime is 60\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Value of fs.s3a.executor.capacity is 16\n",
            "25/02/18 20:36:18 DEBUG SignerManager: No custom signers specified\n",
            "25/02/18 20:36:18 DEBUG AuditIntegration: auditing is disabled\n",
            "25/02/18 20:36:18 DEBUG AbstractService: Service: NoopAuditManagerS3A entered state INITED\n",
            "25/02/18 20:36:18 DEBUG CompositeService: NoopAuditManagerS3A: initing services, size=0\n",
            "25/02/18 20:36:18 DEBUG CompositeService: Adding service NoopAuditor\n",
            "25/02/18 20:36:18 DEBUG AbstractService: Service: NoopAuditor entered state INITED\n",
            "25/02/18 20:36:18 DEBUG CompositeService: NoopAuditManagerS3A: starting services, size=1\n",
            "25/02/18 20:36:18 DEBUG AbstractService: Service NoopAuditor is started\n",
            "25/02/18 20:36:18 DEBUG AbstractService: Service NoopAuditManagerS3A is started\n",
            "25/02/18 20:36:18 DEBUG AuditIntegration: Started Audit Manager Service NoopAuditManagerS3A in state NoopAuditManagerS3A: STARTED\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Value of fs.s3a.internal.upload.part.count.limit is 10000\n",
            "25/02/18 20:36:18 DEBUG S3ARetryPolicy: Retrying on recoverable AWS failures 7 times with an initial interval of 500ms\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Credential provider class is org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: For URI s3a://wba/test.parquet, using credentials AWSCredentialProviderList[refcount= 1: [SimpleAWSCredentialsProvider]\n",
            "25/02/18 20:36:18 DEBUG S3AFileSystem: Using credential provider AWSCredentialProviderList[refcount= 1: [SimpleAWSCredentialsProvider]\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Value of fs.s3a.connection.maximum is 1\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Value of fs.s3a.attempts.maximum is 1\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Value of fs.s3a.connection.establish.timeout is 5000\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Value of fs.s3a.connection.timeout is 5000\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Value of fs.s3a.socket.send.buffer is 8192\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Value of fs.s3a.socket.recv.buffer is 8192\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Using User-Agent: Hadoop 3.3.4\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Data is unencrypted\n",
            "25/02/18 20:36:18 DEBUG DefaultS3ClientFactory: Creating endpoint configuration for \"http://localhost:9000\"\n",
            "25/02/18 20:36:18 DEBUG DefaultS3ClientFactory: Endpoint URI = http://localhost:9000\n",
            "25/02/18 20:36:18 DEBUG DefaultS3ClientFactory: Endpoint http://localhost:9000 is not the default; parsing\n",
            "25/02/18 20:36:18 DEBUG DefaultS3ClientFactory: Region for endpoint http://localhost:9000, URI http://localhost:9000 is determined as null\n",
            "25/02/18 20:36:18 DEBUG CsmConfigurationProviderChain: Unable to load configuration from com.amazonaws.monitoring.EnvironmentVariableCsmConfigurationProvider@5c98d4e4: Unable to load Client Side Monitoring configurations from environment variables!\n",
            "25/02/18 20:36:18 DEBUG CsmConfigurationProviderChain: Unable to load configuration from com.amazonaws.monitoring.SystemPropertyCsmConfigurationProvider@6480ba75: Unable to load Client Side Monitoring configurations from system properties variables!\n",
            "25/02/18 20:36:18 DEBUG CsmConfigurationProviderChain: Unable to load configuration from com.amazonaws.monitoring.ProfileCsmConfigurationProvider@722b6601: Could not find the 'default' profile!\n",
            "25/02/18 20:36:18 DEBUG S3AFileSystem: skipping check for bucket existence\n",
            "25/02/18 20:36:18 DEBUG S3AFileSystem: Input fadvise policy = normal\n",
            "25/02/18 20:36:18 DEBUG S3AFileSystem: Change detection policy = ETagChangeDetectionPolicy mode=Server\n",
            "25/02/18 20:36:18 DEBUG S3AFileSystem: Filesystem support for magic committers is enabled\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Value of fs.s3a.fast.upload.active.blocks is 4\n",
            "25/02/18 20:36:18 DEBUG S3AFileSystem: Using S3ABlockOutputStream with buffer = disk; block=104857600; queue limit=4\n",
            "25/02/18 20:36:18 DEBUG S3Guard: Metastore option source [core-default.xml]\n",
            "25/02/18 20:36:18 DEBUG S3Guard: Using NullMetadataStore metadata store for s3a filesystem\n",
            "25/02/18 20:36:18 DEBUG S3AFileSystem: S3Guard is disabled on this bucket: wba\n",
            "25/02/18 20:36:18 DEBUG DirectoryPolicyImpl: Directory markers will be deleted\n",
            "25/02/18 20:36:18 DEBUG S3AFileSystem: Directory marker retention policy is DirectoryMarkerRetention{policy='delete'}\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Value of fs.s3a.multipart.purge.age is 86400\n",
            "25/02/18 20:36:18 DEBUG S3AUtils: Value of fs.s3a.bulk.delete.page.size is 250\n",
            "25/02/18 20:36:18 DEBUG FileSystem: Creating FS s3a://wba/test.parquet: duration 0:00.014s\n",
            "25/02/18 20:36:18 DEBUG FileCommitProtocol: Creating committer org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol; job dee6fce4-f747-4c73-97f5-6c92053e95a2; output=s3a://wba/test.parquet; dynamic=false\n",
            "25/02/18 20:36:18 DEBUG FileCommitProtocol: Using (String, String, Boolean) constructor\n",
            "25/02/18 20:36:18 DEBUG IOStatisticsStoreImpl: Incrementing counter op_exists by 1 with final value 1\n",
            "25/02/18 20:36:18 DEBUG S3AFileSystem: Getting path status for s3a://wba/test.parquet  (test.parquet); needEmptyDirectory=false\n",
            "25/02/18 20:36:18 DEBUG S3AFileSystem: S3GetFileStatus s3a://wba/test.parquet\n",
            "25/02/18 20:36:18 DEBUG IOStatisticsStoreImpl: Incrementing counter object_metadata_request by 1 with final value 1\n",
            "25/02/18 20:36:18 DEBUG IOStatisticsStoreImpl: Incrementing counter action_http_head_request by 1 with final value 1\n",
            "25/02/18 20:36:18 DEBUG S3AFileSystem: HEAD test.parquet with change tracker null\n",
            "25/02/18 20:36:18 DEBUG AWSCredentialProviderList: Using credentials from SimpleAWSCredentialsProvider\n",
            "25/02/18 20:36:18 DEBUG request: Sending Request: HEAD http://localhost:9000 /wba/test.parquet Headers: (amz-sdk-invocation-id: 774a7502-7a66-5eba-cee1-eee8488196c9, Content-Type: application/octet-stream, User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy, ) \n",
            "25/02/18 20:36:18 DEBUG AWS4Signer: AWS4 Canonical Request: '\"HEAD\n",
            "/wba/test.parquet\n",
            "\n",
            "amz-sdk-invocation-id:774a7502-7a66-5eba-cee1-eee8488196c9\n",
            "amz-sdk-request:attempt=1;max=2\n",
            "amz-sdk-retry:0/0/500\n",
            "content-type:application/octet-stream\n",
            "host:localhost:9000\n",
            "user-agent:Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy\n",
            "x-amz-content-sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "x-amz-date:20250218T203618Z\n",
            "\n",
            "amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date\n",
            "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\"\n",
            "25/02/18 20:36:18 DEBUG AWS4Signer: AWS4 String to Sign: '\"AWS4-HMAC-SHA256\n",
            "20250218T203618Z\n",
            "20250218/us-east-1/s3/aws4_request\n",
            "e873ffe1f6b9d17acec26e8fb4f2d7b0e9b910dc758423d602bf203e81190779\"\n",
            "25/02/18 20:36:18 DEBUG RequestAddCookies: CookieSpec selected: default\n",
            "25/02/18 20:36:18 DEBUG RequestAuthCache: Auth cache not set in the context\n",
            "25/02/18 20:36:18 DEBUG PoolingHttpClientConnectionManager: Connection request: [route: {}->http://localhost:9000][total available: 0; route allocated: 0 of 1; total allocated: 0 of 1]\n",
            "25/02/18 20:36:18 DEBUG PoolingHttpClientConnectionManager: Connection leased: [id: 12][route: {}->http://localhost:9000][total available: 0; route allocated: 1 of 1; total allocated: 1 of 1]\n",
            "25/02/18 20:36:18 DEBUG MainClientExec: Opening connection {}->http://localhost:9000\n",
            "25/02/18 20:36:18 DEBUG DefaultHttpClientConnectionOperator: Connecting to localhost/127.0.0.1:9000\n",
            "25/02/18 20:36:18 DEBUG DefaultHttpClientConnectionOperator: Connection established 127.0.0.1:40914<->127.0.0.1:9000\n",
            "25/02/18 20:36:18 DEBUG DefaultManagedHttpClientConnection: http-outgoing-12: set socket timeout to 5000\n",
            "25/02/18 20:36:18 DEBUG MainClientExec: Executing request HEAD /wba/test.parquet HTTP/1.1\n",
            "25/02/18 20:36:18 DEBUG MainClientExec: Proxy auth state: UNCHALLENGED\n",
            "25/02/18 20:36:18 DEBUG headers: http-outgoing-12 >> HEAD /wba/test.parquet HTTP/1.1\n",
            "25/02/18 20:36:18 DEBUG headers: http-outgoing-12 >> Host: localhost:9000\n",
            "25/02/18 20:36:18 DEBUG headers: http-outgoing-12 >> amz-sdk-invocation-id: 774a7502-7a66-5eba-cee1-eee8488196c9\n",
            "25/02/18 20:36:18 DEBUG headers: http-outgoing-12 >> amz-sdk-request: attempt=1;max=2\n",
            "25/02/18 20:36:18 DEBUG headers: http-outgoing-12 >> amz-sdk-retry: 0/0/500\n",
            "25/02/18 20:36:18 DEBUG headers: http-outgoing-12 >> Authorization: AWS4-HMAC-SHA256 Credential=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=4a6d2207480ee670353670332a04c3183d52a7d6ecf3b6b2fb891d9c1c0e3258\n",
            "25/02/18 20:36:18 DEBUG headers: http-outgoing-12 >> Content-Type: application/octet-stream\n",
            "25/02/18 20:36:18 DEBUG headers: http-outgoing-12 >> User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy\n",
            "25/02/18 20:36:18 DEBUG headers: http-outgoing-12 >> x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "25/02/18 20:36:18 DEBUG headers: http-outgoing-12 >> X-Amz-Date: 20250218T203618Z\n",
            "25/02/18 20:36:18 DEBUG headers: http-outgoing-12 >> Connection: Keep-Alive\n",
            "25/02/18 20:36:18 DEBUG wire: http-outgoing-12 >> \"HEAD /wba/test.parquet HTTP/1.1[\\r][\\n]\"\n",
            "25/02/18 20:36:18 DEBUG wire: http-outgoing-12 >> \"Host: localhost:9000[\\r][\\n]\"\n",
            "25/02/18 20:36:18 DEBUG wire: http-outgoing-12 >> \"amz-sdk-invocation-id: 774a7502-7a66-5eba-cee1-eee8488196c9[\\r][\\n]\"\n",
            "25/02/18 20:36:18 DEBUG wire: http-outgoing-12 >> \"amz-sdk-request: attempt=1;max=2[\\r][\\n]\"\n",
            "25/02/18 20:36:18 DEBUG wire: http-outgoing-12 >> \"amz-sdk-retry: 0/0/500[\\r][\\n]\"\n",
            "25/02/18 20:36:18 DEBUG wire: http-outgoing-12 >> \"Authorization: AWS4-HMAC-SHA256 Credential=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=4a6d2207480ee670353670332a04c3183d52a7d6ecf3b6b2fb891d9c1c0e3258[\\r][\\n]\"\n",
            "25/02/18 20:36:18 DEBUG wire: http-outgoing-12 >> \"Content-Type: application/octet-stream[\\r][\\n]\"\n",
            "25/02/18 20:36:18 DEBUG wire: http-outgoing-12 >> \"User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy[\\r][\\n]\"\n",
            "25/02/18 20:36:18 DEBUG wire: http-outgoing-12 >> \"x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855[\\r][\\n]\"\n",
            "25/02/18 20:36:18 DEBUG wire: http-outgoing-12 >> \"X-Amz-Date: 20250218T203618Z[\\r][\\n]\"\n",
            "25/02/18 20:36:18 DEBUG wire: http-outgoing-12 >> \"Connection: Keep-Alive[\\r][\\n]\"\n",
            "25/02/18 20:36:18 DEBUG wire: http-outgoing-12 >> \"[\\r][\\n]\"\n",
            "25/02/18 20:36:18 DEBUG wire: http-outgoing-12 << \"[0xff][0x0][0x0][0x0][0x0][0x0][0x0][0x0][0x1]\"\n",
            "25/02/18 20:36:18 DEBUG wire: http-outgoing-12 << \"-[0x1]d: 774a7502-7a66-5eba-cee1-eee8488196c9[\\r][\\n]\"\n",
            "25/02/18 20:36:18 DEBUG wire: http-outgoing-12 << \"amz-[0x1]dk-request: attempt=1;max=2[\\r][\\n]\"\n",
            "25/02/18 20:36:18 DEBUG wire: http-outgoing-12 << \"amz-sdk-retry: 0[0x1]0/500[\\r][\\n]\"\n",
            "25/02/18 20:36:18 DEBUG wire: http-outgoing-12 << \"Authorization: AWS4-HMAC-SHA256 Credentia[0x0]=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-reque[0x1]t;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=4a6d2207480ee[0x0]70353670332a04c3183d52a7d6ecf3b6b2fb891d9c1c0e3258[\\r][\\n]\"\n",
            "25/02/18 20:36:18 DEBUG wire: http-outgoing-12 << \"Content-Type: application/octet-stream[\\r][\\n]\"\n",
            "25/02/18 20:36:18 DEBUG wire: http-outgoing-12 << \"User-Agen[0x0]: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.1[0x0]+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 ven[0x0]or/Debian cfg/retry-mode/legacy[\\r][\\n]\"\n",
            "25/02/18 20:36:18 DEBUG wire: http-outgoing-12 << \"x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991[0x0]7852b855[\\r][\\n]\"\n",
            "25/02/18 20:36:18 DEBUG wire: http-outgoing-12 << \"X-Amz-Date: 20250218T203618Z[\\r][\\n]\"\n",
            "25/02/18 20:36:18 DEBUG wire: http-outgoing-12 << \"Connecti\"\n",
            "25/02/18 20:36:18 DEBUG DefaultHttpResponseParser: Garbage in response: \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0001-\u0001d: 774a7502-7a66-5eba-cee1-eee8488196c9\n",
            "25/02/18 20:36:18 DEBUG DefaultHttpResponseParser: Garbage in response: amz-\u0001dk-request: attempt=1;max=2\n",
            "25/02/18 20:36:18 DEBUG DefaultHttpResponseParser: Garbage in response: amz-sdk-retry: 0\u00010/500\n",
            "25/02/18 20:36:18 DEBUG DefaultHttpResponseParser: Garbage in response: Authorization: AWS4-HMAC-SHA256 Credentia\u0000=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-reque\u0001t;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=4a6d2207480ee\u000070353670332a04c3183d52a7d6ecf3b6b2fb891d9c1c0e3258\n",
            "25/02/18 20:36:18 DEBUG DefaultHttpResponseParser: Garbage in response: Content-Type: application/octet-stream\n",
            "25/02/18 20:36:18 DEBUG DefaultHttpResponseParser: Garbage in response: User-Agen\u0000: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.1\u0000+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 ven\u0000or/Debian cfg/retry-mode/legacy\n",
            "25/02/18 20:36:18 DEBUG DefaultHttpResponseParser: Garbage in response: x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991\u00007852b855\n",
            "25/02/18 20:36:18 DEBUG DefaultHttpResponseParser: Garbage in response: X-Amz-Date: 20250218T203618Z\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----+\n",
            "| id|name|\n",
            "+---+----+\n",
            "|  1|John|\n",
            "|  2|Jane|\n",
            "+---+----+\n",
            "\n",
            "Testing S3 connection with parquet write...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/02/18 20:36:23 DEBUG wire: http-outgoing-12 << \"[read] I/O error: Read timed out\"\n",
            "25/02/18 20:36:23 DEBUG DefaultManagedHttpClientConnection: http-outgoing-12: Close connection\n",
            "25/02/18 20:36:23 DEBUG DefaultManagedHttpClientConnection: http-outgoing-12: Shutdown connection\n",
            "25/02/18 20:36:23 DEBUG MainClientExec: Connection discarded\n",
            "25/02/18 20:36:23 DEBUG PoolingHttpClientConnectionManager: Connection released: [id: 12][route: {}->http://localhost:9000][total available: 0; route allocated: 0 of 1; total allocated: 0 of 1]\n",
            "25/02/18 20:36:23 DEBUG AmazonHttpClient: Unable to execute HTTP request: Read timed out Request will be retried.\n",
            "25/02/18 20:36:23 DEBUG request: Retrying Request: HEAD http://localhost:9000 /wba/test.parquet Headers: (amz-sdk-invocation-id: 774a7502-7a66-5eba-cee1-eee8488196c9, Content-Type: application/octet-stream, User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy, ) \n",
            "25/02/18 20:36:23 DEBUG AmazonHttpClient: Retriable error detected, will retry in 63ms, attempt number: 0\n",
            "25/02/18 20:36:23 DEBUG AWS4Signer: AWS4 Canonical Request: '\"HEAD\n",
            "/wba/test.parquet\n",
            "\n",
            "amz-sdk-invocation-id:774a7502-7a66-5eba-cee1-eee8488196c9\n",
            "amz-sdk-request:attempt=2;max=2\n",
            "amz-sdk-retry:1/63/495\n",
            "content-type:application/octet-stream\n",
            "host:localhost:9000\n",
            "user-agent:Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy\n",
            "x-amz-content-sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "x-amz-date:20250218T203623Z\n",
            "\n",
            "amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date\n",
            "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\"\n",
            "25/02/18 20:36:23 DEBUG AWS4Signer: AWS4 String to Sign: '\"AWS4-HMAC-SHA256\n",
            "20250218T203623Z\n",
            "20250218/us-east-1/s3/aws4_request\n",
            "77537c9fe987f868aa39c0946c6012adaf24814ce68df8d600fd373220f514b0\"\n",
            "25/02/18 20:36:23 DEBUG RequestAddCookies: CookieSpec selected: default\n",
            "25/02/18 20:36:23 DEBUG RequestAuthCache: Auth cache not set in the context\n",
            "25/02/18 20:36:23 DEBUG PoolingHttpClientConnectionManager: Connection request: [route: {}->http://localhost:9000][total available: 0; route allocated: 0 of 1; total allocated: 0 of 1]\n",
            "25/02/18 20:36:23 DEBUG PoolingHttpClientConnectionManager: Connection leased: [id: 13][route: {}->http://localhost:9000][total available: 0; route allocated: 1 of 1; total allocated: 1 of 1]\n",
            "25/02/18 20:36:23 DEBUG MainClientExec: Opening connection {}->http://localhost:9000\n",
            "25/02/18 20:36:23 DEBUG DefaultHttpClientConnectionOperator: Connecting to localhost/127.0.0.1:9000\n",
            "25/02/18 20:36:23 DEBUG DefaultHttpClientConnectionOperator: Connection established 127.0.0.1:40938<->127.0.0.1:9000\n",
            "25/02/18 20:36:23 DEBUG DefaultManagedHttpClientConnection: http-outgoing-13: set socket timeout to 5000\n",
            "25/02/18 20:36:23 DEBUG MainClientExec: Executing request HEAD /wba/test.parquet HTTP/1.1\n",
            "25/02/18 20:36:23 DEBUG MainClientExec: Proxy auth state: UNCHALLENGED\n",
            "25/02/18 20:36:23 DEBUG headers: http-outgoing-13 >> HEAD /wba/test.parquet HTTP/1.1\n",
            "25/02/18 20:36:23 DEBUG headers: http-outgoing-13 >> Host: localhost:9000\n",
            "25/02/18 20:36:23 DEBUG headers: http-outgoing-13 >> amz-sdk-invocation-id: 774a7502-7a66-5eba-cee1-eee8488196c9\n",
            "25/02/18 20:36:23 DEBUG headers: http-outgoing-13 >> amz-sdk-request: attempt=2;max=2\n",
            "25/02/18 20:36:23 DEBUG headers: http-outgoing-13 >> amz-sdk-retry: 1/63/495\n",
            "25/02/18 20:36:23 DEBUG headers: http-outgoing-13 >> Authorization: AWS4-HMAC-SHA256 Credential=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=4c8c93519ce253356dc7a74a31a10fb4e9ac6d59b173b3cd64631f201cd21025\n",
            "25/02/18 20:36:23 DEBUG headers: http-outgoing-13 >> Content-Type: application/octet-stream\n",
            "25/02/18 20:36:23 DEBUG headers: http-outgoing-13 >> User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy\n",
            "25/02/18 20:36:23 DEBUG headers: http-outgoing-13 >> x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "25/02/18 20:36:23 DEBUG headers: http-outgoing-13 >> X-Amz-Date: 20250218T203623Z\n",
            "25/02/18 20:36:23 DEBUG headers: http-outgoing-13 >> Connection: Keep-Alive\n",
            "25/02/18 20:36:23 DEBUG wire: http-outgoing-13 >> \"HEAD /wba/test.parquet HTTP/1.1[\\r][\\n]\"\n",
            "25/02/18 20:36:23 DEBUG wire: http-outgoing-13 >> \"Host: localhost:9000[\\r][\\n]\"\n",
            "25/02/18 20:36:23 DEBUG wire: http-outgoing-13 >> \"amz-sdk-invocation-id: 774a7502-7a66-5eba-cee1-eee8488196c9[\\r][\\n]\"\n",
            "25/02/18 20:36:23 DEBUG wire: http-outgoing-13 >> \"amz-sdk-request: attempt=2;max=2[\\r][\\n]\"\n",
            "25/02/18 20:36:23 DEBUG wire: http-outgoing-13 >> \"amz-sdk-retry: 1/63/495[\\r][\\n]\"\n",
            "25/02/18 20:36:23 DEBUG wire: http-outgoing-13 >> \"Authorization: AWS4-HMAC-SHA256 Credential=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=4c8c93519ce253356dc7a74a31a10fb4e9ac6d59b173b3cd64631f201cd21025[\\r][\\n]\"\n",
            "25/02/18 20:36:23 DEBUG wire: http-outgoing-13 >> \"Content-Type: application/octet-stream[\\r][\\n]\"\n",
            "25/02/18 20:36:23 DEBUG wire: http-outgoing-13 >> \"User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy[\\r][\\n]\"\n",
            "25/02/18 20:36:23 DEBUG wire: http-outgoing-13 >> \"x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855[\\r][\\n]\"\n",
            "25/02/18 20:36:23 DEBUG wire: http-outgoing-13 >> \"X-Amz-Date: 20250218T203623Z[\\r][\\n]\"\n",
            "25/02/18 20:36:23 DEBUG wire: http-outgoing-13 >> \"Connection: Keep-Alive[\\r][\\n]\"\n",
            "25/02/18 20:36:23 DEBUG wire: http-outgoing-13 >> \"[\\r][\\n]\"\n",
            "25/02/18 20:36:23 DEBUG wire: http-outgoing-13 << \"[0xff][0x0][0x0][0x0][0x0][0x0][0x0][0x0][0x1]\"\n",
            "25/02/18 20:36:23 DEBUG wire: http-outgoing-13 << \"-[0x1]d: 774a7502-7a66-5eba-cee1-eee8488196c9[\\r][\\n]\"\n",
            "25/02/18 20:36:23 DEBUG wire: http-outgoing-13 << \"amz-[0x1]dk-request: attempt=2;max=2[\\r][\\n]\"\n",
            "25/02/18 20:36:23 DEBUG wire: http-outgoing-13 << \"amz-sdk-retry: 1[0x1]63/495[\\r][\\n]\"\n",
            "25/02/18 20:36:23 DEBUG wire: http-outgoing-13 << \"Authorization: AWS4-HMAC-SHA256 Credentia[0x0]=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-reque[0x1]t;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=4c8c93519ce25[0x1]356dc7a74a31a10fb4e9ac6d59b173b3cd64631f201cd21025[\\r][\\n]\"\n",
            "25/02/18 20:36:23 DEBUG wire: http-outgoing-13 << \"C[0x1]ntent-Type: application/octet-stream[\\r][\\n]\"\n",
            "25/02/18 20:36:23 DEBUG wire: http-outgoing-13 << \"User-Agent: Hadoop 3.3.4, aws[0x1]sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/[0x1]7.0.14 scala/2.12.17 vendor/Debian cfg/retry-mo[0x0]e/legacy[\\r][\\n]\"\n",
            "25/02/18 20:36:23 DEBUG wire: http-outgoing-13 << \"x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855[\\r][\\n]\"\n",
            "25/02/18 20:36:23 DEBUG wire: http-outgoing-13 << \"X-Amz-Date: \"\n",
            "25/02/18 20:36:23 DEBUG DefaultHttpResponseParser: Garbage in response: \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0001-\u0001d: 774a7502-7a66-5eba-cee1-eee8488196c9\n",
            "25/02/18 20:36:23 DEBUG DefaultHttpResponseParser: Garbage in response: amz-\u0001dk-request: attempt=2;max=2\n",
            "25/02/18 20:36:23 DEBUG DefaultHttpResponseParser: Garbage in response: amz-sdk-retry: 1\u000163/495\n",
            "25/02/18 20:36:23 DEBUG DefaultHttpResponseParser: Garbage in response: Authorization: AWS4-HMAC-SHA256 Credentia\u0000=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-reque\u0001t;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=4c8c93519ce25\u0001356dc7a74a31a10fb4e9ac6d59b173b3cd64631f201cd21025\n",
            "25/02/18 20:36:23 DEBUG DefaultHttpResponseParser: Garbage in response: C\u0001ntent-Type: application/octet-stream\n",
            "25/02/18 20:36:23 DEBUG DefaultHttpResponseParser: Garbage in response: User-Agent: Hadoop 3.3.4, aws\u0001sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/\u00017.0.14 scala/2.12.17 vendor/Debian cfg/retry-mo\u0000e/legacy\n",
            "25/02/18 20:36:23 DEBUG DefaultHttpResponseParser: Garbage in response: x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "25/02/18 20:36:27 DEBUG Invoker: retry #6\n",
            "25/02/18 20:36:27 DEBUG IOStatisticsStoreImpl: Incrementing counter object_metadata_request by 1 with final value 7\n",
            "25/02/18 20:36:27 DEBUG IOStatisticsStoreImpl: Incrementing counter action_http_head_request by 1 with final value 7\n",
            "25/02/18 20:36:27 DEBUG S3AFileSystem: HEAD test.parquet with change tracker null\n",
            "25/02/18 20:36:27 DEBUG request: Sending Request: HEAD http://minio:9000 /wba/test.parquet Headers: (amz-sdk-invocation-id: e1e469ea-c6cc-349a-68a7-fa6b64441ed3, Content-Type: application/octet-stream, User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy, ) \n",
            "25/02/18 20:36:27 DEBUG AWS4Signer: AWS4 Canonical Request: '\"HEAD\n",
            "/wba/test.parquet\n",
            "\n",
            "amz-sdk-invocation-id:e1e469ea-c6cc-349a-68a7-fa6b64441ed3\n",
            "amz-sdk-request:attempt=1;max=2\n",
            "amz-sdk-retry:0/0/470\n",
            "content-type:application/octet-stream\n",
            "host:minio:9000\n",
            "user-agent:Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy\n",
            "x-amz-content-sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "x-amz-date:20250218T203627Z\n",
            "\n",
            "amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date\n",
            "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\"\n",
            "25/02/18 20:36:27 DEBUG AWS4Signer: AWS4 String to Sign: '\"AWS4-HMAC-SHA256\n",
            "20250218T203627Z\n",
            "20250218/us-east-1/s3/aws4_request\n",
            "f80689fb97547440bfdeca78c1fa9b3601ab5a987b8c1865369b50f410785aa9\"\n",
            "25/02/18 20:36:27 DEBUG RequestAddCookies: CookieSpec selected: default\n",
            "25/02/18 20:36:27 DEBUG RequestAuthCache: Auth cache not set in the context\n",
            "25/02/18 20:36:27 DEBUG PoolingHttpClientConnectionManager: Connection request: [route: {}->http://minio:9000][total available: 0; route allocated: 0 of 1; total allocated: 0 of 1]\n",
            "25/02/18 20:36:27 DEBUG PoolingHttpClientConnectionManager: Connection leased: [id: 14][route: {}->http://minio:9000][total available: 0; route allocated: 1 of 1; total allocated: 1 of 1]\n",
            "25/02/18 20:36:27 DEBUG MainClientExec: Opening connection {}->http://minio:9000\n",
            "25/02/18 20:36:28 DEBUG ExecutorMetricsPoller: removing (1, 0) from stageTCMP\n",
            "25/02/18 20:36:28 DEBUG ExecutorMetricsPoller: removing (2, 0) from stageTCMP\n",
            "25/02/18 20:36:28 DEBUG ExecutorMetricsPoller: removing (0, 0) from stageTCMP\n",
            "25/02/18 20:36:28 DEBUG wire: http-outgoing-13 << \"[read] I/O error: Read timed out\"\n",
            "25/02/18 20:36:28 DEBUG DefaultManagedHttpClientConnection: http-outgoing-13: Close connection\n",
            "25/02/18 20:36:28 DEBUG DefaultManagedHttpClientConnection: http-outgoing-13: Shutdown connection\n",
            "25/02/18 20:36:28 DEBUG MainClientExec: Connection discarded\n",
            "25/02/18 20:36:28 DEBUG PoolingHttpClientConnectionManager: Connection released: [id: 13][route: {}->http://localhost:9000][total available: 0; route allocated: 0 of 1; total allocated: 0 of 1]\n",
            "25/02/18 20:36:28 DEBUG AmazonHttpClient: Unable to execute HTTP request: Read timed out\n",
            "25/02/18 20:36:28 DEBUG IOStatisticsStoreImpl: Incrementing counter store_io_request by 2 with final value 2\n",
            "25/02/18 20:36:28 DEBUG latency: MaxRetriesExceeded=[true], ServiceName=[Amazon S3], ServiceEndpoint=[http://localhost:9000], Exception=[java.net.SocketTimeoutException: Read timed out, java.net.SocketTimeoutException: Read timed out], RequestType=[GetObjectMetadataRequest], AWSRequestID=[null, null], HttpClientPoolPendingCount=0, RetryCapacityConsumed=5, HttpClientPoolAvailableCount=0, RequestCount=2, Exception=2, HttpClientPoolLeasedCount=0, RetryPauseTime=[63.431], ClientExecuteTime=[10105.628], HttpClientSendRequestTime=[2.461, 0.621], HttpRequestTime=[5028.63, 5009.089], ApiCallLatency=[10105.025], RequestSigningTime=[0.529, 0.939], CredentialsRequestTime=[0.09, 0.008, 0.063], HttpClientReceiveResponseTime=[5019.637, 5006.406], \n",
            "25/02/18 20:36:28 DEBUG IOStatisticsStoreImpl: Incrementing counter store_io_retry by 1 with final value 1\n",
            "25/02/18 20:36:28 DEBUG IOStatisticsStoreImpl: Incrementing counter ignored_errors by 1 with final value 1\n",
            "25/02/18 20:36:29 DEBUG Invoker: retry #1\n",
            "25/02/18 20:36:29 DEBUG IOStatisticsStoreImpl: Incrementing counter object_metadata_request by 1 with final value 2\n",
            "25/02/18 20:36:29 DEBUG IOStatisticsStoreImpl: Incrementing counter action_http_head_request by 1 with final value 2\n",
            "25/02/18 20:36:29 DEBUG S3AFileSystem: HEAD test.parquet with change tracker null\n",
            "25/02/18 20:36:29 DEBUG request: Sending Request: HEAD http://localhost:9000 /wba/test.parquet Headers: (amz-sdk-invocation-id: 963b05b7-d641-34cc-86f1-07306da3934a, Content-Type: application/octet-stream, User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy, ) \n",
            "25/02/18 20:36:29 DEBUG AWS4Signer: AWS4 Canonical Request: '\"HEAD\n",
            "/wba/test.parquet\n",
            "\n",
            "amz-sdk-invocation-id:963b05b7-d641-34cc-86f1-07306da3934a\n",
            "amz-sdk-request:attempt=1;max=2\n",
            "amz-sdk-retry:0/0/495\n",
            "content-type:application/octet-stream\n",
            "host:localhost:9000\n",
            "user-agent:Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy\n",
            "x-amz-content-sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "x-amz-date:20250218T203629Z\n",
            "\n",
            "amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date\n",
            "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\"\n",
            "25/02/18 20:36:29 DEBUG AWS4Signer: AWS4 String to Sign: '\"AWS4-HMAC-SHA256\n",
            "20250218T203629Z\n",
            "20250218/us-east-1/s3/aws4_request\n",
            "3ee75a07a27c3a48744f25bc374d3b789d36ba38490241ea6f3634ffcedc4385\"\n",
            "25/02/18 20:36:29 DEBUG RequestAddCookies: CookieSpec selected: default\n",
            "25/02/18 20:36:29 DEBUG RequestAuthCache: Auth cache not set in the context\n",
            "25/02/18 20:36:29 DEBUG PoolingHttpClientConnectionManager: Connection request: [route: {}->http://localhost:9000][total available: 0; route allocated: 0 of 1; total allocated: 0 of 1]\n",
            "25/02/18 20:36:29 DEBUG PoolingHttpClientConnectionManager: Connection leased: [id: 15][route: {}->http://localhost:9000][total available: 0; route allocated: 1 of 1; total allocated: 1 of 1]\n",
            "25/02/18 20:36:29 DEBUG MainClientExec: Opening connection {}->http://localhost:9000\n",
            "25/02/18 20:36:29 DEBUG DefaultHttpClientConnectionOperator: Connecting to localhost/127.0.0.1:9000\n",
            "25/02/18 20:36:29 DEBUG DefaultHttpClientConnectionOperator: Connection established 127.0.0.1:51202<->127.0.0.1:9000\n",
            "25/02/18 20:36:29 DEBUG DefaultManagedHttpClientConnection: http-outgoing-15: set socket timeout to 5000\n",
            "25/02/18 20:36:29 DEBUG MainClientExec: Executing request HEAD /wba/test.parquet HTTP/1.1\n",
            "25/02/18 20:36:29 DEBUG MainClientExec: Proxy auth state: UNCHALLENGED\n",
            "25/02/18 20:36:29 DEBUG headers: http-outgoing-15 >> HEAD /wba/test.parquet HTTP/1.1\n",
            "25/02/18 20:36:29 DEBUG headers: http-outgoing-15 >> Host: localhost:9000\n",
            "25/02/18 20:36:29 DEBUG headers: http-outgoing-15 >> amz-sdk-invocation-id: 963b05b7-d641-34cc-86f1-07306da3934a\n",
            "25/02/18 20:36:29 DEBUG headers: http-outgoing-15 >> amz-sdk-request: attempt=1;max=2\n",
            "25/02/18 20:36:29 DEBUG headers: http-outgoing-15 >> amz-sdk-retry: 0/0/495\n",
            "25/02/18 20:36:29 DEBUG headers: http-outgoing-15 >> Authorization: AWS4-HMAC-SHA256 Credential=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=900fda9d90b52ecf865579b77bb1e11ebb4e59b3f86d1982be4ee8ac59b6c76c\n",
            "25/02/18 20:36:29 DEBUG headers: http-outgoing-15 >> Content-Type: application/octet-stream\n",
            "25/02/18 20:36:29 DEBUG headers: http-outgoing-15 >> User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy\n",
            "25/02/18 20:36:29 DEBUG headers: http-outgoing-15 >> x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "25/02/18 20:36:29 DEBUG headers: http-outgoing-15 >> X-Amz-Date: 20250218T203629Z\n",
            "25/02/18 20:36:29 DEBUG headers: http-outgoing-15 >> Connection: Keep-Alive\n",
            "25/02/18 20:36:29 DEBUG wire: http-outgoing-15 >> \"HEAD /wba/test.parquet HTTP/1.1[\\r][\\n]\"\n",
            "25/02/18 20:36:29 DEBUG wire: http-outgoing-15 >> \"Host: localhost:9000[\\r][\\n]\"\n",
            "25/02/18 20:36:29 DEBUG wire: http-outgoing-15 >> \"amz-sdk-invocation-id: 963b05b7-d641-34cc-86f1-07306da3934a[\\r][\\n]\"\n",
            "25/02/18 20:36:29 DEBUG wire: http-outgoing-15 >> \"amz-sdk-request: attempt=1;max=2[\\r][\\n]\"\n",
            "25/02/18 20:36:29 DEBUG wire: http-outgoing-15 >> \"amz-sdk-retry: 0/0/495[\\r][\\n]\"\n",
            "25/02/18 20:36:29 DEBUG wire: http-outgoing-15 >> \"Authorization: AWS4-HMAC-SHA256 Credential=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=900fda9d90b52ecf865579b77bb1e11ebb4e59b3f86d1982be4ee8ac59b6c76c[\\r][\\n]\"\n",
            "25/02/18 20:36:29 DEBUG wire: http-outgoing-15 >> \"Content-Type: application/octet-stream[\\r][\\n]\"\n",
            "25/02/18 20:36:29 DEBUG wire: http-outgoing-15 >> \"User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy[\\r][\\n]\"\n",
            "25/02/18 20:36:29 DEBUG wire: http-outgoing-15 >> \"x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855[\\r][\\n]\"\n",
            "25/02/18 20:36:29 DEBUG wire: http-outgoing-15 >> \"X-Amz-Date: 20250218T203629Z[\\r][\\n]\"\n",
            "25/02/18 20:36:29 DEBUG wire: http-outgoing-15 >> \"Connection: Keep-Alive[\\r][\\n]\"\n",
            "25/02/18 20:36:29 DEBUG wire: http-outgoing-15 >> \"[\\r][\\n]\"\n",
            "25/02/18 20:36:29 DEBUG wire: http-outgoing-15 << \"[0xff][0x0][0x0][0x0][0x0][0x0][0x0][0x0][0x1]\"\n",
            "25/02/18 20:36:29 DEBUG wire: http-outgoing-15 << \"-[0x1]d: 963b05b7-d641-34cc-86f1-07306da3934a[\\r][\\n]\"\n",
            "25/02/18 20:36:29 DEBUG wire: http-outgoing-15 << \"amz-[0x1]dk-request: attempt=1;max=2[\\r][\\n]\"\n",
            "25/02/18 20:36:29 DEBUG wire: http-outgoing-15 << \"amz-sdk-retry: 0[0x1]0/495[\\r][\\n]\"\n",
            "25/02/18 20:36:29 DEBUG wire: http-outgoing-15 << \"Authorization: AWS4-HMAC-SHA256 Credentia[0x0]=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-reque[0x1]t;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=900fda9d90b52[0x1]cf865579b77bb1e11ebb4e59b3f86d1982be4ee8ac59b6c76c[0x1][\\n]\"\n",
            "25/02/18 20:36:29 DEBUG wire: http-outgoing-15 << \"Content-Type: application/octet-stream[\\r][\\n]\"\n",
            "25/02/18 20:36:29 DEBUG wire: http-outgoing-15 << \"User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15[0x0]167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_\"\n",
            "25/02/18 20:36:29 DEBUG DefaultHttpResponseParser: Garbage in response: \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0001-\u0001d: 963b05b7-d641-34cc-86f1-07306da3934a\n",
            "25/02/18 20:36:29 DEBUG DefaultHttpResponseParser: Garbage in response: amz-\u0001dk-request: attempt=1;max=2\n",
            "25/02/18 20:36:29 DEBUG DefaultHttpResponseParser: Garbage in response: amz-sdk-retry: 0\u00010/495\n",
            "25/02/18 20:36:29 DEBUG DefaultHttpResponseParser: Garbage in response: Authorization: AWS4-HMAC-SHA256 Credentia\u0000=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-reque\u0001t;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=900fda9d90b52\u0001cf865579b77bb1e11ebb4e59b3f86d1982be4ee8ac59b6c76c\u0001\n",
            "25/02/18 20:36:29 DEBUG DefaultHttpResponseParser: Garbage in response: Content-Type: application/octet-stream\n",
            "25/02/18 20:36:34 DEBUG wire: http-outgoing-15 << \"[read] I/O error: Read timed out\"\n",
            "25/02/18 20:36:34 DEBUG DefaultManagedHttpClientConnection: http-outgoing-15: Close connection\n",
            "25/02/18 20:36:34 DEBUG DefaultManagedHttpClientConnection: http-outgoing-15: Shutdown connection\n",
            "25/02/18 20:36:34 DEBUG MainClientExec: Connection discarded\n",
            "25/02/18 20:36:34 DEBUG PoolingHttpClientConnectionManager: Connection released: [id: 15][route: {}->http://localhost:9000][total available: 0; route allocated: 0 of 1; total allocated: 0 of 1]\n",
            "25/02/18 20:36:34 DEBUG AmazonHttpClient: Unable to execute HTTP request: Read timed out Request will be retried.\n",
            "25/02/18 20:36:34 DEBUG request: Retrying Request: HEAD http://localhost:9000 /wba/test.parquet Headers: (amz-sdk-invocation-id: 963b05b7-d641-34cc-86f1-07306da3934a, Content-Type: application/octet-stream, User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy, ) \n",
            "25/02/18 20:36:34 DEBUG AmazonHttpClient: Retriable error detected, will retry in 21ms, attempt number: 0\n",
            "25/02/18 20:36:34 DEBUG AWS4Signer: AWS4 Canonical Request: '\"HEAD\n",
            "/wba/test.parquet\n",
            "\n",
            "amz-sdk-invocation-id:963b05b7-d641-34cc-86f1-07306da3934a\n",
            "amz-sdk-request:attempt=2;max=2\n",
            "amz-sdk-retry:1/21/490\n",
            "content-type:application/octet-stream\n",
            "host:localhost:9000\n",
            "user-agent:Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy\n",
            "x-amz-content-sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "x-amz-date:20250218T203634Z\n",
            "\n",
            "amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date\n",
            "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\"\n",
            "25/02/18 20:36:34 DEBUG AWS4Signer: AWS4 String to Sign: '\"AWS4-HMAC-SHA256\n",
            "20250218T203634Z\n",
            "20250218/us-east-1/s3/aws4_request\n",
            "8bd67d37d4284556b1ceaa8c457dc48ff8d3c0ceeeb331bc96d257ccbc82ac4b\"\n",
            "25/02/18 20:36:34 DEBUG RequestAddCookies: CookieSpec selected: default\n",
            "25/02/18 20:36:34 DEBUG RequestAuthCache: Auth cache not set in the context\n",
            "25/02/18 20:36:34 DEBUG PoolingHttpClientConnectionManager: Connection request: [route: {}->http://localhost:9000][total available: 0; route allocated: 0 of 1; total allocated: 0 of 1]\n",
            "25/02/18 20:36:34 DEBUG PoolingHttpClientConnectionManager: Connection leased: [id: 16][route: {}->http://localhost:9000][total available: 0; route allocated: 1 of 1; total allocated: 1 of 1]\n",
            "25/02/18 20:36:34 DEBUG MainClientExec: Opening connection {}->http://localhost:9000\n",
            "25/02/18 20:36:34 DEBUG DefaultHttpClientConnectionOperator: Connecting to localhost/127.0.0.1:9000\n",
            "25/02/18 20:36:34 DEBUG DefaultHttpClientConnectionOperator: Connection established 127.0.0.1:51220<->127.0.0.1:9000\n",
            "25/02/18 20:36:34 DEBUG DefaultManagedHttpClientConnection: http-outgoing-16: set socket timeout to 5000\n",
            "25/02/18 20:36:34 DEBUG MainClientExec: Executing request HEAD /wba/test.parquet HTTP/1.1\n",
            "25/02/18 20:36:34 DEBUG MainClientExec: Proxy auth state: UNCHALLENGED\n",
            "25/02/18 20:36:34 DEBUG headers: http-outgoing-16 >> HEAD /wba/test.parquet HTTP/1.1\n",
            "25/02/18 20:36:34 DEBUG headers: http-outgoing-16 >> Host: localhost:9000\n",
            "25/02/18 20:36:34 DEBUG headers: http-outgoing-16 >> amz-sdk-invocation-id: 963b05b7-d641-34cc-86f1-07306da3934a\n",
            "25/02/18 20:36:34 DEBUG headers: http-outgoing-16 >> amz-sdk-request: attempt=2;max=2\n",
            "25/02/18 20:36:34 DEBUG headers: http-outgoing-16 >> amz-sdk-retry: 1/21/490\n",
            "25/02/18 20:36:34 DEBUG headers: http-outgoing-16 >> Authorization: AWS4-HMAC-SHA256 Credential=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=57a7892e64375f8c160e8129196aac1ddb23c4b86adbf7e43609d54c50bce159\n",
            "25/02/18 20:36:34 DEBUG headers: http-outgoing-16 >> Content-Type: application/octet-stream\n",
            "25/02/18 20:36:34 DEBUG headers: http-outgoing-16 >> User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy\n",
            "25/02/18 20:36:34 DEBUG headers: http-outgoing-16 >> x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "25/02/18 20:36:34 DEBUG headers: http-outgoing-16 >> X-Amz-Date: 20250218T203634Z\n",
            "25/02/18 20:36:34 DEBUG headers: http-outgoing-16 >> Connection: Keep-Alive\n",
            "25/02/18 20:36:34 DEBUG wire: http-outgoing-16 >> \"HEAD /wba/test.parquet HTTP/1.1[\\r][\\n]\"\n",
            "25/02/18 20:36:34 DEBUG wire: http-outgoing-16 >> \"Host: localhost:9000[\\r][\\n]\"\n",
            "25/02/18 20:36:34 DEBUG wire: http-outgoing-16 >> \"amz-sdk-invocation-id: 963b05b7-d641-34cc-86f1-07306da3934a[\\r][\\n]\"\n",
            "25/02/18 20:36:34 DEBUG wire: http-outgoing-16 >> \"amz-sdk-request: attempt=2;max=2[\\r][\\n]\"\n",
            "25/02/18 20:36:34 DEBUG wire: http-outgoing-16 >> \"amz-sdk-retry: 1/21/490[\\r][\\n]\"\n",
            "25/02/18 20:36:34 DEBUG wire: http-outgoing-16 >> \"Authorization: AWS4-HMAC-SHA256 Credential=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=57a7892e64375f8c160e8129196aac1ddb23c4b86adbf7e43609d54c50bce159[\\r][\\n]\"\n",
            "25/02/18 20:36:34 DEBUG wire: http-outgoing-16 >> \"Content-Type: application/octet-stream[\\r][\\n]\"\n",
            "25/02/18 20:36:34 DEBUG wire: http-outgoing-16 >> \"User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy[\\r][\\n]\"\n",
            "25/02/18 20:36:34 DEBUG wire: http-outgoing-16 >> \"x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855[\\r][\\n]\"\n",
            "25/02/18 20:36:34 DEBUG wire: http-outgoing-16 >> \"X-Amz-Date: 20250218T203634Z[\\r][\\n]\"\n",
            "25/02/18 20:36:34 DEBUG wire: http-outgoing-16 >> \"Connection: Keep-Alive[\\r][\\n]\"\n",
            "25/02/18 20:36:34 DEBUG wire: http-outgoing-16 >> \"[\\r][\\n]\"\n",
            "25/02/18 20:36:34 DEBUG wire: http-outgoing-16 << \"[0xff][0x0][0x0][0x0][0x0][0x0][0x0][0x0][0x1]\"\n",
            "25/02/18 20:36:34 DEBUG wire: http-outgoing-16 << \"-[0x1]d: 963b05b7-d641-34cc-86f1-07306da3934a[\\r][\\n]\"\n",
            "25/02/18 20:36:34 DEBUG wire: http-outgoing-16 << \"amz-[0x1]dk-request: attempt=2;max=2[\\r][\\n]\"\n",
            "25/02/18 20:36:34 DEBUG wire: http-outgoing-16 << \"amz-sdk-retry: 1[0x1]21/490[\\r][\\n]\"\n",
            "25/02/18 20:36:34 DEBUG wire: http-outgoing-16 << \"Authorization: AWS4-HMAC-SHA256 Credentia[0x0]=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-reque[0x1]t;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=57a7892e64375[0x0]8c160e8129196aac1ddb23c4b86adbf7e43609d54c50bce159[\\r][\\n]\"\n",
            "25/02/18 20:36:34 DEBUG wire: http-outgoing-16 << \"C[0x1]ntent-Type: application/octet-stream[\\r][\\n]\"\n",
            "25/02/18 20:36:34 DEBUG wire: http-outgoing-16 << \"User-Agent: Hadoop 3.3.4, aws[0x1]sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/[0x1]7.0.14 scala/2.12.17 vendor/Debian cfg/retry-mo[0x0]e/legacy[\\r][\\n]\"\n",
            "25/02/18 20:36:34 DEBUG wire: http-outgoing-16 << \"x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855[\\r][\\n]\"\n",
            "25/02/18 20:36:34 DEBUG wire: http-outgoing-16 << \"X-Amz-Date: \"\n",
            "25/02/18 20:36:34 DEBUG DefaultHttpResponseParser: Garbage in response: \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0001-\u0001d: 963b05b7-d641-34cc-86f1-07306da3934a\n",
            "25/02/18 20:36:34 DEBUG DefaultHttpResponseParser: Garbage in response: amz-\u0001dk-request: attempt=2;max=2\n",
            "25/02/18 20:36:34 DEBUG DefaultHttpResponseParser: Garbage in response: amz-sdk-retry: 1\u000121/490\n",
            "25/02/18 20:36:34 DEBUG DefaultHttpResponseParser: Garbage in response: Authorization: AWS4-HMAC-SHA256 Credentia\u0000=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-reque\u0001t;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=57a7892e64375\u00008c160e8129196aac1ddb23c4b86adbf7e43609d54c50bce159\n",
            "25/02/18 20:36:34 DEBUG DefaultHttpResponseParser: Garbage in response: C\u0001ntent-Type: application/octet-stream\n",
            "25/02/18 20:36:34 DEBUG DefaultHttpResponseParser: Garbage in response: User-Agent: Hadoop 3.3.4, aws\u0001sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/\u00017.0.14 scala/2.12.17 vendor/Debian cfg/retry-mo\u0000e/legacy\n",
            "25/02/18 20:36:34 DEBUG DefaultHttpResponseParser: Garbage in response: x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "25/02/18 20:36:35 DEBUG ClientConnectionManagerFactory: \n",
            "java.lang.reflect.InvocationTargetException\n",
            "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
            "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
            "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
            "\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n",
            "\tat com.amazonaws.http.conn.ClientConnectionManagerFactory$Handler.invoke(ClientConnectionManagerFactory.java:76)\n",
            "\tat com.amazonaws.http.conn.$Proxy43.connect(Unknown Source)\n",
            "\tat com.amazonaws.thirdparty.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:393)\n",
            "\tat com.amazonaws.thirdparty.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:236)\n",
            "\tat com.amazonaws.thirdparty.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:186)\n",
            "\tat com.amazonaws.thirdparty.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)\n",
            "\tat com.amazonaws.thirdparty.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)\n",
            "\tat com.amazonaws.thirdparty.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56)\n",
            "\tat com.amazonaws.http.apache.client.impl.SdkHttpClient.execute(SdkHttpClient.java:72)\n",
            "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeOneRequest(AmazonHttpClient.java:1346)\n",
            "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeHelper(AmazonHttpClient.java:1157)\n",
            "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.doExecute(AmazonHttpClient.java:814)\n",
            "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeWithTimer(AmazonHttpClient.java:781)\n",
            "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.execute(AmazonHttpClient.java:755)\n",
            "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.access$500(AmazonHttpClient.java:715)\n",
            "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutionBuilderImpl.execute(AmazonHttpClient.java:697)\n",
            "\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:561)\n",
            "\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:541)\n",
            "\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:5456)\n",
            "\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:5403)\n",
            "\tat com.amazonaws.services.s3.AmazonS3Client.getObjectMetadata(AmazonS3Client.java:1372)\n",
            "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$getObjectMetadata$10(S3AFileSystem.java:2545)\n",
            "\tat org.apache.hadoop.fs.s3a.Invoker.retryUntranslated(Invoker.java:414)\n",
            "\tat org.apache.hadoop.fs.s3a.Invoker.retryUntranslated(Invoker.java:377)\n",
            "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.getObjectMetadata(S3AFileSystem.java:2533)\n",
            "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.getObjectMetadata(S3AFileSystem.java:2513)\n",
            "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.s3GetFileStatus(S3AFileSystem.java:3776)\n",
            "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.innerGetFileStatus(S3AFileSystem.java:3688)\n",
            "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$exists$34(S3AFileSystem.java:4703)\n",
            "\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.lambda$trackDurationOfOperation$5(IOStatisticsBinding.java:499)\n",
            "\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.trackDuration(IOStatisticsBinding.java:444)\n",
            "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2337)\n",
            "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2356)\n",
            "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.exists(S3AFileSystem.java:4701)\n",
            "\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:120)\n",
            "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)\n",
            "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)\n",
            "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
            "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n",
            "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n",
            "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
            "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n",
            "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n",
            "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n",
            "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n",
            "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:239)\n",
            "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
            "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
            "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
            "\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n",
            "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
            "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
            "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
            "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
            "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
            "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
            "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "Caused by: java.net.UnknownHostException: minio: Temporary failure in name resolution\n",
            "\tat java.base/java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method)\n",
            "\tat java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)\n",
            "\tat java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)\n",
            "\tat java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat com.amazonaws.SystemDefaultDnsResolver.resolve(SystemDefaultDnsResolver.java:27)\n",
            "\tat com.amazonaws.http.DelegatingDnsResolver.resolve(DelegatingDnsResolver.java:38)\n",
            "\tat com.amazonaws.thirdparty.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:112)\n",
            "\tat com.amazonaws.thirdparty.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:376)\n",
            "\t... 79 more\n",
            "25/02/18 20:36:35 DEBUG DefaultManagedHttpClientConnection: http-outgoing-14: Shutdown connection\n",
            "25/02/18 20:36:35 DEBUG MainClientExec: Connection discarded\n",
            "25/02/18 20:36:35 DEBUG PoolingHttpClientConnectionManager: Connection released: [id: 14][route: {}->http://minio:9000][total available: 0; route allocated: 0 of 1; total allocated: 0 of 1]\n",
            "25/02/18 20:36:35 DEBUG AmazonHttpClient: Unable to execute HTTP request: minio: Temporary failure in name resolution Request will be retried.\n",
            "25/02/18 20:36:35 DEBUG request: Retrying Request: HEAD http://minio:9000 /wba/test.parquet Headers: (amz-sdk-invocation-id: e1e469ea-c6cc-349a-68a7-fa6b64441ed3, Content-Type: application/octet-stream, User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy, ) \n",
            "25/02/18 20:36:35 DEBUG AmazonHttpClient: Retriable error detected, will retry in 31ms, attempt number: 0\n",
            "25/02/18 20:36:35 DEBUG AWS4Signer: AWS4 Canonical Request: '\"HEAD\n",
            "/wba/test.parquet\n",
            "\n",
            "amz-sdk-invocation-id:e1e469ea-c6cc-349a-68a7-fa6b64441ed3\n",
            "amz-sdk-request:attempt=2;max=2\n",
            "amz-sdk-retry:1/31/465\n",
            "content-type:application/octet-stream\n",
            "host:minio:9000\n",
            "user-agent:Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy\n",
            "x-amz-content-sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "x-amz-date:20250218T203635Z\n",
            "\n",
            "amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date\n",
            "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\"\n",
            "25/02/18 20:36:35 DEBUG AWS4Signer: AWS4 String to Sign: '\"AWS4-HMAC-SHA256\n",
            "20250218T203635Z\n",
            "20250218/us-east-1/s3/aws4_request\n",
            "ee0682cfafb4e225e3677e3987373e47a965ce1d79b8d222398a9b43192cf767\"\n",
            "25/02/18 20:36:35 DEBUG RequestAddCookies: CookieSpec selected: default\n",
            "25/02/18 20:36:35 DEBUG RequestAuthCache: Auth cache not set in the context\n",
            "25/02/18 20:36:35 DEBUG PoolingHttpClientConnectionManager: Connection request: [route: {}->http://minio:9000][total available: 0; route allocated: 0 of 1; total allocated: 0 of 1]\n",
            "25/02/18 20:36:35 DEBUG PoolingHttpClientConnectionManager: Connection leased: [id: 17][route: {}->http://minio:9000][total available: 0; route allocated: 1 of 1; total allocated: 1 of 1]\n",
            "25/02/18 20:36:35 DEBUG MainClientExec: Opening connection {}->http://minio:9000\n",
            "25/02/18 20:36:35 DEBUG ClientConnectionManagerFactory: \n",
            "java.lang.reflect.InvocationTargetException\n",
            "\tat jdk.internal.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)\n",
            "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
            "\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n",
            "\tat com.amazonaws.http.conn.ClientConnectionManagerFactory$Handler.invoke(ClientConnectionManagerFactory.java:76)\n",
            "\tat com.amazonaws.http.conn.$Proxy43.connect(Unknown Source)\n",
            "\tat com.amazonaws.thirdparty.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:393)\n",
            "\tat com.amazonaws.thirdparty.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:236)\n",
            "\tat com.amazonaws.thirdparty.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:186)\n",
            "\tat com.amazonaws.thirdparty.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)\n",
            "\tat com.amazonaws.thirdparty.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)\n",
            "\tat com.amazonaws.thirdparty.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56)\n",
            "\tat com.amazonaws.http.apache.client.impl.SdkHttpClient.execute(SdkHttpClient.java:72)\n",
            "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeOneRequest(AmazonHttpClient.java:1346)\n",
            "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeHelper(AmazonHttpClient.java:1157)\n",
            "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.doExecute(AmazonHttpClient.java:814)\n",
            "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeWithTimer(AmazonHttpClient.java:781)\n",
            "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.execute(AmazonHttpClient.java:755)\n",
            "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.access$500(AmazonHttpClient.java:715)\n",
            "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutionBuilderImpl.execute(AmazonHttpClient.java:697)\n",
            "\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:561)\n",
            "\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:541)\n",
            "\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:5456)\n",
            "\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:5403)\n",
            "\tat com.amazonaws.services.s3.AmazonS3Client.getObjectMetadata(AmazonS3Client.java:1372)\n",
            "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$getObjectMetadata$10(S3AFileSystem.java:2545)\n",
            "\tat org.apache.hadoop.fs.s3a.Invoker.retryUntranslated(Invoker.java:414)\n",
            "\tat org.apache.hadoop.fs.s3a.Invoker.retryUntranslated(Invoker.java:377)\n",
            "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.getObjectMetadata(S3AFileSystem.java:2533)\n",
            "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.getObjectMetadata(S3AFileSystem.java:2513)\n",
            "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.s3GetFileStatus(S3AFileSystem.java:3776)\n",
            "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.innerGetFileStatus(S3AFileSystem.java:3688)\n",
            "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$exists$34(S3AFileSystem.java:4703)\n",
            "\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.lambda$trackDurationOfOperation$5(IOStatisticsBinding.java:499)\n",
            "\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.trackDuration(IOStatisticsBinding.java:444)\n",
            "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2337)\n",
            "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2356)\n",
            "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.exists(S3AFileSystem.java:4701)\n",
            "\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:120)\n",
            "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)\n",
            "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)\n",
            "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
            "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n",
            "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n",
            "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
            "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n",
            "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n",
            "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n",
            "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n",
            "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:239)\n",
            "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
            "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
            "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
            "\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n",
            "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
            "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
            "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
            "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
            "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
            "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
            "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "Caused by: java.net.UnknownHostException: minio\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat com.amazonaws.SystemDefaultDnsResolver.resolve(SystemDefaultDnsResolver.java:27)\n",
            "\tat com.amazonaws.http.DelegatingDnsResolver.resolve(DelegatingDnsResolver.java:38)\n",
            "\tat com.amazonaws.thirdparty.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:112)\n",
            "\tat com.amazonaws.thirdparty.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:376)\n",
            "\t... 78 more\n",
            "25/02/18 20:36:35 DEBUG DefaultManagedHttpClientConnection: http-outgoing-17: Shutdown connection\n",
            "25/02/18 20:36:35 DEBUG MainClientExec: Connection discarded\n",
            "25/02/18 20:36:35 DEBUG PoolingHttpClientConnectionManager: Connection released: [id: 17][route: {}->http://minio:9000][total available: 0; route allocated: 0 of 1; total allocated: 0 of 1]\n",
            "25/02/18 20:36:35 DEBUG AmazonHttpClient: Unable to execute HTTP request: minio\n",
            "25/02/18 20:36:35 DEBUG IOStatisticsStoreImpl: Incrementing counter store_io_request by 2 with final value 14\n",
            "25/02/18 20:36:35 DEBUG latency: MaxRetriesExceeded=[true], ServiceName=[Amazon S3], ServiceEndpoint=[http://minio:9000], Exception=[java.net.UnknownHostException: minio: Temporary failure in name resolution, java.net.UnknownHostException: minio], RequestType=[GetObjectMetadataRequest], AWSRequestID=[null, null], HttpClientPoolPendingCount=0, RetryCapacityConsumed=35, HttpClientPoolAvailableCount=0, RequestCount=2, Exception=2, HttpClientPoolLeasedCount=0, RetryPauseTime=[31.225], ClientExecuteTime=[8045.733], HttpRequestTime=[8010.149, 1.249], ApiCallLatency=[8045.336], RequestSigningTime=[0.891, 0.595], CredentialsRequestTime=[0.011, 0.006, 0.024], \n",
            "25/02/18 20:36:35 DEBUG IOStatisticsStoreImpl: Incrementing counter store_io_retry by 1 with final value 7\n",
            "25/02/18 20:36:35 DEBUG IOStatisticsStoreImpl: Incrementing counter ignored_errors by 1 with final value 7\n",
            "25/02/18 20:36:39 DEBUG wire: http-outgoing-16 << \"[read] I/O error: Read timed out\"\n",
            "25/02/18 20:36:39 DEBUG DefaultManagedHttpClientConnection: http-outgoing-16: Close connection\n",
            "25/02/18 20:36:39 DEBUG DefaultManagedHttpClientConnection: http-outgoing-16: Shutdown connection\n",
            "25/02/18 20:36:39 DEBUG MainClientExec: Connection discarded\n",
            "25/02/18 20:36:39 DEBUG PoolingHttpClientConnectionManager: Connection released: [id: 16][route: {}->http://localhost:9000][total available: 0; route allocated: 0 of 1; total allocated: 0 of 1]\n",
            "25/02/18 20:36:39 DEBUG AmazonHttpClient: Unable to execute HTTP request: Read timed out\n",
            "25/02/18 20:36:39 DEBUG IOStatisticsStoreImpl: Incrementing counter store_io_request by 2 with final value 4\n",
            "25/02/18 20:36:39 DEBUG latency: MaxRetriesExceeded=[true], ServiceName=[Amazon S3], ServiceEndpoint=[http://localhost:9000], Exception=[java.net.SocketTimeoutException: Read timed out, java.net.SocketTimeoutException: Read timed out], RequestType=[GetObjectMetadataRequest], AWSRequestID=[null, null], HttpClientPoolPendingCount=0, RetryCapacityConsumed=10, HttpClientPoolAvailableCount=0, RequestCount=2, Exception=2, HttpClientPoolLeasedCount=0, RetryPauseTime=[21.479], ClientExecuteTime=[10056.386], HttpClientSendRequestTime=[1.898, 3.026], HttpRequestTime=[5016.121, 5013.908], ApiCallLatency=[10055.831], RequestSigningTime=[0.784, 1.143], CredentialsRequestTime=[0.016, 0.018, 0.022], HttpClientReceiveResponseTime=[5007.601, 5007.83], \n",
            "25/02/18 20:36:39 DEBUG IOStatisticsStoreImpl: Incrementing counter store_io_retry by 1 with final value 2\n",
            "25/02/18 20:36:39 DEBUG IOStatisticsStoreImpl: Incrementing counter ignored_errors by 1 with final value 2\n",
            "25/02/18 20:36:41 DEBUG Invoker: retry #2\n",
            "25/02/18 20:36:41 DEBUG IOStatisticsStoreImpl: Incrementing counter object_metadata_request by 1 with final value 3\n",
            "25/02/18 20:36:41 DEBUG IOStatisticsStoreImpl: Incrementing counter action_http_head_request by 1 with final value 3\n",
            "25/02/18 20:36:41 DEBUG S3AFileSystem: HEAD test.parquet with change tracker null\n",
            "25/02/18 20:36:41 DEBUG request: Sending Request: HEAD http://localhost:9000 /wba/test.parquet Headers: (amz-sdk-invocation-id: 7035abac-2525-d682-6a2c-20d1b74e75f3, Content-Type: application/octet-stream, User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy, ) \n",
            "25/02/18 20:36:41 DEBUG AWS4Signer: AWS4 Canonical Request: '\"HEAD\n",
            "/wba/test.parquet\n",
            "\n",
            "amz-sdk-invocation-id:7035abac-2525-d682-6a2c-20d1b74e75f3\n",
            "amz-sdk-request:attempt=1;max=2\n",
            "amz-sdk-retry:0/0/490\n",
            "content-type:application/octet-stream\n",
            "host:localhost:9000\n",
            "user-agent:Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy\n",
            "x-amz-content-sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "x-amz-date:20250218T203641Z\n",
            "\n",
            "amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date\n",
            "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\"\n",
            "25/02/18 20:36:41 DEBUG AWS4Signer: AWS4 String to Sign: '\"AWS4-HMAC-SHA256\n",
            "20250218T203641Z\n",
            "20250218/us-east-1/s3/aws4_request\n",
            "bfc9269fbceb9b89bb581251046fcca522ffdf88cedb3c3e35dbd2e3e84d7350\"\n",
            "25/02/18 20:36:41 DEBUG RequestAddCookies: CookieSpec selected: default\n",
            "25/02/18 20:36:41 DEBUG RequestAuthCache: Auth cache not set in the context\n",
            "25/02/18 20:36:41 DEBUG PoolingHttpClientConnectionManager: Connection request: [route: {}->http://localhost:9000][total available: 0; route allocated: 0 of 1; total allocated: 0 of 1]\n",
            "25/02/18 20:36:41 DEBUG PoolingHttpClientConnectionManager: Connection leased: [id: 18][route: {}->http://localhost:9000][total available: 0; route allocated: 1 of 1; total allocated: 1 of 1]\n",
            "25/02/18 20:36:41 DEBUG MainClientExec: Opening connection {}->http://localhost:9000\n",
            "25/02/18 20:36:41 DEBUG DefaultHttpClientConnectionOperator: Connecting to localhost/127.0.0.1:9000\n",
            "25/02/18 20:36:41 DEBUG DefaultHttpClientConnectionOperator: Connection established 127.0.0.1:48214<->127.0.0.1:9000\n",
            "25/02/18 20:36:41 DEBUG DefaultManagedHttpClientConnection: http-outgoing-18: set socket timeout to 5000\n",
            "25/02/18 20:36:41 DEBUG MainClientExec: Executing request HEAD /wba/test.parquet HTTP/1.1\n",
            "25/02/18 20:36:41 DEBUG MainClientExec: Proxy auth state: UNCHALLENGED\n",
            "25/02/18 20:36:41 DEBUG headers: http-outgoing-18 >> HEAD /wba/test.parquet HTTP/1.1\n",
            "25/02/18 20:36:41 DEBUG headers: http-outgoing-18 >> Host: localhost:9000\n",
            "25/02/18 20:36:41 DEBUG headers: http-outgoing-18 >> amz-sdk-invocation-id: 7035abac-2525-d682-6a2c-20d1b74e75f3\n",
            "25/02/18 20:36:41 DEBUG headers: http-outgoing-18 >> amz-sdk-request: attempt=1;max=2\n",
            "25/02/18 20:36:41 DEBUG headers: http-outgoing-18 >> amz-sdk-retry: 0/0/490\n",
            "25/02/18 20:36:41 DEBUG headers: http-outgoing-18 >> Authorization: AWS4-HMAC-SHA256 Credential=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=cc652c6b1bce7bb17003db8deaa6881350887b34f5798949d8bd001676e744d5\n",
            "25/02/18 20:36:41 DEBUG headers: http-outgoing-18 >> Content-Type: application/octet-stream\n",
            "25/02/18 20:36:41 DEBUG headers: http-outgoing-18 >> User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy\n",
            "25/02/18 20:36:41 DEBUG headers: http-outgoing-18 >> x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "25/02/18 20:36:41 DEBUG headers: http-outgoing-18 >> X-Amz-Date: 20250218T203641Z\n",
            "25/02/18 20:36:41 DEBUG headers: http-outgoing-18 >> Connection: Keep-Alive\n",
            "25/02/18 20:36:41 DEBUG wire: http-outgoing-18 >> \"HEAD /wba/test.parquet HTTP/1.1[\\r][\\n]\"\n",
            "25/02/18 20:36:41 DEBUG wire: http-outgoing-18 >> \"Host: localhost:9000[\\r][\\n]\"\n",
            "25/02/18 20:36:41 DEBUG wire: http-outgoing-18 >> \"amz-sdk-invocation-id: 7035abac-2525-d682-6a2c-20d1b74e75f3[\\r][\\n]\"\n",
            "25/02/18 20:36:41 DEBUG wire: http-outgoing-18 >> \"amz-sdk-request: attempt=1;max=2[\\r][\\n]\"\n",
            "25/02/18 20:36:41 DEBUG wire: http-outgoing-18 >> \"amz-sdk-retry: 0/0/490[\\r][\\n]\"\n",
            "25/02/18 20:36:41 DEBUG wire: http-outgoing-18 >> \"Authorization: AWS4-HMAC-SHA256 Credential=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=cc652c6b1bce7bb17003db8deaa6881350887b34f5798949d8bd001676e744d5[\\r][\\n]\"\n",
            "25/02/18 20:36:41 DEBUG wire: http-outgoing-18 >> \"Content-Type: application/octet-stream[\\r][\\n]\"\n",
            "25/02/18 20:36:41 DEBUG wire: http-outgoing-18 >> \"User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy[\\r][\\n]\"\n",
            "25/02/18 20:36:41 DEBUG wire: http-outgoing-18 >> \"x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855[\\r][\\n]\"\n",
            "25/02/18 20:36:41 DEBUG wire: http-outgoing-18 >> \"X-Amz-Date: 20250218T203641Z[\\r][\\n]\"\n",
            "25/02/18 20:36:41 DEBUG wire: http-outgoing-18 >> \"Connection: Keep-Alive[\\r][\\n]\"\n",
            "25/02/18 20:36:41 DEBUG wire: http-outgoing-18 >> \"[\\r][\\n]\"\n",
            "25/02/18 20:36:41 DEBUG wire: http-outgoing-18 << \"[0xff][0x0][0x0][0x0][0x0][0x0][0x0][0x0][0x1]\"\n",
            "25/02/18 20:36:41 DEBUG wire: http-outgoing-18 << \"-[0x1]d: 7035abac-2525-d682-6a2c-20d1b74e75f3[\\r][\\n]\"\n",
            "25/02/18 20:36:41 DEBUG wire: http-outgoing-18 << \"amz-[0x1]dk-request: attempt=1;max=2[\\r][\\n]\"\n",
            "25/02/18 20:36:41 DEBUG wire: http-outgoing-18 << \"amz-sdk-retry: 0[0x1]0/490[\\r][\\n]\"\n",
            "25/02/18 20:36:41 DEBUG wire: http-outgoing-18 << \"Authorization: AWS4-HMAC-SHA256 Credentia[0x0]=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-reque[0x1]t;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=cc652c6b1bce7[0x0]b17003db8deaa6881350887b34f5798949d8bd001676e744d5[\\r][\\n]\"\n",
            "25/02/18 20:36:41 DEBUG wire: http-outgoing-18 << \"Con[0x0]ent-Type: application/octet-stream[\\r][\\n]\"\n",
            "25/02/18 20:36:41 DEBUG wire: http-outgoing-18 << \"User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsof\"\n",
            "25/02/18 20:36:41 DEBUG DefaultHttpResponseParser: Garbage in response: \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0001-\u0001d: 7035abac-2525-d682-6a2c-20d1b74e75f3\n",
            "25/02/18 20:36:41 DEBUG DefaultHttpResponseParser: Garbage in response: amz-\u0001dk-request: attempt=1;max=2\n",
            "25/02/18 20:36:41 DEBUG DefaultHttpResponseParser: Garbage in response: amz-sdk-retry: 0\u00010/490\n",
            "25/02/18 20:36:41 DEBUG DefaultHttpResponseParser: Garbage in response: Authorization: AWS4-HMAC-SHA256 Credentia\u0000=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-reque\u0001t;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=cc652c6b1bce7\u0000b17003db8deaa6881350887b34f5798949d8bd001676e744d5\n",
            "25/02/18 20:36:41 DEBUG DefaultHttpResponseParser: Garbage in response: Con\u0000ent-Type: application/octet-stream\n",
            "25/02/18 20:36:46 DEBUG wire: http-outgoing-18 << \"[read] I/O error: Read timed out\"\n",
            "25/02/18 20:36:46 DEBUG DefaultManagedHttpClientConnection: http-outgoing-18: Close connection\n",
            "25/02/18 20:36:46 DEBUG DefaultManagedHttpClientConnection: http-outgoing-18: Shutdown connection\n",
            "25/02/18 20:36:46 DEBUG MainClientExec: Connection discarded\n",
            "25/02/18 20:36:46 DEBUG PoolingHttpClientConnectionManager: Connection released: [id: 18][route: {}->http://localhost:9000][total available: 0; route allocated: 0 of 1; total allocated: 0 of 1]\n",
            "25/02/18 20:36:46 DEBUG AmazonHttpClient: Unable to execute HTTP request: Read timed out Request will be retried.\n",
            "25/02/18 20:36:46 DEBUG request: Retrying Request: HEAD http://localhost:9000 /wba/test.parquet Headers: (amz-sdk-invocation-id: 7035abac-2525-d682-6a2c-20d1b74e75f3, Content-Type: application/octet-stream, User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy, ) \n",
            "25/02/18 20:36:46 DEBUG AmazonHttpClient: Retriable error detected, will retry in 75ms, attempt number: 0\n",
            "25/02/18 20:36:46 DEBUG AWS4Signer: AWS4 Canonical Request: '\"HEAD\n",
            "/wba/test.parquet\n",
            "\n",
            "amz-sdk-invocation-id:7035abac-2525-d682-6a2c-20d1b74e75f3\n",
            "amz-sdk-request:attempt=2;max=2\n",
            "amz-sdk-retry:1/75/485\n",
            "content-type:application/octet-stream\n",
            "host:localhost:9000\n",
            "user-agent:Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy\n",
            "x-amz-content-sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "x-amz-date:20250218T203646Z\n",
            "\n",
            "amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date\n",
            "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\"\n",
            "25/02/18 20:36:46 DEBUG AWS4Signer: AWS4 String to Sign: '\"AWS4-HMAC-SHA256\n",
            "20250218T203646Z\n",
            "20250218/us-east-1/s3/aws4_request\n",
            "8c2c9e6fadc516d100428e689f46a417a61b3d66b2de3c0c1bf7411b56075ff9\"\n",
            "25/02/18 20:36:46 DEBUG RequestAddCookies: CookieSpec selected: default\n",
            "25/02/18 20:36:46 DEBUG RequestAuthCache: Auth cache not set in the context\n",
            "25/02/18 20:36:46 DEBUG PoolingHttpClientConnectionManager: Connection request: [route: {}->http://localhost:9000][total available: 0; route allocated: 0 of 1; total allocated: 0 of 1]\n",
            "25/02/18 20:36:46 DEBUG PoolingHttpClientConnectionManager: Connection leased: [id: 19][route: {}->http://localhost:9000][total available: 0; route allocated: 1 of 1; total allocated: 1 of 1]\n",
            "25/02/18 20:36:46 DEBUG MainClientExec: Opening connection {}->http://localhost:9000\n",
            "25/02/18 20:36:46 DEBUG DefaultHttpClientConnectionOperator: Connecting to localhost/127.0.0.1:9000\n",
            "25/02/18 20:36:46 DEBUG DefaultHttpClientConnectionOperator: Connection established 127.0.0.1:48246<->127.0.0.1:9000\n",
            "25/02/18 20:36:46 DEBUG DefaultManagedHttpClientConnection: http-outgoing-19: set socket timeout to 5000\n",
            "25/02/18 20:36:46 DEBUG MainClientExec: Executing request HEAD /wba/test.parquet HTTP/1.1\n",
            "25/02/18 20:36:46 DEBUG MainClientExec: Proxy auth state: UNCHALLENGED\n",
            "25/02/18 20:36:46 DEBUG headers: http-outgoing-19 >> HEAD /wba/test.parquet HTTP/1.1\n",
            "25/02/18 20:36:46 DEBUG headers: http-outgoing-19 >> Host: localhost:9000\n",
            "25/02/18 20:36:46 DEBUG headers: http-outgoing-19 >> amz-sdk-invocation-id: 7035abac-2525-d682-6a2c-20d1b74e75f3\n",
            "25/02/18 20:36:46 DEBUG headers: http-outgoing-19 >> amz-sdk-request: attempt=2;max=2\n",
            "25/02/18 20:36:46 DEBUG headers: http-outgoing-19 >> amz-sdk-retry: 1/75/485\n",
            "25/02/18 20:36:46 DEBUG headers: http-outgoing-19 >> Authorization: AWS4-HMAC-SHA256 Credential=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=27dc5b5e4696bce93c054a042261e2c08f7a595b5b7685e6e7893665d77b67bf\n",
            "25/02/18 20:36:46 DEBUG headers: http-outgoing-19 >> Content-Type: application/octet-stream\n",
            "25/02/18 20:36:46 DEBUG headers: http-outgoing-19 >> User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy\n",
            "25/02/18 20:36:46 DEBUG headers: http-outgoing-19 >> x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "25/02/18 20:36:46 DEBUG headers: http-outgoing-19 >> X-Amz-Date: 20250218T203646Z\n",
            "25/02/18 20:36:46 DEBUG headers: http-outgoing-19 >> Connection: Keep-Alive\n",
            "25/02/18 20:36:46 DEBUG wire: http-outgoing-19 >> \"HEAD /wba/test.parquet HTTP/1.1[\\r][\\n]\"\n",
            "25/02/18 20:36:46 DEBUG wire: http-outgoing-19 >> \"Host: localhost:9000[\\r][\\n]\"\n",
            "25/02/18 20:36:46 DEBUG wire: http-outgoing-19 >> \"amz-sdk-invocation-id: 7035abac-2525-d682-6a2c-20d1b74e75f3[\\r][\\n]\"\n",
            "25/02/18 20:36:46 DEBUG wire: http-outgoing-19 >> \"amz-sdk-request: attempt=2;max=2[\\r][\\n]\"\n",
            "25/02/18 20:36:46 DEBUG wire: http-outgoing-19 >> \"amz-sdk-retry: 1/75/485[\\r][\\n]\"\n",
            "25/02/18 20:36:46 DEBUG wire: http-outgoing-19 >> \"Authorization: AWS4-HMAC-SHA256 Credential=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=27dc5b5e4696bce93c054a042261e2c08f7a595b5b7685e6e7893665d77b67bf[\\r][\\n]\"\n",
            "25/02/18 20:36:46 DEBUG wire: http-outgoing-19 >> \"Content-Type: application/octet-stream[\\r][\\n]\"\n",
            "25/02/18 20:36:46 DEBUG wire: http-outgoing-19 >> \"User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy[\\r][\\n]\"\n",
            "25/02/18 20:36:46 DEBUG wire: http-outgoing-19 >> \"x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855[\\r][\\n]\"\n",
            "25/02/18 20:36:46 DEBUG wire: http-outgoing-19 >> \"X-Amz-Date: 20250218T203646Z[\\r][\\n]\"\n",
            "25/02/18 20:36:46 DEBUG wire: http-outgoing-19 >> \"Connection: Keep-Alive[\\r][\\n]\"\n",
            "25/02/18 20:36:46 DEBUG wire: http-outgoing-19 >> \"[\\r][\\n]\"\n",
            "25/02/18 20:36:46 DEBUG wire: http-outgoing-19 << \"[0xff][0x0][0x0][0x0][0x0][0x0][0x0][0x0][0x1]\"\n",
            "25/02/18 20:36:46 DEBUG wire: http-outgoing-19 << \"-[0x1]d: 7035abac-2525-d682-6a2c-20d1b74e75f3[\\r][\\n]\"\n",
            "25/02/18 20:36:46 DEBUG wire: http-outgoing-19 << \"amz-[0x1]dk-request: attempt=2;max=2[\\r][\\n]\"\n",
            "25/02/18 20:36:46 DEBUG wire: http-outgoing-19 << \"amz-sdk-retry: 1[0x1]75/485[\\r][\\n]\"\n",
            "25/02/18 20:36:46 DEBUG wire: http-outgoing-19 << \"Authorization: AWS4-HMAC-SHA256 Credentia[0x0]=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-reque[0x1]t;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=27dc5b5e4696b[0x1]e93c054a042261e2c08f7a595b5b7685e6e7893665d77b67bf[\\r][\\n]\"\n",
            "25/02/18 20:36:46 DEBUG wire: http-outgoing-19 << \"Content-Type: application/octet-stream[\\r][\\n]\"\n",
            "25/02/18 20:36:46 DEBUG wire: http-outgoing-19 << \"User-A[0x1]ent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microso[0x0]t-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cf\"\n",
            "25/02/18 20:36:46 DEBUG DefaultHttpResponseParser: Garbage in response: \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0001-\u0001d: 7035abac-2525-d682-6a2c-20d1b74e75f3\n",
            "25/02/18 20:36:46 DEBUG DefaultHttpResponseParser: Garbage in response: amz-\u0001dk-request: attempt=2;max=2\n",
            "25/02/18 20:36:46 DEBUG DefaultHttpResponseParser: Garbage in response: amz-sdk-retry: 1\u000175/485\n",
            "25/02/18 20:36:46 DEBUG DefaultHttpResponseParser: Garbage in response: Authorization: AWS4-HMAC-SHA256 Credentia\u0000=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-reque\u0001t;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=27dc5b5e4696b\u0001e93c054a042261e2c08f7a595b5b7685e6e7893665d77b67bf\n",
            "25/02/18 20:36:46 DEBUG DefaultHttpResponseParser: Garbage in response: Content-Type: application/octet-stream\n",
            "25/02/18 20:36:51 DEBUG wire: http-outgoing-19 << \"[read] I/O error: Read timed out\"\n",
            "25/02/18 20:36:51 DEBUG DefaultManagedHttpClientConnection: http-outgoing-19: Close connection\n",
            "25/02/18 20:36:51 DEBUG DefaultManagedHttpClientConnection: http-outgoing-19: Shutdown connection\n",
            "25/02/18 20:36:51 DEBUG MainClientExec: Connection discarded\n",
            "25/02/18 20:36:51 DEBUG PoolingHttpClientConnectionManager: Connection released: [id: 19][route: {}->http://localhost:9000][total available: 0; route allocated: 0 of 1; total allocated: 0 of 1]\n",
            "25/02/18 20:36:51 DEBUG AmazonHttpClient: Unable to execute HTTP request: Read timed out\n",
            "25/02/18 20:36:51 DEBUG IOStatisticsStoreImpl: Incrementing counter store_io_request by 2 with final value 6\n",
            "25/02/18 20:36:51 DEBUG latency: MaxRetriesExceeded=[true], ServiceName=[Amazon S3], ServiceEndpoint=[http://localhost:9000], Exception=[java.net.SocketTimeoutException: Read timed out, java.net.SocketTimeoutException: Read timed out], RequestType=[GetObjectMetadataRequest], AWSRequestID=[null, null], HttpClientPoolPendingCount=0, RetryCapacityConsumed=15, HttpClientPoolAvailableCount=0, RequestCount=2, Exception=2, HttpClientPoolLeasedCount=0, RetryPauseTime=[75.552], ClientExecuteTime=[10105.676], HttpClientSendRequestTime=[1.525, 2.374], HttpRequestTime=[5012.141, 5013.153], ApiCallLatency=[10105.207], RequestSigningTime=[0.78, 1.41], CredentialsRequestTime=[0.014, 0.01, 0.02], HttpClientReceiveResponseTime=[5007.829, 5007.616], \n",
            "25/02/18 20:36:51 DEBUG IOStatisticsStoreImpl: Incrementing counter store_io_retry by 1 with final value 3\n",
            "25/02/18 20:36:51 DEBUG IOStatisticsStoreImpl: Incrementing counter ignored_errors by 1 with final value 3\n",
            "25/02/18 20:36:55 DEBUG Invoker: retry #3\n",
            "25/02/18 20:36:55 DEBUG IOStatisticsStoreImpl: Incrementing counter object_metadata_request by 1 with final value 4\n",
            "25/02/18 20:36:55 DEBUG IOStatisticsStoreImpl: Incrementing counter action_http_head_request by 1 with final value 4\n",
            "25/02/18 20:36:55 DEBUG S3AFileSystem: HEAD test.parquet with change tracker null\n",
            "25/02/18 20:36:55 DEBUG request: Sending Request: HEAD http://localhost:9000 /wba/test.parquet Headers: (amz-sdk-invocation-id: 0466fef7-6eeb-2017-8f44-11b707445c92, Content-Type: application/octet-stream, User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy, ) \n",
            "25/02/18 20:36:55 DEBUG AWS4Signer: AWS4 Canonical Request: '\"HEAD\n",
            "/wba/test.parquet\n",
            "\n",
            "amz-sdk-invocation-id:0466fef7-6eeb-2017-8f44-11b707445c92\n",
            "amz-sdk-request:attempt=1;max=2\n",
            "amz-sdk-retry:0/0/485\n",
            "content-type:application/octet-stream\n",
            "host:localhost:9000\n",
            "user-agent:Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy\n",
            "x-amz-content-sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "x-amz-date:20250218T203655Z\n",
            "\n",
            "amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date\n",
            "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\"\n",
            "25/02/18 20:36:55 DEBUG AWS4Signer: AWS4 String to Sign: '\"AWS4-HMAC-SHA256\n",
            "20250218T203655Z\n",
            "20250218/us-east-1/s3/aws4_request\n",
            "3d88b96510dfd688ccc6ef38b503c3f019d014d2f4768381202de70cec4e1702\"\n",
            "25/02/18 20:36:55 DEBUG RequestAddCookies: CookieSpec selected: default\n",
            "25/02/18 20:36:55 DEBUG RequestAuthCache: Auth cache not set in the context\n",
            "25/02/18 20:36:55 DEBUG PoolingHttpClientConnectionManager: Connection request: [route: {}->http://localhost:9000][total available: 0; route allocated: 0 of 1; total allocated: 0 of 1]\n",
            "25/02/18 20:36:55 DEBUG PoolingHttpClientConnectionManager: Connection leased: [id: 20][route: {}->http://localhost:9000][total available: 0; route allocated: 1 of 1; total allocated: 1 of 1]\n",
            "25/02/18 20:36:55 DEBUG MainClientExec: Opening connection {}->http://localhost:9000\n",
            "25/02/18 20:36:55 DEBUG DefaultHttpClientConnectionOperator: Connecting to localhost/127.0.0.1:9000\n",
            "25/02/18 20:36:55 DEBUG DefaultHttpClientConnectionOperator: Connection established 127.0.0.1:35446<->127.0.0.1:9000\n",
            "25/02/18 20:36:55 DEBUG DefaultManagedHttpClientConnection: http-outgoing-20: set socket timeout to 5000\n",
            "25/02/18 20:36:55 DEBUG MainClientExec: Executing request HEAD /wba/test.parquet HTTP/1.1\n",
            "25/02/18 20:36:55 DEBUG MainClientExec: Proxy auth state: UNCHALLENGED\n",
            "25/02/18 20:36:55 DEBUG headers: http-outgoing-20 >> HEAD /wba/test.parquet HTTP/1.1\n",
            "25/02/18 20:36:55 DEBUG headers: http-outgoing-20 >> Host: localhost:9000\n",
            "25/02/18 20:36:55 DEBUG headers: http-outgoing-20 >> amz-sdk-invocation-id: 0466fef7-6eeb-2017-8f44-11b707445c92\n",
            "25/02/18 20:36:55 DEBUG headers: http-outgoing-20 >> amz-sdk-request: attempt=1;max=2\n",
            "25/02/18 20:36:55 DEBUG headers: http-outgoing-20 >> amz-sdk-retry: 0/0/485\n",
            "25/02/18 20:36:55 DEBUG headers: http-outgoing-20 >> Authorization: AWS4-HMAC-SHA256 Credential=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=9ab6d645077fefb3fbdbd536ba9e01bce553dcda099e93fedc067efd3bf1290f\n",
            "25/02/18 20:36:55 DEBUG headers: http-outgoing-20 >> Content-Type: application/octet-stream\n",
            "25/02/18 20:36:55 DEBUG headers: http-outgoing-20 >> User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy\n",
            "25/02/18 20:36:55 DEBUG headers: http-outgoing-20 >> x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "25/02/18 20:36:55 DEBUG headers: http-outgoing-20 >> X-Amz-Date: 20250218T203655Z\n",
            "25/02/18 20:36:55 DEBUG headers: http-outgoing-20 >> Connection: Keep-Alive\n",
            "25/02/18 20:36:55 DEBUG wire: http-outgoing-20 >> \"HEAD /wba/test.parquet HTTP/1.1[\\r][\\n]\"\n",
            "25/02/18 20:36:55 DEBUG wire: http-outgoing-20 >> \"Host: localhost:9000[\\r][\\n]\"\n",
            "25/02/18 20:36:55 DEBUG wire: http-outgoing-20 >> \"amz-sdk-invocation-id: 0466fef7-6eeb-2017-8f44-11b707445c92[\\r][\\n]\"\n",
            "25/02/18 20:36:55 DEBUG wire: http-outgoing-20 >> \"amz-sdk-request: attempt=1;max=2[\\r][\\n]\"\n",
            "25/02/18 20:36:55 DEBUG wire: http-outgoing-20 >> \"amz-sdk-retry: 0/0/485[\\r][\\n]\"\n",
            "25/02/18 20:36:55 DEBUG wire: http-outgoing-20 >> \"Authorization: AWS4-HMAC-SHA256 Credential=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=9ab6d645077fefb3fbdbd536ba9e01bce553dcda099e93fedc067efd3bf1290f[\\r][\\n]\"\n",
            "25/02/18 20:36:55 DEBUG wire: http-outgoing-20 >> \"Content-Type: application/octet-stream[\\r][\\n]\"\n",
            "25/02/18 20:36:55 DEBUG wire: http-outgoing-20 >> \"User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy[\\r][\\n]\"\n",
            "25/02/18 20:36:55 DEBUG wire: http-outgoing-20 >> \"x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855[\\r][\\n]\"\n",
            "25/02/18 20:36:55 DEBUG wire: http-outgoing-20 >> \"X-Amz-Date: 20250218T203655Z[\\r][\\n]\"\n",
            "25/02/18 20:36:55 DEBUG wire: http-outgoing-20 >> \"Connection: Keep-Alive[\\r][\\n]\"\n",
            "25/02/18 20:36:55 DEBUG wire: http-outgoing-20 >> \"[\\r][\\n]\"\n",
            "25/02/18 20:36:55 DEBUG wire: http-outgoing-20 << \"[0xff][0x0][0x0][0x0][0x0][0x0][0x0][0x0][0x1]\"\n",
            "25/02/18 20:36:55 DEBUG wire: http-outgoing-20 << \"-[0x1]d: 0466fef7-6eeb-2017-8f44-11b707445c92[\\r][\\n]\"\n",
            "25/02/18 20:36:55 DEBUG wire: http-outgoing-20 << \"amz-[0x1]dk-request: attempt=1;max=2[\\r][\\n]\"\n",
            "25/02/18 20:36:55 DEBUG wire: http-outgoing-20 << \"amz-sdk-retry: 0[0x1]0/485[\\r][\\n]\"\n",
            "25/02/18 20:36:55 DEBUG wire: http-outgoing-20 << \"Authorization: AWS4-HMAC-SHA256 Credentia[0x0]=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-reque[0x1]t;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=9ab6d645077fe[0x0]b3fbdbd536ba9e01bce553dcda099e93fedc067efd3bf1290f[\\r][\\n]\"\n",
            "25/02/18 20:36:55 DEBUG wire: http-outgoing-20 << \"Content-Type: application/octet-stream[\\r][\\n]\"\n",
            "25/02/18 20:36:55 DEBUG wire: http-outgoing-20 << \"User-Agen[0x0]: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.1[0x0]+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 ven[0x0]or/Debian cfg/retry-mode/legacy[\\r][\\n]\"\n",
            "25/02/18 20:36:55 DEBUG wire: http-outgoing-20 << \"x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991[0x0]7852b855[\\r][\\n]\"\n",
            "25/02/18 20:36:55 DEBUG wire: http-outgoing-20 << \"X-Amz-Date: 20250218T203655Z[\\r][\\n]\"\n",
            "25/02/18 20:36:55 DEBUG wire: http-outgoing-20 << \"Connecti\"\n",
            "25/02/18 20:36:55 DEBUG DefaultHttpResponseParser: Garbage in response: \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0001-\u0001d: 0466fef7-6eeb-2017-8f44-11b707445c92\n",
            "25/02/18 20:36:55 DEBUG DefaultHttpResponseParser: Garbage in response: amz-\u0001dk-request: attempt=1;max=2\n",
            "25/02/18 20:36:55 DEBUG DefaultHttpResponseParser: Garbage in response: amz-sdk-retry: 0\u00010/485\n",
            "25/02/18 20:36:55 DEBUG DefaultHttpResponseParser: Garbage in response: Authorization: AWS4-HMAC-SHA256 Credentia\u0000=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-reque\u0001t;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=9ab6d645077fe\u0000b3fbdbd536ba9e01bce553dcda099e93fedc067efd3bf1290f\n",
            "25/02/18 20:36:55 DEBUG DefaultHttpResponseParser: Garbage in response: Content-Type: application/octet-stream\n",
            "25/02/18 20:36:55 DEBUG DefaultHttpResponseParser: Garbage in response: User-Agen\u0000: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.1\u0000+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 ven\u0000or/Debian cfg/retry-mode/legacy\n",
            "25/02/18 20:36:55 DEBUG DefaultHttpResponseParser: Garbage in response: x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991\u00007852b855\n",
            "25/02/18 20:36:55 DEBUG DefaultHttpResponseParser: Garbage in response: X-Amz-Date: 20250218T203655Z\n",
            "25/02/18 20:37:00 DEBUG wire: http-outgoing-20 << \"[read] I/O error: Read timed out\"\n",
            "25/02/18 20:37:00 DEBUG DefaultManagedHttpClientConnection: http-outgoing-20: Close connection\n",
            "25/02/18 20:37:00 DEBUG DefaultManagedHttpClientConnection: http-outgoing-20: Shutdown connection\n",
            "25/02/18 20:37:00 DEBUG MainClientExec: Connection discarded\n",
            "25/02/18 20:37:00 DEBUG PoolingHttpClientConnectionManager: Connection released: [id: 20][route: {}->http://localhost:9000][total available: 0; route allocated: 0 of 1; total allocated: 0 of 1]\n",
            "25/02/18 20:37:00 DEBUG AmazonHttpClient: Unable to execute HTTP request: Read timed out Request will be retried.\n",
            "25/02/18 20:37:00 DEBUG request: Retrying Request: HEAD http://localhost:9000 /wba/test.parquet Headers: (amz-sdk-invocation-id: 0466fef7-6eeb-2017-8f44-11b707445c92, Content-Type: application/octet-stream, User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy, ) \n",
            "25/02/18 20:37:00 DEBUG AmazonHttpClient: Retriable error detected, will retry in 81ms, attempt number: 0\n",
            "25/02/18 20:37:00 DEBUG AWS4Signer: AWS4 Canonical Request: '\"HEAD\n",
            "/wba/test.parquet\n",
            "\n",
            "amz-sdk-invocation-id:0466fef7-6eeb-2017-8f44-11b707445c92\n",
            "amz-sdk-request:attempt=2;max=2\n",
            "amz-sdk-retry:1/81/480\n",
            "content-type:application/octet-stream\n",
            "host:localhost:9000\n",
            "user-agent:Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy\n",
            "x-amz-content-sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "x-amz-date:20250218T203700Z\n",
            "\n",
            "amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date\n",
            "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\"\n",
            "25/02/18 20:37:00 DEBUG AWS4Signer: AWS4 String to Sign: '\"AWS4-HMAC-SHA256\n",
            "20250218T203700Z\n",
            "20250218/us-east-1/s3/aws4_request\n",
            "3c839eef22e76f44e93d9b1dda7872184af47683ac465c68935a5d4208eeab18\"\n",
            "25/02/18 20:37:00 DEBUG RequestAddCookies: CookieSpec selected: default\n",
            "25/02/18 20:37:00 DEBUG RequestAuthCache: Auth cache not set in the context\n",
            "25/02/18 20:37:00 DEBUG PoolingHttpClientConnectionManager: Connection request: [route: {}->http://localhost:9000][total available: 0; route allocated: 0 of 1; total allocated: 0 of 1]\n",
            "25/02/18 20:37:00 DEBUG PoolingHttpClientConnectionManager: Connection leased: [id: 21][route: {}->http://localhost:9000][total available: 0; route allocated: 1 of 1; total allocated: 1 of 1]\n",
            "25/02/18 20:37:00 DEBUG MainClientExec: Opening connection {}->http://localhost:9000\n",
            "25/02/18 20:37:00 DEBUG DefaultHttpClientConnectionOperator: Connecting to localhost/127.0.0.1:9000\n",
            "25/02/18 20:37:00 DEBUG DefaultHttpClientConnectionOperator: Connection established 127.0.0.1:39574<->127.0.0.1:9000\n",
            "25/02/18 20:37:00 DEBUG DefaultManagedHttpClientConnection: http-outgoing-21: set socket timeout to 5000\n",
            "25/02/18 20:37:00 DEBUG MainClientExec: Executing request HEAD /wba/test.parquet HTTP/1.1\n",
            "25/02/18 20:37:00 DEBUG MainClientExec: Proxy auth state: UNCHALLENGED\n",
            "25/02/18 20:37:00 DEBUG headers: http-outgoing-21 >> HEAD /wba/test.parquet HTTP/1.1\n",
            "25/02/18 20:37:00 DEBUG headers: http-outgoing-21 >> Host: localhost:9000\n",
            "25/02/18 20:37:00 DEBUG headers: http-outgoing-21 >> amz-sdk-invocation-id: 0466fef7-6eeb-2017-8f44-11b707445c92\n",
            "25/02/18 20:37:00 DEBUG headers: http-outgoing-21 >> amz-sdk-request: attempt=2;max=2\n",
            "25/02/18 20:37:00 DEBUG headers: http-outgoing-21 >> amz-sdk-retry: 1/81/480\n",
            "25/02/18 20:37:00 DEBUG headers: http-outgoing-21 >> Authorization: AWS4-HMAC-SHA256 Credential=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=fc412930e320bb1b6ac42afef46e50853d76a5a97752f9ff63900bf957fd49a0\n",
            "25/02/18 20:37:00 DEBUG headers: http-outgoing-21 >> Content-Type: application/octet-stream\n",
            "25/02/18 20:37:00 DEBUG headers: http-outgoing-21 >> User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy\n",
            "25/02/18 20:37:00 DEBUG headers: http-outgoing-21 >> x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "25/02/18 20:37:00 DEBUG headers: http-outgoing-21 >> X-Amz-Date: 20250218T203700Z\n",
            "25/02/18 20:37:00 DEBUG headers: http-outgoing-21 >> Connection: Keep-Alive\n",
            "25/02/18 20:37:00 DEBUG wire: http-outgoing-21 >> \"HEAD /wba/test.parquet HTTP/1.1[\\r][\\n]\"\n",
            "25/02/18 20:37:00 DEBUG wire: http-outgoing-21 >> \"Host: localhost:9000[\\r][\\n]\"\n",
            "25/02/18 20:37:00 DEBUG wire: http-outgoing-21 >> \"amz-sdk-invocation-id: 0466fef7-6eeb-2017-8f44-11b707445c92[\\r][\\n]\"\n",
            "25/02/18 20:37:00 DEBUG wire: http-outgoing-21 >> \"amz-sdk-request: attempt=2;max=2[\\r][\\n]\"\n",
            "25/02/18 20:37:00 DEBUG wire: http-outgoing-21 >> \"amz-sdk-retry: 1/81/480[\\r][\\n]\"\n",
            "25/02/18 20:37:00 DEBUG wire: http-outgoing-21 >> \"Authorization: AWS4-HMAC-SHA256 Credential=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=fc412930e320bb1b6ac42afef46e50853d76a5a97752f9ff63900bf957fd49a0[\\r][\\n]\"\n",
            "25/02/18 20:37:00 DEBUG wire: http-outgoing-21 >> \"Content-Type: application/octet-stream[\\r][\\n]\"\n",
            "25/02/18 20:37:00 DEBUG wire: http-outgoing-21 >> \"User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy[\\r][\\n]\"\n",
            "25/02/18 20:37:00 DEBUG wire: http-outgoing-21 >> \"x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855[\\r][\\n]\"\n",
            "25/02/18 20:37:00 DEBUG wire: http-outgoing-21 >> \"X-Amz-Date: 20250218T203700Z[\\r][\\n]\"\n",
            "25/02/18 20:37:00 DEBUG wire: http-outgoing-21 >> \"Connection: Keep-Alive[\\r][\\n]\"\n",
            "25/02/18 20:37:00 DEBUG wire: http-outgoing-21 >> \"[\\r][\\n]\"\n",
            "25/02/18 20:37:00 DEBUG wire: http-outgoing-21 << \"[0xff][0x0][0x0][0x0][0x0][0x0][0x0][0x0][0x1]\"\n",
            "25/02/18 20:37:00 DEBUG wire: http-outgoing-21 << \"-[0x1]d: 0466fef7-6eeb-2017-8f44-11b707445c92[\\r][\\n]\"\n",
            "25/02/18 20:37:00 DEBUG wire: http-outgoing-21 << \"amz-[0x1]dk-request: attempt=2;max=2[\\r][\\n]\"\n",
            "25/02/18 20:37:00 DEBUG wire: http-outgoing-21 << \"amz-sdk-retry: 1[0x1]81/480[\\r][\\n]\"\n",
            "25/02/18 20:37:00 DEBUG wire: http-outgoing-21 << \"Authorization: AWS4-HMAC-SHA256 Credentia[0x0]=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-reque[0x1]t;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=fc412930e320b[0x0]1b6ac42afef46e50853d76a5a97752f9ff63900bf957fd49a0[\\r][\\n]\"\n",
            "25/02/18 20:37:00 DEBUG wire: http-outgoing-21 << \"Content-Type: application/octet-stream[\\r][\\n]\"\n",
            "25/02/18 20:37:00 DEBUG wire: http-outgoing-21 << \"User-A[0x1]ent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microso[0x0]t-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cf\"\n",
            "25/02/18 20:37:00 DEBUG DefaultHttpResponseParser: Garbage in response: \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0001-\u0001d: 0466fef7-6eeb-2017-8f44-11b707445c92\n",
            "25/02/18 20:37:00 DEBUG DefaultHttpResponseParser: Garbage in response: amz-\u0001dk-request: attempt=2;max=2\n",
            "25/02/18 20:37:00 DEBUG DefaultHttpResponseParser: Garbage in response: amz-sdk-retry: 1\u000181/480\n",
            "25/02/18 20:37:00 DEBUG DefaultHttpResponseParser: Garbage in response: Authorization: AWS4-HMAC-SHA256 Credentia\u0000=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-reque\u0001t;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=fc412930e320b\u00001b6ac42afef46e50853d76a5a97752f9ff63900bf957fd49a0\n",
            "25/02/18 20:37:00 DEBUG DefaultHttpResponseParser: Garbage in response: Content-Type: application/octet-stream\n",
            "25/02/18 20:37:05 DEBUG wire: http-outgoing-21 << \"[read] I/O error: Read timed out\"\n",
            "25/02/18 20:37:05 DEBUG DefaultManagedHttpClientConnection: http-outgoing-21: Close connection\n",
            "25/02/18 20:37:05 DEBUG DefaultManagedHttpClientConnection: http-outgoing-21: Shutdown connection\n",
            "25/02/18 20:37:05 DEBUG MainClientExec: Connection discarded\n",
            "25/02/18 20:37:05 DEBUG PoolingHttpClientConnectionManager: Connection released: [id: 21][route: {}->http://localhost:9000][total available: 0; route allocated: 0 of 1; total allocated: 0 of 1]\n",
            "25/02/18 20:37:05 DEBUG AmazonHttpClient: Unable to execute HTTP request: Read timed out\n",
            "25/02/18 20:37:05 DEBUG IOStatisticsStoreImpl: Incrementing counter store_io_request by 2 with final value 8\n",
            "25/02/18 20:37:05 DEBUG latency: MaxRetriesExceeded=[true], ServiceName=[Amazon S3], ServiceEndpoint=[http://localhost:9000], Exception=[java.net.SocketTimeoutException: Read timed out, java.net.SocketTimeoutException: Read timed out], RequestType=[GetObjectMetadataRequest], AWSRequestID=[null, null], HttpClientPoolPendingCount=0, RetryCapacityConsumed=20, HttpClientPoolAvailableCount=0, RequestCount=2, Exception=2, HttpClientPoolLeasedCount=0, RetryPauseTime=[81.155], ClientExecuteTime=[10102.263], HttpClientSendRequestTime=[0.732, 0.794], HttpRequestTime=[5008.942, 5009.331], ApiCallLatency=[10101.843], RequestSigningTime=[0.288, 0.971], CredentialsRequestTime=[0.01, 0.006, 0.011], HttpClientReceiveResponseTime=[5006.159, 5006.436], \n",
            "25/02/18 20:37:05 DEBUG IOStatisticsStoreImpl: Incrementing counter store_io_retry by 1 with final value 4\n",
            "25/02/18 20:37:05 DEBUG IOStatisticsStoreImpl: Incrementing counter ignored_errors by 1 with final value 4\n",
            "25/02/18 20:37:10 DEBUG PoolingHttpClientConnectionManager: Closing connections idle longer than 60000 MILLISECONDS\n",
            "25/02/18 20:37:10 DEBUG PoolingHttpClientConnectionManager: Closing connections idle longer than 60000 MILLISECONDS\n",
            "25/02/18 20:37:10 DEBUG PoolingHttpClientConnectionManager: Closing connections idle longer than 60000 MILLISECONDS\n",
            "25/02/18 20:37:15 DEBUG Invoker: retry #4\n",
            "25/02/18 20:37:15 DEBUG IOStatisticsStoreImpl: Incrementing counter object_metadata_request by 1 with final value 5\n",
            "25/02/18 20:37:15 DEBUG IOStatisticsStoreImpl: Incrementing counter action_http_head_request by 1 with final value 5\n",
            "25/02/18 20:37:15 DEBUG S3AFileSystem: HEAD test.parquet with change tracker null\n",
            "25/02/18 20:37:15 DEBUG request: Sending Request: HEAD http://localhost:9000 /wba/test.parquet Headers: (amz-sdk-invocation-id: 17e35653-e56c-de5b-d841-36d5d5abe6ad, Content-Type: application/octet-stream, User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy, ) \n",
            "25/02/18 20:37:15 DEBUG AWS4Signer: AWS4 Canonical Request: '\"HEAD\n",
            "/wba/test.parquet\n",
            "\n",
            "amz-sdk-invocation-id:17e35653-e56c-de5b-d841-36d5d5abe6ad\n",
            "amz-sdk-request:attempt=1;max=2\n",
            "amz-sdk-retry:0/0/480\n",
            "content-type:application/octet-stream\n",
            "host:localhost:9000\n",
            "user-agent:Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy\n",
            "x-amz-content-sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "x-amz-date:20250218T203715Z\n",
            "\n",
            "amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date\n",
            "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\"\n",
            "25/02/18 20:37:15 DEBUG AWS4Signer: AWS4 String to Sign: '\"AWS4-HMAC-SHA256\n",
            "20250218T203715Z\n",
            "20250218/us-east-1/s3/aws4_request\n",
            "e53e81d926fe13f9e2c590cd5b827e0e007beb0190e3e5ee57b8d6824b5666b2\"\n",
            "25/02/18 20:37:15 DEBUG RequestAddCookies: CookieSpec selected: default\n",
            "25/02/18 20:37:15 DEBUG RequestAuthCache: Auth cache not set in the context\n",
            "25/02/18 20:37:15 DEBUG PoolingHttpClientConnectionManager: Connection request: [route: {}->http://localhost:9000][total available: 0; route allocated: 0 of 1; total allocated: 0 of 1]\n",
            "25/02/18 20:37:15 DEBUG PoolingHttpClientConnectionManager: Connection leased: [id: 22][route: {}->http://localhost:9000][total available: 0; route allocated: 1 of 1; total allocated: 1 of 1]\n",
            "25/02/18 20:37:15 DEBUG MainClientExec: Opening connection {}->http://localhost:9000\n",
            "25/02/18 20:37:15 DEBUG DefaultHttpClientConnectionOperator: Connecting to localhost/127.0.0.1:9000\n",
            "25/02/18 20:37:15 DEBUG DefaultHttpClientConnectionOperator: Connection established 127.0.0.1:46496<->127.0.0.1:9000\n",
            "25/02/18 20:37:15 DEBUG DefaultManagedHttpClientConnection: http-outgoing-22: set socket timeout to 5000\n",
            "25/02/18 20:37:15 DEBUG MainClientExec: Executing request HEAD /wba/test.parquet HTTP/1.1\n",
            "25/02/18 20:37:15 DEBUG MainClientExec: Proxy auth state: UNCHALLENGED\n",
            "25/02/18 20:37:15 DEBUG headers: http-outgoing-22 >> HEAD /wba/test.parquet HTTP/1.1\n",
            "25/02/18 20:37:15 DEBUG headers: http-outgoing-22 >> Host: localhost:9000\n",
            "25/02/18 20:37:15 DEBUG headers: http-outgoing-22 >> amz-sdk-invocation-id: 17e35653-e56c-de5b-d841-36d5d5abe6ad\n",
            "25/02/18 20:37:15 DEBUG headers: http-outgoing-22 >> amz-sdk-request: attempt=1;max=2\n",
            "25/02/18 20:37:15 DEBUG headers: http-outgoing-22 >> amz-sdk-retry: 0/0/480\n",
            "25/02/18 20:37:15 DEBUG headers: http-outgoing-22 >> Authorization: AWS4-HMAC-SHA256 Credential=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=416fa47589ca8211634069ce57f0b703a300d930949a943ccdb772063866257d\n",
            "25/02/18 20:37:15 DEBUG headers: http-outgoing-22 >> Content-Type: application/octet-stream\n",
            "25/02/18 20:37:15 DEBUG headers: http-outgoing-22 >> User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy\n",
            "25/02/18 20:37:15 DEBUG headers: http-outgoing-22 >> x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "25/02/18 20:37:15 DEBUG headers: http-outgoing-22 >> X-Amz-Date: 20250218T203715Z\n",
            "25/02/18 20:37:15 DEBUG headers: http-outgoing-22 >> Connection: Keep-Alive\n",
            "25/02/18 20:37:15 DEBUG wire: http-outgoing-22 >> \"HEAD /wba/test.parquet HTTP/1.1[\\r][\\n]\"\n",
            "25/02/18 20:37:15 DEBUG wire: http-outgoing-22 >> \"Host: localhost:9000[\\r][\\n]\"\n",
            "25/02/18 20:37:15 DEBUG wire: http-outgoing-22 >> \"amz-sdk-invocation-id: 17e35653-e56c-de5b-d841-36d5d5abe6ad[\\r][\\n]\"\n",
            "25/02/18 20:37:15 DEBUG wire: http-outgoing-22 >> \"amz-sdk-request: attempt=1;max=2[\\r][\\n]\"\n",
            "25/02/18 20:37:15 DEBUG wire: http-outgoing-22 >> \"amz-sdk-retry: 0/0/480[\\r][\\n]\"\n",
            "25/02/18 20:37:15 DEBUG wire: http-outgoing-22 >> \"Authorization: AWS4-HMAC-SHA256 Credential=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=416fa47589ca8211634069ce57f0b703a300d930949a943ccdb772063866257d[\\r][\\n]\"\n",
            "25/02/18 20:37:15 DEBUG wire: http-outgoing-22 >> \"Content-Type: application/octet-stream[\\r][\\n]\"\n",
            "25/02/18 20:37:15 DEBUG wire: http-outgoing-22 >> \"User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy[\\r][\\n]\"\n",
            "25/02/18 20:37:15 DEBUG wire: http-outgoing-22 >> \"x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855[\\r][\\n]\"\n",
            "25/02/18 20:37:15 DEBUG wire: http-outgoing-22 >> \"X-Amz-Date: 20250218T203715Z[\\r][\\n]\"\n",
            "25/02/18 20:37:15 DEBUG wire: http-outgoing-22 >> \"Connection: Keep-Alive[\\r][\\n]\"\n",
            "25/02/18 20:37:15 DEBUG wire: http-outgoing-22 >> \"[\\r][\\n]\"\n",
            "25/02/18 20:37:15 DEBUG wire: http-outgoing-22 << \"[0xff][0x0][0x0][0x0][0x0][0x0][0x0][0x0][0x1]\"\n",
            "25/02/18 20:37:15 DEBUG wire: http-outgoing-22 << \"-[0x1]d: 17e35653-e56c-de5b-d841-36d5d5abe6ad[\\r][\\n]\"\n",
            "25/02/18 20:37:15 DEBUG wire: http-outgoing-22 << \"amz-[0x1]dk-request: attempt=1;max=2[\\r][\\n]\"\n",
            "25/02/18 20:37:15 DEBUG wire: http-outgoing-22 << \"amz-sdk-retry: 0[0x1]0/480[\\r][\\n]\"\n",
            "25/02/18 20:37:15 DEBUG wire: http-outgoing-22 << \"Authorization: AWS4-HMAC-SHA256 Credentia[0x0]=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-reque[0x1]t;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=416fa47589ca8[0x0]11634069ce57f0b703a300d930949a943ccdb772063866257d[\\r][\\n]\"\n",
            "25/02/18 20:37:15 DEBUG wire: http-outgoing-22 << \"Cont[0x1]nt-Type: application/octet-stream[\\r][\\n]\"\n",
            "25/02/18 20:37:15 DEBUG wire: http-outgoing-22 << \"User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standa[0x0]d-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debia[0x0] cfg/retry-mode/legacy[\\r][\\n]\"\n",
            "25/02/18 20:37:15 DEBUG wire: http-outgoing-22 << \"x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca4\"\n",
            "25/02/18 20:37:15 DEBUG DefaultHttpResponseParser: Garbage in response: \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0001-\u0001d: 17e35653-e56c-de5b-d841-36d5d5abe6ad\n",
            "25/02/18 20:37:15 DEBUG DefaultHttpResponseParser: Garbage in response: amz-\u0001dk-request: attempt=1;max=2\n",
            "25/02/18 20:37:15 DEBUG DefaultHttpResponseParser: Garbage in response: amz-sdk-retry: 0\u00010/480\n",
            "25/02/18 20:37:15 DEBUG DefaultHttpResponseParser: Garbage in response: Authorization: AWS4-HMAC-SHA256 Credentia\u0000=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-reque\u0001t;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=416fa47589ca8\u000011634069ce57f0b703a300d930949a943ccdb772063866257d\n",
            "25/02/18 20:37:15 DEBUG DefaultHttpResponseParser: Garbage in response: Cont\u0001nt-Type: application/octet-stream\n",
            "25/02/18 20:37:15 DEBUG DefaultHttpResponseParser: Garbage in response: User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standa\u0000d-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debia\u0000 cfg/retry-mode/legacy\n",
            "25/02/18 20:37:20 DEBUG wire: http-outgoing-22 << \"[read] I/O error: Read timed out\"\n",
            "25/02/18 20:37:20 DEBUG DefaultManagedHttpClientConnection: http-outgoing-22: Close connection\n",
            "25/02/18 20:37:20 DEBUG DefaultManagedHttpClientConnection: http-outgoing-22: Shutdown connection\n",
            "25/02/18 20:37:20 DEBUG MainClientExec: Connection discarded\n",
            "25/02/18 20:37:20 DEBUG PoolingHttpClientConnectionManager: Connection released: [id: 22][route: {}->http://localhost:9000][total available: 0; route allocated: 0 of 1; total allocated: 0 of 1]\n",
            "25/02/18 20:37:20 DEBUG AmazonHttpClient: Unable to execute HTTP request: Read timed out Request will be retried.\n",
            "25/02/18 20:37:20 DEBUG request: Retrying Request: HEAD http://localhost:9000 /wba/test.parquet Headers: (amz-sdk-invocation-id: 17e35653-e56c-de5b-d841-36d5d5abe6ad, Content-Type: application/octet-stream, User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy, ) \n",
            "25/02/18 20:37:20 DEBUG AmazonHttpClient: Retriable error detected, will retry in 7ms, attempt number: 0\n",
            "25/02/18 20:37:20 DEBUG AWS4Signer: AWS4 Canonical Request: '\"HEAD\n",
            "/wba/test.parquet\n",
            "\n",
            "amz-sdk-invocation-id:17e35653-e56c-de5b-d841-36d5d5abe6ad\n",
            "amz-sdk-request:attempt=2;max=2\n",
            "amz-sdk-retry:1/7/475\n",
            "content-type:application/octet-stream\n",
            "host:localhost:9000\n",
            "user-agent:Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy\n",
            "x-amz-content-sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "x-amz-date:20250218T203720Z\n",
            "\n",
            "amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date\n",
            "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\"\n",
            "25/02/18 20:37:20 DEBUG AWS4Signer: AWS4 String to Sign: '\"AWS4-HMAC-SHA256\n",
            "20250218T203720Z\n",
            "20250218/us-east-1/s3/aws4_request\n",
            "e8a45b92a6c669308477ecc7c93056a77a00256b7ab5ff46d56670d4c7256907\"\n",
            "25/02/18 20:37:20 DEBUG RequestAddCookies: CookieSpec selected: default\n",
            "25/02/18 20:37:20 DEBUG RequestAuthCache: Auth cache not set in the context\n",
            "25/02/18 20:37:20 DEBUG PoolingHttpClientConnectionManager: Connection request: [route: {}->http://localhost:9000][total available: 0; route allocated: 0 of 1; total allocated: 0 of 1]\n",
            "25/02/18 20:37:20 DEBUG PoolingHttpClientConnectionManager: Connection leased: [id: 23][route: {}->http://localhost:9000][total available: 0; route allocated: 1 of 1; total allocated: 1 of 1]\n",
            "25/02/18 20:37:20 DEBUG MainClientExec: Opening connection {}->http://localhost:9000\n",
            "25/02/18 20:37:20 DEBUG DefaultHttpClientConnectionOperator: Connecting to localhost/127.0.0.1:9000\n",
            "25/02/18 20:37:20 DEBUG DefaultHttpClientConnectionOperator: Connection established 127.0.0.1:46470<->127.0.0.1:9000\n",
            "25/02/18 20:37:20 DEBUG DefaultManagedHttpClientConnection: http-outgoing-23: set socket timeout to 5000\n",
            "25/02/18 20:37:20 DEBUG MainClientExec: Executing request HEAD /wba/test.parquet HTTP/1.1\n",
            "25/02/18 20:37:20 DEBUG MainClientExec: Proxy auth state: UNCHALLENGED\n",
            "25/02/18 20:37:20 DEBUG headers: http-outgoing-23 >> HEAD /wba/test.parquet HTTP/1.1\n",
            "25/02/18 20:37:20 DEBUG headers: http-outgoing-23 >> Host: localhost:9000\n",
            "25/02/18 20:37:20 DEBUG headers: http-outgoing-23 >> amz-sdk-invocation-id: 17e35653-e56c-de5b-d841-36d5d5abe6ad\n",
            "25/02/18 20:37:20 DEBUG headers: http-outgoing-23 >> amz-sdk-request: attempt=2;max=2\n",
            "25/02/18 20:37:20 DEBUG headers: http-outgoing-23 >> amz-sdk-retry: 1/7/475\n",
            "25/02/18 20:37:20 DEBUG headers: http-outgoing-23 >> Authorization: AWS4-HMAC-SHA256 Credential=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=d3cdd4f98c4eba5e143be4a799551b2d21899cc79a3e7f4a3c58c7672d991012\n",
            "25/02/18 20:37:20 DEBUG headers: http-outgoing-23 >> Content-Type: application/octet-stream\n",
            "25/02/18 20:37:20 DEBUG headers: http-outgoing-23 >> User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy\n",
            "25/02/18 20:37:20 DEBUG headers: http-outgoing-23 >> x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "25/02/18 20:37:20 DEBUG headers: http-outgoing-23 >> X-Amz-Date: 20250218T203720Z\n",
            "25/02/18 20:37:20 DEBUG headers: http-outgoing-23 >> Connection: Keep-Alive\n",
            "25/02/18 20:37:20 DEBUG wire: http-outgoing-23 >> \"HEAD /wba/test.parquet HTTP/1.1[\\r][\\n]\"\n",
            "25/02/18 20:37:20 DEBUG wire: http-outgoing-23 >> \"Host: localhost:9000[\\r][\\n]\"\n",
            "25/02/18 20:37:20 DEBUG wire: http-outgoing-23 >> \"amz-sdk-invocation-id: 17e35653-e56c-de5b-d841-36d5d5abe6ad[\\r][\\n]\"\n",
            "25/02/18 20:37:20 DEBUG wire: http-outgoing-23 >> \"amz-sdk-request: attempt=2;max=2[\\r][\\n]\"\n",
            "25/02/18 20:37:20 DEBUG wire: http-outgoing-23 >> \"amz-sdk-retry: 1/7/475[\\r][\\n]\"\n",
            "25/02/18 20:37:20 DEBUG wire: http-outgoing-23 >> \"Authorization: AWS4-HMAC-SHA256 Credential=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=d3cdd4f98c4eba5e143be4a799551b2d21899cc79a3e7f4a3c58c7672d991012[\\r][\\n]\"\n",
            "25/02/18 20:37:20 DEBUG wire: http-outgoing-23 >> \"Content-Type: application/octet-stream[\\r][\\n]\"\n",
            "25/02/18 20:37:20 DEBUG wire: http-outgoing-23 >> \"User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy[\\r][\\n]\"\n",
            "25/02/18 20:37:20 DEBUG wire: http-outgoing-23 >> \"x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855[\\r][\\n]\"\n",
            "25/02/18 20:37:20 DEBUG wire: http-outgoing-23 >> \"X-Amz-Date: 20250218T203720Z[\\r][\\n]\"\n",
            "25/02/18 20:37:20 DEBUG wire: http-outgoing-23 >> \"Connection: Keep-Alive[\\r][\\n]\"\n",
            "25/02/18 20:37:20 DEBUG wire: http-outgoing-23 >> \"[\\r][\\n]\"\n",
            "25/02/18 20:37:20 DEBUG wire: http-outgoing-23 << \"[0xff][0x0][0x0][0x0][0x0][0x0][0x0][0x0][0x1]\"\n",
            "25/02/18 20:37:20 DEBUG wire: http-outgoing-23 << \"-[0x1]d: 17e35653-e56c-de5b-d841-36d5d5abe6ad[\\r][\\n]\"\n",
            "25/02/18 20:37:20 DEBUG wire: http-outgoing-23 << \"amz-[0x1]dk-request: attempt=2;max=2[\\r][\\n]\"\n",
            "25/02/18 20:37:20 DEBUG wire: http-outgoing-23 << \"amz-sdk-retry: 1[0x1]7/475[\\r][\\n]\"\n",
            "25/02/18 20:37:20 DEBUG wire: http-outgoing-23 << \"Authorization: AWS4-HMAC-SHA256 Credential[0x1]minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-sdk-r[0x1]try;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=d3cdd4f98c4eba5e143be4a799551b2d21899c[0x1]79a3e7f4a3c58c7672d991012[\\r][\\n]\"\n",
            "25/02/18 20:37:20 DEBUG wire: http-outgoing-23 << \"Content-Type: application/octet-stream[\\r][\\n]\"\n",
            "25/02/18 20:37:20 DEBUG wire: http-outgoing-23 << \"User-Agent: Hadoop 3.3.4, aws-sd[0x1]-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1d[0x1]b12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy[\\r][\\n]\"\n",
            "25/02/18 20:37:20 DEBUG wire: http-outgoing-23 << \"x-amz-content-sha256: e3b0c442[0x1]8fc1c149afbf4c8996fb92427ae41e4649b934ca495991b785[0x0]b855[\\r][\\n]\"\n",
            "25/02/18 20:37:20 DEBUG wire: http-outgoing-23 << \"X-Amz-Date: 20250218T203720Z[\\r][\\n]\"\n",
            "25/02/18 20:37:20 DEBUG wire: http-outgoing-23 << \"Connection: Keep\"\n",
            "25/02/18 20:37:20 DEBUG DefaultHttpResponseParser: Garbage in response: \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0001-\u0001d: 17e35653-e56c-de5b-d841-36d5d5abe6ad\n",
            "25/02/18 20:37:20 DEBUG DefaultHttpResponseParser: Garbage in response: amz-\u0001dk-request: attempt=2;max=2\n",
            "25/02/18 20:37:20 DEBUG DefaultHttpResponseParser: Garbage in response: amz-sdk-retry: 1\u00017/475\n",
            "25/02/18 20:37:20 DEBUG DefaultHttpResponseParser: Garbage in response: Authorization: AWS4-HMAC-SHA256 Credential\u0001minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-sdk-r\u0001try;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=d3cdd4f98c4eba5e143be4a799551b2d21899c\u000179a3e7f4a3c58c7672d991012\n",
            "25/02/18 20:37:20 DEBUG DefaultHttpResponseParser: Garbage in response: Content-Type: application/octet-stream\n",
            "25/02/18 20:37:20 DEBUG DefaultHttpResponseParser: Garbage in response: User-Agent: Hadoop 3.3.4, aws-sd\u0001-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1d\u0001b12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy\n",
            "25/02/18 20:37:20 DEBUG DefaultHttpResponseParser: Garbage in response: x-amz-content-sha256: e3b0c442\u00018fc1c149afbf4c8996fb92427ae41e4649b934ca495991b785\u0000b855\n",
            "25/02/18 20:37:20 DEBUG DefaultHttpResponseParser: Garbage in response: X-Amz-Date: 20250218T203720Z\n",
            "25/02/18 20:37:25 DEBUG wire: http-outgoing-23 << \"[read] I/O error: Read timed out\"\n",
            "25/02/18 20:37:25 DEBUG DefaultManagedHttpClientConnection: http-outgoing-23: Close connection\n",
            "25/02/18 20:37:25 DEBUG DefaultManagedHttpClientConnection: http-outgoing-23: Shutdown connection\n",
            "25/02/18 20:37:25 DEBUG MainClientExec: Connection discarded\n",
            "25/02/18 20:37:25 DEBUG PoolingHttpClientConnectionManager: Connection released: [id: 23][route: {}->http://localhost:9000][total available: 0; route allocated: 0 of 1; total allocated: 0 of 1]\n",
            "25/02/18 20:37:25 DEBUG AmazonHttpClient: Unable to execute HTTP request: Read timed out\n",
            "25/02/18 20:37:25 DEBUG IOStatisticsStoreImpl: Incrementing counter store_io_request by 2 with final value 10\n",
            "25/02/18 20:37:25 DEBUG latency: MaxRetriesExceeded=[true], ServiceName=[Amazon S3], ServiceEndpoint=[http://localhost:9000], Exception=[java.net.SocketTimeoutException: Read timed out, java.net.SocketTimeoutException: Read timed out], RequestType=[GetObjectMetadataRequest], AWSRequestID=[null, null], HttpClientPoolPendingCount=0, RetryCapacityConsumed=25, HttpClientPoolAvailableCount=0, RequestCount=2, Exception=2, HttpClientPoolLeasedCount=0, RetryPauseTime=[7.199], ClientExecuteTime=[10023.933], HttpClientSendRequestTime=[0.676, 0.573], HttpRequestTime=[5005.274, 5008.954], ApiCallLatency=[10023.656], RequestSigningTime=[0.329, 0.604], CredentialsRequestTime=[0.008, 0.007, 0.04], HttpClientReceiveResponseTime=[5003.161, 5006.454], \n",
            "25/02/18 20:37:25 DEBUG IOStatisticsStoreImpl: Incrementing counter store_io_retry by 1 with final value 5\n",
            "25/02/18 20:37:25 DEBUG IOStatisticsStoreImpl: Incrementing counter ignored_errors by 1 with final value 5\n",
            "25/02/18 20:37:38 DEBUG Invoker: retry #5\n",
            "25/02/18 20:37:38 DEBUG IOStatisticsStoreImpl: Incrementing counter object_metadata_request by 1 with final value 6\n",
            "25/02/18 20:37:38 DEBUG IOStatisticsStoreImpl: Incrementing counter action_http_head_request by 1 with final value 6\n",
            "25/02/18 20:37:38 DEBUG S3AFileSystem: HEAD test.parquet with change tracker null\n",
            "25/02/18 20:37:38 DEBUG request: Sending Request: HEAD http://localhost:9000 /wba/test.parquet Headers: (amz-sdk-invocation-id: 8383e703-d489-3ac5-caf4-70b21dba51b5, Content-Type: application/octet-stream, User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy, ) \n",
            "25/02/18 20:37:38 DEBUG AWS4Signer: AWS4 Canonical Request: '\"HEAD\n",
            "/wba/test.parquet\n",
            "\n",
            "amz-sdk-invocation-id:8383e703-d489-3ac5-caf4-70b21dba51b5\n",
            "amz-sdk-request:attempt=1;max=2\n",
            "amz-sdk-retry:0/0/475\n",
            "content-type:application/octet-stream\n",
            "host:localhost:9000\n",
            "user-agent:Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy\n",
            "x-amz-content-sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "x-amz-date:20250218T203738Z\n",
            "\n",
            "amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date\n",
            "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\"\n",
            "25/02/18 20:37:38 DEBUG AWS4Signer: AWS4 String to Sign: '\"AWS4-HMAC-SHA256\n",
            "20250218T203738Z\n",
            "20250218/us-east-1/s3/aws4_request\n",
            "3efe50796fc79d1f0f7a3159d9abd88e741c1d0130ca23e8ee17660d4a4375a4\"\n",
            "25/02/18 20:37:38 DEBUG RequestAddCookies: CookieSpec selected: default\n",
            "25/02/18 20:37:38 DEBUG RequestAuthCache: Auth cache not set in the context\n",
            "25/02/18 20:37:38 DEBUG PoolingHttpClientConnectionManager: Connection request: [route: {}->http://localhost:9000][total available: 0; route allocated: 0 of 1; total allocated: 0 of 1]\n",
            "25/02/18 20:37:38 DEBUG PoolingHttpClientConnectionManager: Connection leased: [id: 24][route: {}->http://localhost:9000][total available: 0; route allocated: 1 of 1; total allocated: 1 of 1]\n",
            "25/02/18 20:37:38 DEBUG MainClientExec: Opening connection {}->http://localhost:9000\n",
            "25/02/18 20:37:38 DEBUG DefaultHttpClientConnectionOperator: Connecting to localhost/127.0.0.1:9000\n",
            "25/02/18 20:37:38 DEBUG DefaultHttpClientConnectionOperator: Connection established 127.0.0.1:46956<->127.0.0.1:9000\n",
            "25/02/18 20:37:38 DEBUG DefaultManagedHttpClientConnection: http-outgoing-24: set socket timeout to 5000\n",
            "25/02/18 20:37:38 DEBUG MainClientExec: Executing request HEAD /wba/test.parquet HTTP/1.1\n",
            "25/02/18 20:37:38 DEBUG MainClientExec: Proxy auth state: UNCHALLENGED\n",
            "25/02/18 20:37:38 DEBUG headers: http-outgoing-24 >> HEAD /wba/test.parquet HTTP/1.1\n",
            "25/02/18 20:37:38 DEBUG headers: http-outgoing-24 >> Host: localhost:9000\n",
            "25/02/18 20:37:38 DEBUG headers: http-outgoing-24 >> amz-sdk-invocation-id: 8383e703-d489-3ac5-caf4-70b21dba51b5\n",
            "25/02/18 20:37:38 DEBUG headers: http-outgoing-24 >> amz-sdk-request: attempt=1;max=2\n",
            "25/02/18 20:37:38 DEBUG headers: http-outgoing-24 >> amz-sdk-retry: 0/0/475\n",
            "25/02/18 20:37:38 DEBUG headers: http-outgoing-24 >> Authorization: AWS4-HMAC-SHA256 Credential=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=2bb31b39c63b56424fa4fb4ae9a0722a1a2374dfc80070132d20be80271edcbb\n",
            "25/02/18 20:37:38 DEBUG headers: http-outgoing-24 >> Content-Type: application/octet-stream\n",
            "25/02/18 20:37:38 DEBUG headers: http-outgoing-24 >> User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy\n",
            "25/02/18 20:37:38 DEBUG headers: http-outgoing-24 >> x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "25/02/18 20:37:38 DEBUG headers: http-outgoing-24 >> X-Amz-Date: 20250218T203738Z\n",
            "25/02/18 20:37:38 DEBUG headers: http-outgoing-24 >> Connection: Keep-Alive\n",
            "25/02/18 20:37:38 DEBUG wire: http-outgoing-24 >> \"HEAD /wba/test.parquet HTTP/1.1[\\r][\\n]\"\n",
            "25/02/18 20:37:38 DEBUG wire: http-outgoing-24 >> \"Host: localhost:9000[\\r][\\n]\"\n",
            "25/02/18 20:37:38 DEBUG wire: http-outgoing-24 >> \"amz-sdk-invocation-id: 8383e703-d489-3ac5-caf4-70b21dba51b5[\\r][\\n]\"\n",
            "25/02/18 20:37:38 DEBUG wire: http-outgoing-24 >> \"amz-sdk-request: attempt=1;max=2[\\r][\\n]\"\n",
            "25/02/18 20:37:38 DEBUG wire: http-outgoing-24 >> \"amz-sdk-retry: 0/0/475[\\r][\\n]\"\n",
            "25/02/18 20:37:38 DEBUG wire: http-outgoing-24 >> \"Authorization: AWS4-HMAC-SHA256 Credential=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=2bb31b39c63b56424fa4fb4ae9a0722a1a2374dfc80070132d20be80271edcbb[\\r][\\n]\"\n",
            "25/02/18 20:37:38 DEBUG wire: http-outgoing-24 >> \"Content-Type: application/octet-stream[\\r][\\n]\"\n",
            "25/02/18 20:37:38 DEBUG wire: http-outgoing-24 >> \"User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy[\\r][\\n]\"\n",
            "25/02/18 20:37:38 DEBUG wire: http-outgoing-24 >> \"x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855[\\r][\\n]\"\n",
            "25/02/18 20:37:38 DEBUG wire: http-outgoing-24 >> \"X-Amz-Date: 20250218T203738Z[\\r][\\n]\"\n",
            "25/02/18 20:37:38 DEBUG wire: http-outgoing-24 >> \"Connection: Keep-Alive[\\r][\\n]\"\n",
            "25/02/18 20:37:38 DEBUG wire: http-outgoing-24 >> \"[\\r][\\n]\"\n",
            "25/02/18 20:37:38 DEBUG wire: http-outgoing-24 << \"[0xff][0x0][0x0][0x0][0x0][0x0][0x0][0x0][0x1]\"\n",
            "25/02/18 20:37:38 DEBUG wire: http-outgoing-24 << \"-[0x1]d: 8383e703-d489-3ac5-caf4-70b21dba51b5[\\r][\\n]\"\n",
            "25/02/18 20:37:38 DEBUG wire: http-outgoing-24 << \"amz-[0x1]dk-request: attempt=1;max=2[\\r][\\n]\"\n",
            "25/02/18 20:37:38 DEBUG wire: http-outgoing-24 << \"amz-sdk-retry: 0[0x1]0/475[\\r][\\n]\"\n",
            "25/02/18 20:37:38 DEBUG wire: http-outgoing-24 << \"Authorization: AWS4-HMAC-SHA256 Credentia[0x0]=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-reque[0x1]t;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=2bb31b39c63b5[0x0]424fa4fb4ae9a0722a1a2374dfc80070132d20be80271edcbb[\\r][\\n]\"\n",
            "25/02/18 20:37:38 DEBUG wire: http-outgoing-24 << \"C[0x1]ntent-Type: application/octet-stream[\\r][\\n]\"\n",
            "25/02/18 20:37:38 DEBUG wire: http-outgoing-24 << \"User-Agent: Hadoop 3.3.4, aws[0x1]sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/[0x1]7.0.14 scala/2.12.17 vendor/Debian cfg/retry-mo[0x0]e/legacy[\\r][\\n]\"\n",
            "25/02/18 20:37:38 DEBUG wire: http-outgoing-24 << \"x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855[\\r][\\n]\"\n",
            "25/02/18 20:37:38 DEBUG wire: http-outgoing-24 << \"X-Amz-Date: \"\n",
            "25/02/18 20:37:38 DEBUG DefaultHttpResponseParser: Garbage in response: \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0001-\u0001d: 8383e703-d489-3ac5-caf4-70b21dba51b5\n",
            "25/02/18 20:37:38 DEBUG DefaultHttpResponseParser: Garbage in response: amz-\u0001dk-request: attempt=1;max=2\n",
            "25/02/18 20:37:38 DEBUG DefaultHttpResponseParser: Garbage in response: amz-sdk-retry: 0\u00010/475\n",
            "25/02/18 20:37:38 DEBUG DefaultHttpResponseParser: Garbage in response: Authorization: AWS4-HMAC-SHA256 Credentia\u0000=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-reque\u0001t;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=2bb31b39c63b5\u0000424fa4fb4ae9a0722a1a2374dfc80070132d20be80271edcbb\n",
            "25/02/18 20:37:38 DEBUG DefaultHttpResponseParser: Garbage in response: C\u0001ntent-Type: application/octet-stream\n",
            "25/02/18 20:37:38 DEBUG DefaultHttpResponseParser: Garbage in response: User-Agent: Hadoop 3.3.4, aws\u0001sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/\u00017.0.14 scala/2.12.17 vendor/Debian cfg/retry-mo\u0000e/legacy\n",
            "25/02/18 20:37:38 DEBUG DefaultHttpResponseParser: Garbage in response: x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "25/02/18 20:37:43 DEBUG wire: http-outgoing-24 << \"[read] I/O error: Read timed out\"\n",
            "25/02/18 20:37:43 DEBUG DefaultManagedHttpClientConnection: http-outgoing-24: Close connection\n",
            "25/02/18 20:37:43 DEBUG DefaultManagedHttpClientConnection: http-outgoing-24: Shutdown connection\n",
            "25/02/18 20:37:43 DEBUG MainClientExec: Connection discarded\n",
            "25/02/18 20:37:43 DEBUG PoolingHttpClientConnectionManager: Connection released: [id: 24][route: {}->http://localhost:9000][total available: 0; route allocated: 0 of 1; total allocated: 0 of 1]\n",
            "25/02/18 20:37:43 DEBUG AmazonHttpClient: Unable to execute HTTP request: Read timed out Request will be retried.\n",
            "25/02/18 20:37:43 DEBUG request: Retrying Request: HEAD http://localhost:9000 /wba/test.parquet Headers: (amz-sdk-invocation-id: 8383e703-d489-3ac5-caf4-70b21dba51b5, Content-Type: application/octet-stream, User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy, ) \n",
            "25/02/18 20:37:43 DEBUG AmazonHttpClient: Retriable error detected, will retry in 100ms, attempt number: 0\n",
            "25/02/18 20:37:43 DEBUG AWS4Signer: AWS4 Canonical Request: '\"HEAD\n",
            "/wba/test.parquet\n",
            "\n",
            "amz-sdk-invocation-id:8383e703-d489-3ac5-caf4-70b21dba51b5\n",
            "amz-sdk-request:attempt=2;max=2\n",
            "amz-sdk-retry:1/100/470\n",
            "content-type:application/octet-stream\n",
            "host:localhost:9000\n",
            "user-agent:Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy\n",
            "x-amz-content-sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "x-amz-date:20250218T203743Z\n",
            "\n",
            "amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date\n",
            "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\"\n",
            "25/02/18 20:37:43 DEBUG AWS4Signer: AWS4 String to Sign: '\"AWS4-HMAC-SHA256\n",
            "20250218T203743Z\n",
            "20250218/us-east-1/s3/aws4_request\n",
            "54ced64acb757c03596665c9a867f38b0fb5d61e45179492938bcd130a70cc8a\"\n",
            "25/02/18 20:37:43 DEBUG RequestAddCookies: CookieSpec selected: default\n",
            "25/02/18 20:37:43 DEBUG RequestAuthCache: Auth cache not set in the context\n",
            "25/02/18 20:37:43 DEBUG PoolingHttpClientConnectionManager: Connection request: [route: {}->http://localhost:9000][total available: 0; route allocated: 0 of 1; total allocated: 0 of 1]\n",
            "25/02/18 20:37:43 DEBUG PoolingHttpClientConnectionManager: Connection leased: [id: 25][route: {}->http://localhost:9000][total available: 0; route allocated: 1 of 1; total allocated: 1 of 1]\n",
            "25/02/18 20:37:43 DEBUG MainClientExec: Opening connection {}->http://localhost:9000\n",
            "25/02/18 20:37:43 DEBUG DefaultHttpClientConnectionOperator: Connecting to localhost/127.0.0.1:9000\n",
            "25/02/18 20:37:43 DEBUG DefaultHttpClientConnectionOperator: Connection established 127.0.0.1:46962<->127.0.0.1:9000\n",
            "25/02/18 20:37:43 DEBUG DefaultManagedHttpClientConnection: http-outgoing-25: set socket timeout to 5000\n",
            "25/02/18 20:37:43 DEBUG MainClientExec: Executing request HEAD /wba/test.parquet HTTP/1.1\n",
            "25/02/18 20:37:43 DEBUG MainClientExec: Proxy auth state: UNCHALLENGED\n",
            "25/02/18 20:37:43 DEBUG headers: http-outgoing-25 >> HEAD /wba/test.parquet HTTP/1.1\n",
            "25/02/18 20:37:43 DEBUG headers: http-outgoing-25 >> Host: localhost:9000\n",
            "25/02/18 20:37:43 DEBUG headers: http-outgoing-25 >> amz-sdk-invocation-id: 8383e703-d489-3ac5-caf4-70b21dba51b5\n",
            "25/02/18 20:37:43 DEBUG headers: http-outgoing-25 >> amz-sdk-request: attempt=2;max=2\n",
            "25/02/18 20:37:43 DEBUG headers: http-outgoing-25 >> amz-sdk-retry: 1/100/470\n",
            "25/02/18 20:37:43 DEBUG headers: http-outgoing-25 >> Authorization: AWS4-HMAC-SHA256 Credential=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=ac9c61d72b124ac0e4165dd9c80e2315ac6740cc2b795d1ae8c03fe99ec0b811\n",
            "25/02/18 20:37:43 DEBUG headers: http-outgoing-25 >> Content-Type: application/octet-stream\n",
            "25/02/18 20:37:43 DEBUG headers: http-outgoing-25 >> User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy\n",
            "25/02/18 20:37:43 DEBUG headers: http-outgoing-25 >> x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "25/02/18 20:37:43 DEBUG headers: http-outgoing-25 >> X-Amz-Date: 20250218T203743Z\n",
            "25/02/18 20:37:43 DEBUG headers: http-outgoing-25 >> Connection: Keep-Alive\n",
            "25/02/18 20:37:43 DEBUG wire: http-outgoing-25 >> \"HEAD /wba/test.parquet HTTP/1.1[\\r][\\n]\"\n",
            "25/02/18 20:37:43 DEBUG wire: http-outgoing-25 >> \"Host: localhost:9000[\\r][\\n]\"\n",
            "25/02/18 20:37:43 DEBUG wire: http-outgoing-25 >> \"amz-sdk-invocation-id: 8383e703-d489-3ac5-caf4-70b21dba51b5[\\r][\\n]\"\n",
            "25/02/18 20:37:43 DEBUG wire: http-outgoing-25 >> \"amz-sdk-request: attempt=2;max=2[\\r][\\n]\"\n",
            "25/02/18 20:37:43 DEBUG wire: http-outgoing-25 >> \"amz-sdk-retry: 1/100/470[\\r][\\n]\"\n",
            "25/02/18 20:37:43 DEBUG wire: http-outgoing-25 >> \"Authorization: AWS4-HMAC-SHA256 Credential=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=ac9c61d72b124ac0e4165dd9c80e2315ac6740cc2b795d1ae8c03fe99ec0b811[\\r][\\n]\"\n",
            "25/02/18 20:37:43 DEBUG wire: http-outgoing-25 >> \"Content-Type: application/octet-stream[\\r][\\n]\"\n",
            "25/02/18 20:37:43 DEBUG wire: http-outgoing-25 >> \"User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy[\\r][\\n]\"\n",
            "25/02/18 20:37:43 DEBUG wire: http-outgoing-25 >> \"x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855[\\r][\\n]\"\n",
            "25/02/18 20:37:43 DEBUG wire: http-outgoing-25 >> \"X-Amz-Date: 20250218T203743Z[\\r][\\n]\"\n",
            "25/02/18 20:37:43 DEBUG wire: http-outgoing-25 >> \"Connection: Keep-Alive[\\r][\\n]\"\n",
            "25/02/18 20:37:43 DEBUG wire: http-outgoing-25 >> \"[\\r][\\n]\"\n",
            "25/02/18 20:37:43 DEBUG wire: http-outgoing-25 << \"[0xff][0x0][0x0][0x0][0x0][0x0][0x0][0x0][0x1]\"\n",
            "25/02/18 20:37:43 DEBUG wire: http-outgoing-25 << \"-[0x1]d: 8383e703-d489-3ac5-caf4-70b21dba51b5[\\r][\\n]\"\n",
            "25/02/18 20:37:43 DEBUG wire: http-outgoing-25 << \"amz-[0x1]dk-request: attempt=2;max=2[\\r][\\n]\"\n",
            "25/02/18 20:37:43 DEBUG wire: http-outgoing-25 << \"amz-sdk-retry: 1[0x1]100/470[\\r][\\n]\"\n",
            "25/02/18 20:37:43 DEBUG wire: http-outgoing-25 << \"Authorization: AWS4-HMAC-SHA256 Credenti[0x1]l=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-[0x1]dk-retry;content-type;host;user-agent;x-amz-c[0x1]ntent-sha256;x-amz-date, Signature=ac9c61d72b124ac0e4165dd9c80e2315ac6740cc2b795d1ae8c03fe99ec0b811[0x1][\\n]\"\n",
            "25/02/18 20:37:43 DEBUG wire: http-outgoing-25 << \"Content-Type: application/octet-stream[\\r][\\n]\"\n",
            "25/02/18 20:37:43 DEBUG wire: http-outgoing-25 << \"User-Age[0x0]t: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server[0x1]VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy[\\r][\\n]\"\n",
            "25/02/18 20:37:43 DEBUG wire: http-outgoing-25 << \"x-amz-content-sha256:[0x0]e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7\"\n",
            "25/02/18 20:37:43 DEBUG DefaultHttpResponseParser: Garbage in response: \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0001-\u0001d: 8383e703-d489-3ac5-caf4-70b21dba51b5\n",
            "25/02/18 20:37:43 DEBUG DefaultHttpResponseParser: Garbage in response: amz-\u0001dk-request: attempt=2;max=2\n",
            "25/02/18 20:37:43 DEBUG DefaultHttpResponseParser: Garbage in response: amz-sdk-retry: 1\u0001100/470\n",
            "25/02/18 20:37:43 DEBUG DefaultHttpResponseParser: Garbage in response: Authorization: AWS4-HMAC-SHA256 Credenti\u0001l=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-\u0001dk-retry;content-type;host;user-agent;x-amz-c\u0001ntent-sha256;x-amz-date, Signature=ac9c61d72b124ac0e4165dd9c80e2315ac6740cc2b795d1ae8c03fe99ec0b811\u0001\n",
            "25/02/18 20:37:43 DEBUG DefaultHttpResponseParser: Garbage in response: Content-Type: application/octet-stream\n",
            "25/02/18 20:37:43 DEBUG DefaultHttpResponseParser: Garbage in response: User-Age\u0000t: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server\u0001VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy\n",
            "25/02/18 20:37:48 DEBUG wire: http-outgoing-25 << \"[read] I/O error: Read timed out\"\n",
            "25/02/18 20:37:48 DEBUG DefaultManagedHttpClientConnection: http-outgoing-25: Close connection\n",
            "25/02/18 20:37:48 DEBUG DefaultManagedHttpClientConnection: http-outgoing-25: Shutdown connection\n",
            "25/02/18 20:37:48 DEBUG MainClientExec: Connection discarded\n",
            "25/02/18 20:37:48 DEBUG PoolingHttpClientConnectionManager: Connection released: [id: 25][route: {}->http://localhost:9000][total available: 0; route allocated: 0 of 1; total allocated: 0 of 1]\n",
            "25/02/18 20:37:48 DEBUG AmazonHttpClient: Unable to execute HTTP request: Read timed out\n",
            "25/02/18 20:37:48 DEBUG IOStatisticsStoreImpl: Incrementing counter store_io_request by 2 with final value 12\n",
            "25/02/18 20:37:48 DEBUG latency: MaxRetriesExceeded=[true], ServiceName=[Amazon S3], ServiceEndpoint=[http://localhost:9000], Exception=[java.net.SocketTimeoutException: Read timed out, java.net.SocketTimeoutException: Read timed out], RequestType=[GetObjectMetadataRequest], AWSRequestID=[null, null], HttpClientPoolPendingCount=0, RetryCapacityConsumed=30, HttpClientPoolAvailableCount=0, RequestCount=2, Exception=2, HttpClientPoolLeasedCount=0, RetryPauseTime=[100.29], ClientExecuteTime=[10124.807], HttpClientSendRequestTime=[0.823, 0.877], HttpRequestTime=[5009.81, 5011.02], ApiCallLatency=[10124.275], RequestSigningTime=[0.471, 0.909], CredentialsRequestTime=[0.011, 0.005, 0.021], HttpClientReceiveResponseTime=[5006.826, 5007.201], \n",
            "25/02/18 20:37:48 DEBUG IOStatisticsStoreImpl: Incrementing counter store_io_retry by 1 with final value 6\n",
            "25/02/18 20:37:48 DEBUG IOStatisticsStoreImpl: Incrementing counter ignored_errors by 1 with final value 6\n",
            "25/02/18 20:38:06 DEBUG Invoker: retry #6\n",
            "25/02/18 20:38:06 DEBUG IOStatisticsStoreImpl: Incrementing counter object_metadata_request by 1 with final value 7\n",
            "25/02/18 20:38:06 DEBUG IOStatisticsStoreImpl: Incrementing counter action_http_head_request by 1 with final value 7\n",
            "25/02/18 20:38:06 DEBUG S3AFileSystem: HEAD test.parquet with change tracker null\n",
            "25/02/18 20:38:06 DEBUG request: Sending Request: HEAD http://localhost:9000 /wba/test.parquet Headers: (amz-sdk-invocation-id: e59b7ef1-7c80-54ce-a0dc-e4263a66a47a, Content-Type: application/octet-stream, User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy, ) \n",
            "25/02/18 20:38:06 DEBUG AWS4Signer: AWS4 Canonical Request: '\"HEAD\n",
            "/wba/test.parquet\n",
            "\n",
            "amz-sdk-invocation-id:e59b7ef1-7c80-54ce-a0dc-e4263a66a47a\n",
            "amz-sdk-request:attempt=1;max=2\n",
            "amz-sdk-retry:0/0/470\n",
            "content-type:application/octet-stream\n",
            "host:localhost:9000\n",
            "user-agent:Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy\n",
            "x-amz-content-sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "x-amz-date:20250218T203806Z\n",
            "\n",
            "amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date\n",
            "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\"\n",
            "25/02/18 20:38:06 DEBUG AWS4Signer: AWS4 String to Sign: '\"AWS4-HMAC-SHA256\n",
            "20250218T203806Z\n",
            "20250218/us-east-1/s3/aws4_request\n",
            "11ddec2b1c196629d738344e4091530de2eff2a764c495816ac776ccfb7e1bda\"\n",
            "25/02/18 20:38:06 DEBUG RequestAddCookies: CookieSpec selected: default\n",
            "25/02/18 20:38:06 DEBUG RequestAuthCache: Auth cache not set in the context\n",
            "25/02/18 20:38:06 DEBUG PoolingHttpClientConnectionManager: Connection request: [route: {}->http://localhost:9000][total available: 0; route allocated: 0 of 1; total allocated: 0 of 1]\n",
            "25/02/18 20:38:06 DEBUG PoolingHttpClientConnectionManager: Connection leased: [id: 26][route: {}->http://localhost:9000][total available: 0; route allocated: 1 of 1; total allocated: 1 of 1]\n",
            "25/02/18 20:38:06 DEBUG MainClientExec: Opening connection {}->http://localhost:9000\n",
            "25/02/18 20:38:06 DEBUG DefaultHttpClientConnectionOperator: Connecting to localhost/127.0.0.1:9000\n",
            "25/02/18 20:38:06 DEBUG DefaultHttpClientConnectionOperator: Connection established 127.0.0.1:54378<->127.0.0.1:9000\n",
            "25/02/18 20:38:06 DEBUG DefaultManagedHttpClientConnection: http-outgoing-26: set socket timeout to 5000\n",
            "25/02/18 20:38:06 DEBUG MainClientExec: Executing request HEAD /wba/test.parquet HTTP/1.1\n",
            "25/02/18 20:38:06 DEBUG MainClientExec: Proxy auth state: UNCHALLENGED\n",
            "25/02/18 20:38:06 DEBUG headers: http-outgoing-26 >> HEAD /wba/test.parquet HTTP/1.1\n",
            "25/02/18 20:38:06 DEBUG headers: http-outgoing-26 >> Host: localhost:9000\n",
            "25/02/18 20:38:06 DEBUG headers: http-outgoing-26 >> amz-sdk-invocation-id: e59b7ef1-7c80-54ce-a0dc-e4263a66a47a\n",
            "25/02/18 20:38:06 DEBUG headers: http-outgoing-26 >> amz-sdk-request: attempt=1;max=2\n",
            "25/02/18 20:38:06 DEBUG headers: http-outgoing-26 >> amz-sdk-retry: 0/0/470\n",
            "25/02/18 20:38:06 DEBUG headers: http-outgoing-26 >> Authorization: AWS4-HMAC-SHA256 Credential=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=07808d2e511fa49f0f2809953f20880379c46a297ca74d7bf748c965ac5173b4\n",
            "25/02/18 20:38:06 DEBUG headers: http-outgoing-26 >> Content-Type: application/octet-stream\n",
            "25/02/18 20:38:06 DEBUG headers: http-outgoing-26 >> User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy\n",
            "25/02/18 20:38:06 DEBUG headers: http-outgoing-26 >> x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "25/02/18 20:38:06 DEBUG headers: http-outgoing-26 >> X-Amz-Date: 20250218T203806Z\n",
            "25/02/18 20:38:06 DEBUG headers: http-outgoing-26 >> Connection: Keep-Alive\n",
            "25/02/18 20:38:06 DEBUG wire: http-outgoing-26 >> \"HEAD /wba/test.parquet HTTP/1.1[\\r][\\n]\"\n",
            "25/02/18 20:38:06 DEBUG wire: http-outgoing-26 >> \"Host: localhost:9000[\\r][\\n]\"\n",
            "25/02/18 20:38:06 DEBUG wire: http-outgoing-26 >> \"amz-sdk-invocation-id: e59b7ef1-7c80-54ce-a0dc-e4263a66a47a[\\r][\\n]\"\n",
            "25/02/18 20:38:06 DEBUG wire: http-outgoing-26 >> \"amz-sdk-request: attempt=1;max=2[\\r][\\n]\"\n",
            "25/02/18 20:38:06 DEBUG wire: http-outgoing-26 >> \"amz-sdk-retry: 0/0/470[\\r][\\n]\"\n",
            "25/02/18 20:38:06 DEBUG wire: http-outgoing-26 >> \"Authorization: AWS4-HMAC-SHA256 Credential=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=07808d2e511fa49f0f2809953f20880379c46a297ca74d7bf748c965ac5173b4[\\r][\\n]\"\n",
            "25/02/18 20:38:06 DEBUG wire: http-outgoing-26 >> \"Content-Type: application/octet-stream[\\r][\\n]\"\n",
            "25/02/18 20:38:06 DEBUG wire: http-outgoing-26 >> \"User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy[\\r][\\n]\"\n",
            "25/02/18 20:38:06 DEBUG wire: http-outgoing-26 >> \"x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855[\\r][\\n]\"\n",
            "25/02/18 20:38:06 DEBUG wire: http-outgoing-26 >> \"X-Amz-Date: 20250218T203806Z[\\r][\\n]\"\n",
            "25/02/18 20:38:06 DEBUG wire: http-outgoing-26 >> \"Connection: Keep-Alive[\\r][\\n]\"\n",
            "25/02/18 20:38:06 DEBUG wire: http-outgoing-26 >> \"[\\r][\\n]\"\n",
            "25/02/18 20:38:06 DEBUG wire: http-outgoing-26 << \"[0xff][0x0][0x0][0x0][0x0][0x0][0x0][0x0][0x1]\"\n",
            "25/02/18 20:38:06 DEBUG wire: http-outgoing-26 << \"-[0x1]d: e59b7ef1-7c80-54ce-a0dc-e4263a66a47a[\\r][\\n]\"\n",
            "25/02/18 20:38:06 DEBUG wire: http-outgoing-26 << \"amz-[0x1]dk-request: attempt=1;max=2[\\r][\\n]\"\n",
            "25/02/18 20:38:06 DEBUG wire: http-outgoing-26 << \"amz-sdk-retry: 0[0x1]0/470[\\r][\\n]\"\n",
            "25/02/18 20:38:06 DEBUG wire: http-outgoing-26 << \"Authorization: AWS4-HMAC-SHA256 Credentia[0x0]=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-reque[0x1]t;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=07808d2e511fa[0x0]9f0f2809953f20880379c46a297ca74d7bf748c965ac5173b4[\\r][\\n]\"\n",
            "25/02/18 20:38:06 DEBUG wire: http-outgoing-26 << \"Content-Type: application/octet-stream[\\r][\\n]\"\n",
            "25/02/18 20:38:06 DEBUG wire: http-outgoing-26 << \"User-[0x1]gent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Lin[0x1]x/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.1[0x0].17 vendor/Debian cfg/retry-mode/legacy[\\r][\\n]\"\n",
            "25/02/18 20:38:06 DEBUG wire: http-outgoing-26 << \"x-amz-co[0x0]tent-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855[\\r][\\n]\"\n",
            "25/02/18 20:38:06 DEBUG wire: http-outgoing-26 << \"X-Amz-Date: 20250218T203806Z[\\r][\\n]\"\n",
            "25/02/18 20:38:06 DEBUG wire: http-outgoing-26 << \"C\"\n",
            "25/02/18 20:38:06 DEBUG DefaultHttpResponseParser: Garbage in response: \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0001-\u0001d: e59b7ef1-7c80-54ce-a0dc-e4263a66a47a\n",
            "25/02/18 20:38:06 DEBUG DefaultHttpResponseParser: Garbage in response: amz-\u0001dk-request: attempt=1;max=2\n",
            "25/02/18 20:38:06 DEBUG DefaultHttpResponseParser: Garbage in response: amz-sdk-retry: 0\u00010/470\n",
            "25/02/18 20:38:06 DEBUG DefaultHttpResponseParser: Garbage in response: Authorization: AWS4-HMAC-SHA256 Credentia\u0000=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-reque\u0001t;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=07808d2e511fa\u00009f0f2809953f20880379c46a297ca74d7bf748c965ac5173b4\n",
            "25/02/18 20:38:06 DEBUG DefaultHttpResponseParser: Garbage in response: Content-Type: application/octet-stream\n",
            "25/02/18 20:38:06 DEBUG DefaultHttpResponseParser: Garbage in response: User-\u0001gent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Lin\u0001x/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.1\u0000.17 vendor/Debian cfg/retry-mode/legacy\n",
            "25/02/18 20:38:06 DEBUG DefaultHttpResponseParser: Garbage in response: x-amz-co\u0000tent-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "25/02/18 20:38:06 DEBUG DefaultHttpResponseParser: Garbage in response: X-Amz-Date: 20250218T203806Z\n",
            "25/02/18 20:38:06 DEBUG Invoker: retry #7\n",
            "25/02/18 20:38:06 DEBUG IOStatisticsStoreImpl: Incrementing counter object_metadata_request by 1 with final value 8\n",
            "25/02/18 20:38:06 DEBUG IOStatisticsStoreImpl: Incrementing counter action_http_head_request by 1 with final value 8\n",
            "25/02/18 20:38:06 DEBUG S3AFileSystem: HEAD test.parquet with change tracker null\n",
            "25/02/18 20:38:06 DEBUG request: Sending Request: HEAD http://minio:9000 /wba/test.parquet Headers: (amz-sdk-invocation-id: 8f3372b0-cad1-3f4c-1f84-7a1c13fa011a, Content-Type: application/octet-stream, User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy, ) \n",
            "25/02/18 20:38:06 DEBUG AWS4Signer: AWS4 Canonical Request: '\"HEAD\n",
            "/wba/test.parquet\n",
            "\n",
            "amz-sdk-invocation-id:8f3372b0-cad1-3f4c-1f84-7a1c13fa011a\n",
            "amz-sdk-request:attempt=1;max=2\n",
            "amz-sdk-retry:0/0/465\n",
            "content-type:application/octet-stream\n",
            "host:minio:9000\n",
            "user-agent:Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy\n",
            "x-amz-content-sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "x-amz-date:20250218T203806Z\n",
            "\n",
            "amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date\n",
            "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\"\n",
            "25/02/18 20:38:06 DEBUG AWS4Signer: AWS4 String to Sign: '\"AWS4-HMAC-SHA256\n",
            "20250218T203806Z\n",
            "20250218/us-east-1/s3/aws4_request\n",
            "5b7072c0fce430e18c6aea2dc2dd0eb321f812dff9fe66a4050b49dedbace838\"\n",
            "25/02/18 20:38:06 DEBUG RequestAddCookies: CookieSpec selected: default\n",
            "25/02/18 20:38:06 DEBUG RequestAuthCache: Auth cache not set in the context\n",
            "25/02/18 20:38:06 DEBUG PoolingHttpClientConnectionManager: Connection request: [route: {}->http://minio:9000][total available: 0; route allocated: 0 of 1; total allocated: 0 of 1]\n",
            "25/02/18 20:38:06 DEBUG PoolingHttpClientConnectionManager: Connection leased: [id: 27][route: {}->http://minio:9000][total available: 0; route allocated: 1 of 1; total allocated: 1 of 1]\n",
            "25/02/18 20:38:06 DEBUG MainClientExec: Opening connection {}->http://minio:9000\n",
            "25/02/18 20:38:10 DEBUG PoolingHttpClientConnectionManager: Closing connections idle longer than 60000 MILLISECONDS\n",
            "25/02/18 20:38:10 DEBUG PoolingHttpClientConnectionManager: Closing connections idle longer than 60000 MILLISECONDS\n",
            "25/02/18 20:38:10 DEBUG PoolingHttpClientConnectionManager: Closing connections idle longer than 60000 MILLISECONDS\n",
            "25/02/18 20:38:11 DEBUG wire: http-outgoing-26 << \"[read] I/O error: Read timed out\"\n",
            "25/02/18 20:38:11 DEBUG DefaultManagedHttpClientConnection: http-outgoing-26: Close connection\n",
            "25/02/18 20:38:11 DEBUG DefaultManagedHttpClientConnection: http-outgoing-26: Shutdown connection\n",
            "25/02/18 20:38:11 DEBUG MainClientExec: Connection discarded\n",
            "25/02/18 20:38:11 DEBUG PoolingHttpClientConnectionManager: Connection released: [id: 26][route: {}->http://localhost:9000][total available: 0; route allocated: 0 of 1; total allocated: 0 of 1]\n",
            "25/02/18 20:38:11 DEBUG AmazonHttpClient: Unable to execute HTTP request: Read timed out Request will be retried.\n",
            "25/02/18 20:38:11 DEBUG request: Retrying Request: HEAD http://localhost:9000 /wba/test.parquet Headers: (amz-sdk-invocation-id: e59b7ef1-7c80-54ce-a0dc-e4263a66a47a, Content-Type: application/octet-stream, User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy, ) \n",
            "25/02/18 20:38:11 DEBUG AmazonHttpClient: Retriable error detected, will retry in 9ms, attempt number: 0\n",
            "25/02/18 20:38:11 DEBUG AWS4Signer: AWS4 Canonical Request: '\"HEAD\n",
            "/wba/test.parquet\n",
            "\n",
            "amz-sdk-invocation-id:e59b7ef1-7c80-54ce-a0dc-e4263a66a47a\n",
            "amz-sdk-request:attempt=2;max=2\n",
            "amz-sdk-retry:1/9/465\n",
            "content-type:application/octet-stream\n",
            "host:localhost:9000\n",
            "user-agent:Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy\n",
            "x-amz-content-sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "x-amz-date:20250218T203811Z\n",
            "\n",
            "amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date\n",
            "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\"\n",
            "25/02/18 20:38:11 DEBUG AWS4Signer: AWS4 String to Sign: '\"AWS4-HMAC-SHA256\n",
            "20250218T203811Z\n",
            "20250218/us-east-1/s3/aws4_request\n",
            "6c94ec9fc3f3c03ade98f1a8a85f8b45c3166539d6d11fe1b72d38cd4b234577\"\n",
            "25/02/18 20:38:11 DEBUG RequestAddCookies: CookieSpec selected: default\n",
            "25/02/18 20:38:11 DEBUG RequestAuthCache: Auth cache not set in the context\n",
            "25/02/18 20:38:11 DEBUG PoolingHttpClientConnectionManager: Connection request: [route: {}->http://localhost:9000][total available: 0; route allocated: 0 of 1; total allocated: 0 of 1]\n",
            "25/02/18 20:38:11 DEBUG PoolingHttpClientConnectionManager: Connection leased: [id: 28][route: {}->http://localhost:9000][total available: 0; route allocated: 1 of 1; total allocated: 1 of 1]\n",
            "25/02/18 20:38:11 DEBUG MainClientExec: Opening connection {}->http://localhost:9000\n",
            "25/02/18 20:38:11 DEBUG DefaultHttpClientConnectionOperator: Connecting to localhost/127.0.0.1:9000\n",
            "25/02/18 20:38:11 DEBUG DefaultHttpClientConnectionOperator: Connection established 127.0.0.1:38706<->127.0.0.1:9000\n",
            "25/02/18 20:38:11 DEBUG DefaultManagedHttpClientConnection: http-outgoing-28: set socket timeout to 5000\n",
            "25/02/18 20:38:11 DEBUG MainClientExec: Executing request HEAD /wba/test.parquet HTTP/1.1\n",
            "25/02/18 20:38:11 DEBUG MainClientExec: Proxy auth state: UNCHALLENGED\n",
            "25/02/18 20:38:11 DEBUG headers: http-outgoing-28 >> HEAD /wba/test.parquet HTTP/1.1\n",
            "25/02/18 20:38:11 DEBUG headers: http-outgoing-28 >> Host: localhost:9000\n",
            "25/02/18 20:38:11 DEBUG headers: http-outgoing-28 >> amz-sdk-invocation-id: e59b7ef1-7c80-54ce-a0dc-e4263a66a47a\n",
            "25/02/18 20:38:11 DEBUG headers: http-outgoing-28 >> amz-sdk-request: attempt=2;max=2\n",
            "25/02/18 20:38:11 DEBUG headers: http-outgoing-28 >> amz-sdk-retry: 1/9/465\n",
            "25/02/18 20:38:11 DEBUG headers: http-outgoing-28 >> Authorization: AWS4-HMAC-SHA256 Credential=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=0a3abc9ac106a3a6bf129f5e894e2624362cde81dbe35f34f80c9aff840e5b15\n",
            "25/02/18 20:38:11 DEBUG headers: http-outgoing-28 >> Content-Type: application/octet-stream\n",
            "25/02/18 20:38:11 DEBUG headers: http-outgoing-28 >> User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy\n",
            "25/02/18 20:38:11 DEBUG headers: http-outgoing-28 >> x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "25/02/18 20:38:11 DEBUG headers: http-outgoing-28 >> X-Amz-Date: 20250218T203811Z\n",
            "25/02/18 20:38:11 DEBUG headers: http-outgoing-28 >> Connection: Keep-Alive\n",
            "25/02/18 20:38:11 DEBUG wire: http-outgoing-28 >> \"HEAD /wba/test.parquet HTTP/1.1[\\r][\\n]\"\n",
            "25/02/18 20:38:11 DEBUG wire: http-outgoing-28 >> \"Host: localhost:9000[\\r][\\n]\"\n",
            "25/02/18 20:38:11 DEBUG wire: http-outgoing-28 >> \"amz-sdk-invocation-id: e59b7ef1-7c80-54ce-a0dc-e4263a66a47a[\\r][\\n]\"\n",
            "25/02/18 20:38:11 DEBUG wire: http-outgoing-28 >> \"amz-sdk-request: attempt=2;max=2[\\r][\\n]\"\n",
            "25/02/18 20:38:11 DEBUG wire: http-outgoing-28 >> \"amz-sdk-retry: 1/9/465[\\r][\\n]\"\n",
            "25/02/18 20:38:11 DEBUG wire: http-outgoing-28 >> \"Authorization: AWS4-HMAC-SHA256 Credential=minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=0a3abc9ac106a3a6bf129f5e894e2624362cde81dbe35f34f80c9aff840e5b15[\\r][\\n]\"\n",
            "25/02/18 20:38:11 DEBUG wire: http-outgoing-28 >> \"Content-Type: application/octet-stream[\\r][\\n]\"\n",
            "25/02/18 20:38:11 DEBUG wire: http-outgoing-28 >> \"User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy[\\r][\\n]\"\n",
            "25/02/18 20:38:11 DEBUG wire: http-outgoing-28 >> \"x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855[\\r][\\n]\"\n",
            "25/02/18 20:38:11 DEBUG wire: http-outgoing-28 >> \"X-Amz-Date: 20250218T203811Z[\\r][\\n]\"\n",
            "25/02/18 20:38:11 DEBUG wire: http-outgoing-28 >> \"Connection: Keep-Alive[\\r][\\n]\"\n",
            "25/02/18 20:38:11 DEBUG wire: http-outgoing-28 >> \"[\\r][\\n]\"\n",
            "25/02/18 20:38:11 DEBUG wire: http-outgoing-28 << \"[0xff][0x0][0x0][0x0][0x0][0x0][0x0][0x0][0x1]\"\n",
            "25/02/18 20:38:11 DEBUG wire: http-outgoing-28 << \"-[0x1]d: e59b7ef1-7c80-54ce-a0dc-e4263a66a47a[\\r][\\n]\"\n",
            "25/02/18 20:38:11 DEBUG wire: http-outgoing-28 << \"amz-[0x1]dk-request: attempt=2;max=2[\\r][\\n]\"\n",
            "25/02/18 20:38:11 DEBUG wire: http-outgoing-28 << \"amz-sdk-retry: 1[0x1]9/465[\\r][\\n]\"\n",
            "25/02/18 20:38:11 DEBUG wire: http-outgoing-28 << \"Authorization: AWS4-HMAC-SHA256 Credential[0x1]minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-sdk-r[0x1]try;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=0a3abc9ac106a3a6bf129f5e894e2624362cde[0x0]1dbe35f34f80c9aff840e5b15[\\r][\\n]\"\n",
            "25/02/18 20:38:11 DEBUG wire: http-outgoing-28 << \"Content-Type: application/octet-stream[\\r][\\n]\"\n",
            "25/02/18 20:38:11 DEBUG wire: http-outgoing-28 << \"User-Agent: Hadoop 3.3.4, aws-sdk-[0x0]ava/1.12.261 Linux/5.15.167.4-microsoft-stan\"\n",
            "25/02/18 20:38:11 DEBUG DefaultHttpResponseParser: Garbage in response: \u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0001-\u0001d: e59b7ef1-7c80-54ce-a0dc-e4263a66a47a\n",
            "25/02/18 20:38:11 DEBUG DefaultHttpResponseParser: Garbage in response: amz-\u0001dk-request: attempt=2;max=2\n",
            "25/02/18 20:38:11 DEBUG DefaultHttpResponseParser: Garbage in response: amz-sdk-retry: 1\u00019/465\n",
            "25/02/18 20:38:11 DEBUG DefaultHttpResponseParser: Garbage in response: Authorization: AWS4-HMAC-SHA256 Credential\u0001minioadmin/20250218/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-sdk-r\u0001try;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=0a3abc9ac106a3a6bf129f5e894e2624362cde\u00001dbe35f34f80c9aff840e5b15\n",
            "25/02/18 20:38:11 DEBUG DefaultHttpResponseParser: Garbage in response: Content-Type: application/octet-stream\n",
            "25/02/18 20:38:14 DEBUG ClientConnectionManagerFactory: \n",
            "java.lang.reflect.InvocationTargetException\n",
            "\tat jdk.internal.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)\n",
            "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
            "\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n",
            "\tat com.amazonaws.http.conn.ClientConnectionManagerFactory$Handler.invoke(ClientConnectionManagerFactory.java:76)\n",
            "\tat com.amazonaws.http.conn.$Proxy43.connect(Unknown Source)\n",
            "\tat com.amazonaws.thirdparty.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:393)\n",
            "\tat com.amazonaws.thirdparty.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:236)\n",
            "\tat com.amazonaws.thirdparty.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:186)\n",
            "\tat com.amazonaws.thirdparty.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)\n",
            "\tat com.amazonaws.thirdparty.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)\n",
            "\tat com.amazonaws.thirdparty.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56)\n",
            "\tat com.amazonaws.http.apache.client.impl.SdkHttpClient.execute(SdkHttpClient.java:72)\n",
            "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeOneRequest(AmazonHttpClient.java:1346)\n",
            "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeHelper(AmazonHttpClient.java:1157)\n",
            "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.doExecute(AmazonHttpClient.java:814)\n",
            "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeWithTimer(AmazonHttpClient.java:781)\n",
            "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.execute(AmazonHttpClient.java:755)\n",
            "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.access$500(AmazonHttpClient.java:715)\n",
            "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutionBuilderImpl.execute(AmazonHttpClient.java:697)\n",
            "\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:561)\n",
            "\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:541)\n",
            "\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:5456)\n",
            "\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:5403)\n",
            "\tat com.amazonaws.services.s3.AmazonS3Client.getObjectMetadata(AmazonS3Client.java:1372)\n",
            "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$getObjectMetadata$10(S3AFileSystem.java:2545)\n",
            "\tat org.apache.hadoop.fs.s3a.Invoker.retryUntranslated(Invoker.java:414)\n",
            "\tat org.apache.hadoop.fs.s3a.Invoker.retryUntranslated(Invoker.java:377)\n",
            "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.getObjectMetadata(S3AFileSystem.java:2533)\n",
            "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.getObjectMetadata(S3AFileSystem.java:2513)\n",
            "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.s3GetFileStatus(S3AFileSystem.java:3776)\n",
            "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.innerGetFileStatus(S3AFileSystem.java:3688)\n",
            "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$exists$34(S3AFileSystem.java:4703)\n",
            "\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.lambda$trackDurationOfOperation$5(IOStatisticsBinding.java:499)\n",
            "\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.trackDuration(IOStatisticsBinding.java:444)\n",
            "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2337)\n",
            "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2356)\n",
            "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.exists(S3AFileSystem.java:4701)\n",
            "\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:120)\n",
            "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)\n",
            "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)\n",
            "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
            "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n",
            "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n",
            "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
            "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n",
            "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n",
            "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n",
            "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n",
            "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:239)\n",
            "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
            "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
            "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
            "\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n",
            "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
            "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
            "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
            "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
            "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
            "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
            "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "Caused by: java.net.UnknownHostException: minio: Temporary failure in name resolution\n",
            "\tat java.base/java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method)\n",
            "\tat java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)\n",
            "\tat java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)\n",
            "\tat java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat com.amazonaws.SystemDefaultDnsResolver.resolve(SystemDefaultDnsResolver.java:27)\n",
            "\tat com.amazonaws.http.DelegatingDnsResolver.resolve(DelegatingDnsResolver.java:38)\n",
            "\tat com.amazonaws.thirdparty.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:112)\n",
            "\tat com.amazonaws.thirdparty.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:376)\n",
            "\t... 78 more\n",
            "25/02/18 20:38:14 DEBUG DefaultManagedHttpClientConnection: http-outgoing-27: Shutdown connection\n",
            "25/02/18 20:38:14 DEBUG MainClientExec: Connection discarded\n",
            "25/02/18 20:38:14 DEBUG PoolingHttpClientConnectionManager: Connection released: [id: 27][route: {}->http://minio:9000][total available: 0; route allocated: 0 of 1; total allocated: 0 of 1]\n",
            "25/02/18 20:38:14 DEBUG AmazonHttpClient: Unable to execute HTTP request: minio: Temporary failure in name resolution Request will be retried.\n",
            "25/02/18 20:38:14 DEBUG request: Retrying Request: HEAD http://minio:9000 /wba/test.parquet Headers: (amz-sdk-invocation-id: 8f3372b0-cad1-3f4c-1f84-7a1c13fa011a, Content-Type: application/octet-stream, User-Agent: Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy, ) \n",
            "25/02/18 20:38:14 DEBUG AmazonHttpClient: Retriable error detected, will retry in 27ms, attempt number: 0\n",
            "25/02/18 20:38:14 DEBUG AWS4Signer: AWS4 Canonical Request: '\"HEAD\n",
            "/wba/test.parquet\n",
            "\n",
            "amz-sdk-invocation-id:8f3372b0-cad1-3f4c-1f84-7a1c13fa011a\n",
            "amz-sdk-request:attempt=2;max=2\n",
            "amz-sdk-retry:1/27/460\n",
            "content-type:application/octet-stream\n",
            "host:minio:9000\n",
            "user-agent:Hadoop 3.3.4, aws-sdk-java/1.12.261 Linux/5.15.167.4-microsoft-standard-WSL2 OpenJDK_64-Bit_Server_VM/17.0.14+7-Debian-1deb12u1 java/17.0.14 scala/2.12.17 vendor/Debian cfg/retry-mode/legacy\n",
            "x-amz-content-sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "x-amz-date:20250218T203814Z\n",
            "\n",
            "amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date\n",
            "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\"\n",
            "25/02/18 20:38:14 DEBUG AWS4Signer: AWS4 String to Sign: '\"AWS4-HMAC-SHA256\n",
            "20250218T203814Z\n",
            "20250218/us-east-1/s3/aws4_request\n",
            "e36c8560b928eb80281e66464f3b6c8aa6be792e9025d5c88bfbad0b8afbeab1\"\n",
            "25/02/18 20:38:14 DEBUG RequestAddCookies: CookieSpec selected: default\n",
            "25/02/18 20:38:14 DEBUG RequestAuthCache: Auth cache not set in the context\n",
            "25/02/18 20:38:14 DEBUG PoolingHttpClientConnectionManager: Connection request: [route: {}->http://minio:9000][total available: 0; route allocated: 0 of 1; total allocated: 0 of 1]\n",
            "25/02/18 20:38:14 DEBUG PoolingHttpClientConnectionManager: Connection leased: [id: 29][route: {}->http://minio:9000][total available: 0; route allocated: 1 of 1; total allocated: 1 of 1]\n",
            "25/02/18 20:38:14 DEBUG MainClientExec: Opening connection {}->http://minio:9000\n",
            "25/02/18 20:38:14 DEBUG ClientConnectionManagerFactory: \n",
            "java.lang.reflect.InvocationTargetException\n",
            "\tat jdk.internal.reflect.GeneratedMethodAccessor72.invoke(Unknown Source)\n",
            "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
            "\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n",
            "\tat com.amazonaws.http.conn.ClientConnectionManagerFactory$Handler.invoke(ClientConnectionManagerFactory.java:76)\n",
            "\tat com.amazonaws.http.conn.$Proxy43.connect(Unknown Source)\n",
            "\tat com.amazonaws.thirdparty.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:393)\n",
            "\tat com.amazonaws.thirdparty.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:236)\n",
            "\tat com.amazonaws.thirdparty.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:186)\n",
            "\tat com.amazonaws.thirdparty.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)\n",
            "\tat com.amazonaws.thirdparty.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)\n",
            "\tat com.amazonaws.thirdparty.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56)\n",
            "\tat com.amazonaws.http.apache.client.impl.SdkHttpClient.execute(SdkHttpClient.java:72)\n",
            "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeOneRequest(AmazonHttpClient.java:1346)\n",
            "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeHelper(AmazonHttpClient.java:1157)\n",
            "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.doExecute(AmazonHttpClient.java:814)\n",
            "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeWithTimer(AmazonHttpClient.java:781)\n",
            "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.execute(AmazonHttpClient.java:755)\n",
            "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.access$500(AmazonHttpClient.java:715)\n",
            "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutionBuilderImpl.execute(AmazonHttpClient.java:697)\n",
            "\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:561)\n",
            "\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:541)\n",
            "\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:5456)\n",
            "\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:5403)\n",
            "\tat com.amazonaws.services.s3.AmazonS3Client.getObjectMetadata(AmazonS3Client.java:1372)\n",
            "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$getObjectMetadata$10(S3AFileSystem.java:2545)\n",
            "\tat org.apache.hadoop.fs.s3a.Invoker.retryUntranslated(Invoker.java:414)\n",
            "\tat org.apache.hadoop.fs.s3a.Invoker.retryUntranslated(Invoker.java:377)\n",
            "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.getObjectMetadata(S3AFileSystem.java:2533)\n",
            "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.getObjectMetadata(S3AFileSystem.java:2513)\n",
            "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.s3GetFileStatus(S3AFileSystem.java:3776)\n",
            "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.innerGetFileStatus(S3AFileSystem.java:3688)\n",
            "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$exists$34(S3AFileSystem.java:4703)\n",
            "\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.lambda$trackDurationOfOperation$5(IOStatisticsBinding.java:499)\n",
            "\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.trackDuration(IOStatisticsBinding.java:444)\n",
            "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2337)\n",
            "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2356)\n",
            "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.exists(S3AFileSystem.java:4701)\n",
            "\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:120)\n",
            "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)\n",
            "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)\n",
            "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
            "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n",
            "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n",
            "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
            "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n",
            "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n",
            "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n",
            "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n",
            "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:239)\n",
            "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
            "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
            "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
            "\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n",
            "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
            "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
            "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
            "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
            "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
            "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
            "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
            "Caused by: java.net.UnknownHostException: minio\n",
            "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
            "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
            "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
            "\tat com.amazonaws.SystemDefaultDnsResolver.resolve(SystemDefaultDnsResolver.java:27)\n",
            "\tat com.amazonaws.http.DelegatingDnsResolver.resolve(DelegatingDnsResolver.java:38)\n",
            "\tat com.amazonaws.thirdparty.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:112)\n",
            "\tat com.amazonaws.thirdparty.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:376)\n",
            "\t... 78 more\n",
            "25/02/18 20:38:14 DEBUG DefaultManagedHttpClientConnection: http-outgoing-29: Shutdown connection\n",
            "25/02/18 20:38:14 DEBUG MainClientExec: Connection discarded\n",
            "25/02/18 20:38:14 DEBUG PoolingHttpClientConnectionManager: Connection released: [id: 29][route: {}->http://minio:9000][total available: 0; route allocated: 0 of 1; total allocated: 0 of 1]\n",
            "25/02/18 20:38:14 DEBUG AmazonHttpClient: Unable to execute HTTP request: minio\n",
            "25/02/18 20:38:14 DEBUG IOStatisticsStoreImpl: Incrementing counter store_io_request by 2 with final value 16\n",
            "25/02/18 20:38:14 DEBUG latency: MaxRetriesExceeded=[true], ServiceName=[Amazon S3], ServiceEndpoint=[http://minio:9000], Exception=[java.net.UnknownHostException: minio: Temporary failure in name resolution, java.net.UnknownHostException: minio], RequestType=[GetObjectMetadataRequest], AWSRequestID=[null, null], HttpClientPoolPendingCount=0, RetryCapacityConsumed=40, HttpClientPoolAvailableCount=0, RequestCount=2, Exception=2, HttpClientPoolLeasedCount=0, RetryPauseTime=[27.324], ClientExecuteTime=[8039.979], HttpRequestTime=[8006.388, 3.378], ApiCallLatency=[8039.619], RequestSigningTime=[0.426, 0.995], CredentialsRequestTime=[0.01, 0.009, 0.015], \n",
            "25/02/18 20:38:14 DEBUG IOStatisticsStoreImpl: Incrementing counter op_exists.failures by 1 with final value 1\n",
            "25/02/18 20:38:16 DEBUG wire: http-outgoing-28 << \"[read] I/O error: Read timed out\"\n",
            "25/02/18 20:38:16 DEBUG DefaultManagedHttpClientConnection: http-outgoing-28: Close connection\n",
            "25/02/18 20:38:16 DEBUG DefaultManagedHttpClientConnection: http-outgoing-28: Shutdown connection\n",
            "25/02/18 20:38:16 DEBUG MainClientExec: Connection discarded\n",
            "25/02/18 20:38:16 DEBUG PoolingHttpClientConnectionManager: Connection released: [id: 28][route: {}->http://localhost:9000][total available: 0; route allocated: 0 of 1; total allocated: 0 of 1]\n",
            "25/02/18 20:38:16 DEBUG AmazonHttpClient: Unable to execute HTTP request: Read timed out\n",
            "25/02/18 20:38:16 DEBUG IOStatisticsStoreImpl: Incrementing counter store_io_request by 2 with final value 14\n",
            "25/02/18 20:38:16 DEBUG latency: MaxRetriesExceeded=[true], ServiceName=[Amazon S3], ServiceEndpoint=[http://localhost:9000], Exception=[java.net.SocketTimeoutException: Read timed out, java.net.SocketTimeoutException: Read timed out], RequestType=[GetObjectMetadataRequest], AWSRequestID=[null, null], HttpClientPoolPendingCount=0, RetryCapacityConsumed=35, HttpClientPoolAvailableCount=0, RequestCount=2, Exception=2, HttpClientPoolLeasedCount=0, RetryPauseTime=[9.154], ClientExecuteTime=[10033.428], HttpClientSendRequestTime=[1.68, 0.63], HttpRequestTime=[5011.446, 5009.365], ApiCallLatency=[10032.775], RequestSigningTime=[0.841, 0.627], CredentialsRequestTime=[0.017, 0.012, 0.008], HttpClientReceiveResponseTime=[5006.793, 5006.655], \n",
            "25/02/18 20:38:16 DEBUG IOStatisticsStoreImpl: Incrementing counter store_io_retry by 1 with final value 7\n",
            "25/02/18 20:38:16 DEBUG IOStatisticsStoreImpl: Incrementing counter ignored_errors by 1 with final value 7\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Get the Spark home directory\n",
        "spark_home = os.environ.get('SPARK_HOME', '/opt/spark')\n",
        "\n",
        "# Define all required JARs\n",
        "jars = [\n",
        "    f\"{spark_home}/jars/delta-core_2.12-2.4.0.jar\",\n",
        "    f\"{spark_home}/jars/delta-storage-2.4.0.jar\",\n",
        "    f\"{spark_home}/jars/hadoop-aws-3.3.2.jar\",\n",
        "    f\"{spark_home}/jars/aws-java-sdk-bundle-1.12.261.jar\"\n",
        "]\n",
        "\n",
        "# Create SparkSession using the builder pattern\n",
        "builder = (SparkSession.builder\n",
        "           .appName(\"DeltaExample\")\n",
        "           .master(\"local[*]\")\n",
        "           # Add debug configurations\n",
        "           .config(\"spark.hadoop.fs.s3a.connection.maximum\", \"1\")\n",
        "           .config(\"spark.hadoop.fs.s3a.attempts.maximum\", \"1\")\n",
        "           .config(\"spark.hadoop.fs.s3a.connection.timeout\", \"5000\")\n",
        "           .config(\"spark.hadoop.fs.s3a.impl.disable.cache\", \"true\")\n",
        "           .config(\"spark.hadoop.fs.s3a.debug.detailed.exceptions\", \"true\")\n",
        "           # Add jars directly\n",
        "           .config(\"spark.jars\", \",\".join(jars))\n",
        "           .config(\"spark.driver.extraClassPath\", \",\".join(jars))\n",
        "           .config(\"spark.executor.extraClassPath\", \",\".join(jars))\n",
        "           # Delta Lake configurations\n",
        "           .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
        "           .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
        "           # S3/MinIO configurations\n",
        "           .config(\"spark.hadoop.fs.s3a.access.key\", \"minioadmin\")\n",
        "           .config(\"spark.hadoop.fs.s3a.secret.key\", \"minioadmin\")\n",
        "           .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\")\n",
        "           .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
        "           .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
        "           .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\")\n",
        "           .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\")\n",
        "           # Additional Delta Lake configurations\n",
        "           .config(\"spark.delta.logStore.class\", \"io.delta.storage.S3SingleDriverLogStore\")\n",
        "           .config(\"spark.hadoop.fs.s3a.fast.upload\", \"true\")\n",
        "           .config(\"spark.hadoop.fs.s3a.multipart.size\", \"104857600\")\n",
        "           .config(\"spark.sql.warehouse.dir\", \"/tmp/spark-warehouse\"))\n",
        "\n",
        "# Stop any existing session\n",
        "if 'spark' in locals():\n",
        "    spark.stop()\n",
        "\n",
        "\n",
        "# Create the session\n",
        "spark = builder.enableHiveSupport().getOrCreate()\n",
        "\n",
        "# Initialize Delta Lake settings\n",
        "spark.sql(\"SET spark.databricks.delta.formatCheck.enabled=false\")\n",
        "\n",
        "# Access the SparkContext\n",
        "sc = spark.sparkContext\n",
        "\n",
        "# Set the log level to INFO\n",
        "sc.setLogLevel(\"DEBUG\")\n",
        "\n",
        "# Test DataFrame\n",
        "data = [(1, \"John\"), (2, \"Jane\")]\n",
        "df = spark.createDataFrame(data, [\"id\", \"name\"])\n",
        "df.show()\n",
        "\n",
        "# First verify the S3 connection by listing the bucket\n",
        "try:\n",
        "    # Try to write to a simple parquet file first to test S3 connection\n",
        "    print(\"Testing S3 connection with parquet write...\")\n",
        "    df.write.format(\"parquet\").mode(\"overwrite\").save(\"s3a://wba/test.parquet\")\n",
        "    print(\"S3 connection successful\")\n",
        "\n",
        "    print(\"Attempting to write Delta table...\")\n",
        "    df.write \\\n",
        "        .format(\"delta\") \\\n",
        "        .mode(\"overwrite\") \\\n",
        "        .option(\"overwriteSchema\", \"true\") \\\n",
        "        .option(\"delta.compatibility.symlinkFormatManifest.enabled\", \"false\") \\\n",
        "        .save(\"s3a://wba/example-table\")\n",
        "    print(\"Successfully wrote Delta table\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error: {str(e)}\")\n",
        "    print(\"\\nTrying local filesystem instead...\")\n",
        "    try:\n",
        "        local_path = \"/tmp/test-delta-table\"\n",
        "        df.write \\\n",
        "            .format(\"delta\") \\\n",
        "            .mode(\"overwrite\") \\\n",
        "            .option(\"overwriteSchema\", \"true\") \\\n",
        "            .save(local_path)\n",
        "        print(f\"Successfully wrote to {local_path}\")\n",
        "    except Exception as local_e:\n",
        "        print(f\"Error writing to local filesystem: {str(local_e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
