{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/02/17 20:17:36 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----+\n",
            "| id|name|\n",
            "+---+----+\n",
            "|  1| foo|\n",
            "|  2| bar|\n",
            "+---+----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Initialize Spark with Iceberg support\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Iceberg Example\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
        "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.iceberg.spark.SparkSessionCatalog\") \\\n",
        "    .config(\"spark.sql.catalog.spark_catalog.type\", \"hive\") \\\n",
        "    .config(\"spark.sql.catalog.local\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
        "    .config(\"spark.sql.catalog.local.type\", \"hadoop\") \\\n",
        "    .config(\"spark.sql.catalog.local.warehouse\", \"s3a://iceberg/warehouse\") \\\n",
        "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9010\") \\\n",
        "    .config(\"spark.hadoop.fs.s3a.access.key\", \"minioadmin\") \\\n",
        "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"minioadmin\") \\\n",
        "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
        "    .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\") \\\n",
        "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\") \\\n",
        "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
        "    .getOrCreate()\n",
        "    \n",
        "# Create example data\n",
        "data = [(1, \"foo\"), (2, \"bar\")]\n",
        "df = spark.createDataFrame(data, [\"id\", \"name\"])\n",
        "\n",
        "# Create an Iceberg table\n",
        "df.writeTo(\"local.db.example\").createOrReplace()\n",
        "\n",
        "# Read from the Iceberg table\n",
        "result = spark.table(\"local.db.example\")\n",
        "result.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
