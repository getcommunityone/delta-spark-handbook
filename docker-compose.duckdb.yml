services:
  minio:
    image: minio/minio:latest
    container_name: minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin
      - MINIO_HTTP_BODY_SIZE_LIMIT=1G
      - MINIO_HTTP_MIN_PART_SIZE=64M
    command: server /data --console-address ":9001"
    volumes:
      - minio-data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
      start_period: 10s
    networks:
      - spark-net

  createbucket:
    container_name: createbucket
    image: minio/mc:latest
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -c "
      until (/usr/bin/mc alias set myminio http://minio:9000 minioadmin minioadmin); do echo 'Waiting for MinIO...'; sleep 1; done;
      /usr/bin/mc mb myminio/wba;
      /usr/bin/mc policy set public myminio/wba;
      echo 'Bucket created successfully `myminio/wba`.';
      echo 'Access permission for `myminio/wba` is set to `public`';
      "
    networks:
      - spark-net

  deltasharing:
    image: deltaio/delta-sharing-server:0.6.7 
    platform: linux/amd64
    container_name: deltasharing
    ports:
      - "7777:80"
    volumes:
      - ./delta-sharing-conf/delta-sharing-server-config.yaml:/config/delta-sharing-server-config.yaml
      - ./delta-jars:/opt/delta-sharing/jars
    command: ["--config", "/config/delta-sharing-server-config.yaml"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    depends_on:
      - minio
    networks:
      - spark-net

  spark-init:
    image: bitnami/spark:3.5.5
    container_name: spark-init
    user: "0"  # Run as root to avoid permission issues
    volumes:
      - ./spark-conf:/opt/bitnami/spark/conf:rw
    entrypoint: ["/bin/bash", "-c"]
    command:
      - |
        echo "Fixing Spark configuration permissions..."
        chown -R 1001:1001 /opt/bitnami/spark/conf
        chmod -R u+rwX,g+rX,o+rX /opt/bitnami/spark/conf
        echo "Permissions fixed."
    depends_on:
      minio:
        condition: service_healthy  # Ensure it runs after minio is healthy
    networks:
      - spark-net

  spark-master:
    image: bitnami/spark:3.5.5
    container_name: spark-master
    user: "1001"
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
      - SPARK_EXTRA_CLASSPATH=/opt/bitnami/spark/jars/*
      - HADOOP_CLASSPATH=/opt/bitnami/spark/jars/*
    ports:
      - "8080:8080"
      - "7077:7077"
    volumes:
      - ./spark-conf:/opt/bitnami/spark/conf:rw,z
      - ./delta-jars:/opt/bitnami/spark/jars
    networks:
      - spark-net
    deploy:
        restart_policy:
          condition: on-failure
          delay: 5s
          max_attempts: 3
    healthcheck:
      test: ["CMD", "true"]
      interval: 5s
      timeout: 5s
      retries: 3
    depends_on:
      spark-init:
        condition: service_completed_successfully
      minio:
        condition: service_healthy

  spark-worker:
    image: bitnami/spark:3.5.5
    container_name: spark-worker
    user: "1001"
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=4G
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_WEBUI_PORT=8081
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
      - SPARK_EXTRA_CLASSPATH=/opt/bitnami/spark/jars/*
      - HADOOP_CLASSPATH=/opt/bitnami/spark/jars/*
    ports:
      - "8082:8081"  # Changed from 8081 to avoid conflict with DuckDB server
    volumes:
      - ./spark-conf:/opt/bitnami/spark/conf:rw,z
      - ./delta-jars:/opt/bitnami/spark/jars
    networks:
      - spark-net
    deploy:
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
    healthcheck:
      test: ["CMD", "true"]
      interval: 5s
      timeout: 5s
      retries: 3
    depends_on:
      spark-init:
        condition: service_completed_successfully
      spark-master:
        condition: service_started
      minio:
        condition: service_healthy

  duckdb-server:
    build:
      context: .
      dockerfile: .devcontainer/Dockerfile.duckdb
    container_name: duckdb-server
    volumes:
      - ./duckdb-data:/data
      - ./delta-jars:/jars
      - ./duckdb-config:/app
    environment:
      - DUCKDB_DATABASE=/data/database.db
      - DUCKDB_USE_DIRECT_IO=true
    ports:
      - "8081:8081"
    command: >
      bash -c "
        mkdir -p /data && chmod 777 /data &&
        duckdb /data/database.db -c '
        INSTALL httpfs;
        LOAD httpfs;
        SET s3_region=\"us-east-1\";
        SET s3_endpoint=\"http://minio:9000\";
        SET s3_access_key_id=\"minioadmin\";
        SET s3_secret_access_key=\"minioadmin\";
        ' &&
        python -m uvicorn server:app --host 0.0.0.0 --port 8081"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    depends_on:
      - minio
      - spark-master
    networks:
      - spark-net

  dev:
    container_name: dev
    build: 
      context: .
      dockerfile: .devcontainer/Dockerfile.dev
    volumes:
      - ..:/workspace:cached
      - delta-spark-cache:/root/.cache
      - /var/run/docker.sock:/var/run/docker.sock
      - ./delta-jars:/opt/spark/jars
    user: vscode
    command: sleep infinity
    environment:
      - PYTHONPATH=/workspace
      - DEBIAN_FRONTEND=noninteractive
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
      - DUCKDB_DATABASE=/data/warehouse.db
      - SPARK_HOME=/opt/spark
      - SPARK_EXTRA_CLASSPATH=/opt/spark/jars/*
      - HADOOP_CLASSPATH=/opt/spark/jars/*
      - SPARK_LOCAL_IP=0.0.0.0
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_DRIVER_HOST=0.0.0.0
      - SPARK_DRIVER_PORT=0
      - SPARK_BLOCK_MANAGER_PORT=0
    depends_on:
      - spark-master
      - duckdb-server
      - minio
    networks:
      - spark-net

networks:
  spark-net:
    driver: bridge

volumes:
  minio-data:
  delta-spark-cache: