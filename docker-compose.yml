version: '3.8'

services:
  kyuubi:
    image: apache/kyuubi:master-snapshot
    container_name: kyuubi-server
    ports:
      - "10009:10009"  # Kyuubi server
      - "19090:19090"  # Kyuubi web UI
    environment:
      - KYUUBI_JAVA_OPTS=-Dkyuubi.frontend.thrift.binary.bind.host=0.0.0.0 -Djavax.security.auth.useSubjectCredsOnly=false
      - KYUUBI_HOME=/opt/kyuubi
      - KYUUBI_WORK_DIR_ROOT=/opt/kyuubi/work
      - SPARK_HOME=/opt/spark
    volumes:
      - ./kyuubi-conf:/opt/kyuubi/conf
      - ./spark-conf:/opt/spark/conf
      - ./warehouse:/opt/kyuubi/warehouse
    depends_on:
      - spark-master
      - minio
    networks:
      - spark-net

  spark-master:
    hostname: spark-master
    extra_hosts:
      - "spark-master:127.0.0.1"
    image: bitnami/spark:3.4
    container_name: spark-master
    init: true
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8080 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - "8080:8080"
      - "7077:7077"
    volumes:
      - ./spark-conf:/opt/bitnami/spark/conf:rw,z
      - ./delta-jars:/opt/bitnami/spark/delta-jars
    networks:
      - spark-net

  spark-netcat-installer:
    image: bitnami/spark:3.4
    user: root
    command: apt-get update && apt-get install -y netcat-traditional
    volumes:
      - /usr/bin/nc:/usr/bin/nc

  spark-worker:
    image: bitnami/spark:3.4
    container_name: spark-worker
    user: "root"  # This is typically the Bitnami spark user ID
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=4G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./spark-conf:/opt/bitnami/spark/conf
      - ./delta-jars:/opt/bitnami/spark/delta-jars
    depends_on:
      spark-master:
        condition: service_healthy
    networks:
      - spark-net

  minio:
    image: minio/minio:latest
    container_name: minio
    hostname: minio
    extra_hosts:
      - "spark-master:127.0.0.1"
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin
    command: server /data --console-address ":9001"
    volumes:
      - minio-data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://minio:9000/minio/health/live"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    networks:
      spark-net:
          aliases:
            - minio  # Add explicit alias
  createbucket:
    hostname: createbucket
    container_name: createbucket
    image: minio/mc:latest
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -c "
      /usr/bin/mc alias set myminio http://minio:9000 minioadmin minioadmin;
      /usr/bin/mc mb myminio/wba;
      /usr/bin/mc anonymous set public myminio/wba;
      "
    networks:
      - spark-net

  dev:
    build: 
      context: .
      dockerfile: .devcontainer/Dockerfile.dev
    volumes:
      - ..:/workspace:cached
      - delta-spark-cache:/root/.cache
      - /var/run/docker.sock:/var/run/docker.sock
    user: vscode
    command: sleep infinity
    environment:
      - PYTHONPATH=/workspace
      - SPARK_HOME=/opt/spark
      - DEBIAN_FRONTEND=noninteractive
    depends_on:
      - kyuubi
      - spark-master
      - minio
    networks:
      - spark-net

networks:
  spark-net:
    driver: bridge

volumes:
  minio-data:
  delta-spark-cache:

